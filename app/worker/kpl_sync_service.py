"""
å¼€ç›˜å•¦æ•°æ®åŒæ­¥æœåŠ¡
è´Ÿè´£åŒæ­¥å¼€ç›˜å•¦ï¼ˆKPLï¼‰ä¸‰ä¸ªæ¥å£çš„æ•°æ®åˆ°MongoDB
- kpl_concept: å¼€ç›˜å•¦é¢˜æåº“
- kpl_concept_cons: å¼€ç›˜å•¦é¢˜ææˆåˆ†
- kpl_list: å¼€ç›˜å•¦æ¦œå•æ•°æ®
"""
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import logging

from tradingagents.dataflows.providers.china.tushare import TushareProvider
from app.core.database import get_mongo_db
from app.core.config import settings
from app.core.rate_limiter import get_tushare_rate_limiter
from pymongo import UpdateOne
from pymongo.errors import BulkWriteError

logger = logging.getLogger(__name__)


class KPLSyncService:
    """
    å¼€ç›˜å•¦æ•°æ®åŒæ­¥æœåŠ¡
    è´Ÿè´£å°†å¼€ç›˜å•¦æ•°æ®åŒæ­¥åˆ°MongoDB
    """
    
    def __init__(self):
        self.provider = TushareProvider()
        self.db = get_mongo_db()
        self.settings = settings
        
        # é€Ÿç‡é™åˆ¶å™¨
        tushare_tier = getattr(settings, "TUSHARE_TIER", "standard")
        safety_margin = float(getattr(settings, "TUSHARE_RATE_LIMIT_SAFETY_MARGIN", "0.8"))
        self.rate_limiter = get_tushare_rate_limiter(tier=tushare_tier, safety_margin=safety_margin)
        
        # æ‰¹é‡å¤„ç†é…ç½®
        self.batch_size = 500
        self._indexes_ensured = {
            "kpl_concept": False,
            "kpl_concept_cons": False,
            "kpl_list": False,
            "kpl_concept_stats": False
        }
    
    async def initialize(self):
        """åˆå§‹åŒ–åŒæ­¥æœåŠ¡"""
        success = await self.provider.connect()
        if not success:
            raise RuntimeError("âŒ Tushareè¿æ¥å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨å¼€ç›˜å•¦åŒæ­¥æœåŠ¡")
        logger.info("âœ… å¼€ç›˜å•¦åŒæ­¥æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    # ==================== ç´¢å¼•ç®¡ç† ====================
    
    async def _ensure_indexes(self, collection_name: str):
        """ç¡®ä¿å¿…è¦çš„ç´¢å¼•å­˜åœ¨"""
        if self._indexes_ensured.get(collection_name, False):
            return
        
        try:
            collection = self.db[collection_name]
            
            if collection_name == "kpl_concept":
                # å¼€ç›˜å•¦é¢˜æåº“ç´¢å¼•
                await collection.create_index(
                    [("trade_date", 1), ("ts_code", 1)],
                    unique=True,
                    name="trade_date_ts_code_unique",
                    background=True
                )
                await collection.create_index([("trade_date", -1)], name="trade_date_desc", background=True)
                await collection.create_index([("ts_code", 1)], name="ts_code_index", background=True)
                await collection.create_index([("name", 1)], name="name_index", background=True)
                await collection.create_index([("z_t_num", -1)], name="z_t_num_desc", background=True)
                await collection.create_index([("up_num", 1)], name="up_num_index", background=True)
                
            elif collection_name == "kpl_concept_cons":
                # å¼€ç›˜å•¦é¢˜ææˆåˆ†ç´¢å¼•
                await collection.create_index(
                    [("trade_date", 1), ("concept_code", 1), ("ts_code", 1)],
                    unique=True,
                    name="trade_date_concept_cons_unique",
                    background=True
                )
                await collection.create_index([("trade_date", -1)], name="trade_date_desc", background=True)
                await collection.create_index([("concept_code", 1)], name="concept_code_index", background=True)
                await collection.create_index([("ts_code", 1)], name="ts_code_index", background=True)
                await collection.create_index([("concept_name", 1)], name="concept_name_index", background=True)
                
            elif collection_name == "kpl_list":
                # å¼€ç›˜å•¦æ¦œå•æ•°æ®ç´¢å¼•
                # å…ˆåˆ é™¤æ—§çš„ç´¢å¼•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                try:
                    old_indexes = ["trade_date_rank_type_rank_unique", "rank_type_index", "rank_index"]
                    existing_indexes = await collection.list_indexes().to_list(length=None)
                    for idx in existing_indexes:
                        idx_name = idx.get('name', '')
                        if idx_name in old_indexes:
                            try:
                                await collection.drop_index(idx_name)
                                logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ—§ç´¢å¼•: {idx_name}")
                            except Exception as e:
                                logger.debug(f"åˆ é™¤ç´¢å¼• {idx_name} å¤±è´¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ£€æŸ¥æ—§ç´¢å¼•æ—¶å‡ºé”™: {e}")
                
                # åˆ›å»ºæ–°çš„å”¯ä¸€ç´¢å¼•ï¼ˆå…ˆå°è¯•åˆ é™¤ï¼Œå†åˆ›å»ºï¼‰
                try:
                    # å¦‚æœæ–°ç´¢å¼•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
                    try:
                        await collection.drop_index("trade_date_tag_ts_code_unique")
                        logger.info("ğŸ—‘ï¸ åˆ é™¤å·²å­˜åœ¨çš„æ–°ç´¢å¼•ï¼Œå‡†å¤‡é‡æ–°åˆ›å»º")
                    except:
                        pass  # ç´¢å¼•ä¸å­˜åœ¨ï¼Œç»§ç»­åˆ›å»º
                    
                    await collection.create_index(
                        [("trade_date", 1), ("tag", 1), ("ts_code", 1)],
                        unique=True,
                        name="trade_date_tag_ts_code_unique",
                        background=True
                    )
                except Exception as e:
                    if "already exists" not in str(e).lower():
                        logger.warning(f"âš ï¸ åˆ›å»ºå”¯ä¸€ç´¢å¼•å¤±è´¥: {e}")
                
                # åˆ›å»ºå…¶ä»–ç´¢å¼•
                try:
                    await collection.create_index([("trade_date", -1)], name="trade_date_desc", background=True)
                except:
                    pass
                try:
                    await collection.create_index([("tag", 1)], name="tag_index", background=True)
                except:
                    pass
                try:
                    await collection.create_index([("ts_code", 1)], name="ts_code_index", background=True)
                except:
                    pass
                try:
                    await collection.create_index([("status", 1)], name="status_index", background=True)
                except:
                    pass
                try:
                    await collection.create_index([("theme", 1)], name="theme_index", background=True)
                except:
                    pass
            
            elif collection_name == "kpl_concept_stats":
                # å¼€ç›˜å•¦é¢˜æç»Ÿè®¡æ•°æ®ç´¢å¼•
                await collection.create_index(
                    [("trade_date", 1), ("concept_code", 1)],
                    unique=True,
                    name="trade_date_concept_code_unique",
                    background=True
                )
                await collection.create_index([("trade_date", -1)], name="trade_date_desc", background=True)
                await collection.create_index([("concept_code", 1)], name="concept_code_index", background=True)
                await collection.create_index([("concept_name", 1)], name="concept_name_index", background=True)
                await collection.create_index([("limit_up_count", -1)], name="limit_up_count_desc", background=True)
            
            self._indexes_ensured[collection_name] = True
            logger.info(f"âœ… {collection_name} ç´¢å¼•æ£€æŸ¥å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ›å»º {collection_name} ç´¢å¼•æ—¶å‡ºç°è­¦å‘Šï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")
            self._indexes_ensured[collection_name] = True
    
    # ==================== å¼€ç›˜å•¦é¢˜æåº“åŒæ­¥ ====================
    
    async def sync_kpl_concept(self, trade_date: Optional[str] = None) -> Dict[str, Any]:
        """
        åŒæ­¥å¼€ç›˜å•¦é¢˜æåº“æ•°æ®
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼‰ï¼Œä¸ºç©ºåˆ™ä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥
        
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥å¼€ç›˜å•¦é¢˜æåº“æ•°æ®...")
        
        stats = {
            "total_processed": 0,
            "inserted": 0,
            "updated": 0,
            "errors": 0,
            "start_time": datetime.utcnow(),
            "errors_list": []
        }
        
        try:
            # ç¡®ä¿ç´¢å¼•å­˜åœ¨
            await self._ensure_indexes("kpl_concept")
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸï¼Œä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥
            if not trade_date:
                trade_date = await self._get_latest_trade_date()
            
            # ç­‰å¾…é€Ÿç‡é™åˆ¶
            await self.rate_limiter.acquire()
            
            # è°ƒç”¨Tushare API
            df = await asyncio.to_thread(
                self.provider.api.kpl_concept,
                trade_date=trade_date
            )
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ å¼€ç›˜å•¦é¢˜æåº“æ•°æ®ä¸ºç©ºï¼ˆæ—¥æœŸ: {trade_date}ï¼‰")
                stats["errors"] = 1
                stats["errors_list"].append(f"æ•°æ®ä¸ºç©ºï¼ˆæ—¥æœŸ: {trade_date}ï¼‰")
                return stats
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            records = df.to_dict('records')
            stats["total_processed"] = len(records)
            
            # æ‰¹é‡å†™å…¥MongoDB
            operations = []
            now_iso = datetime.utcnow().isoformat()
            
            for record in records:
                # æ ‡å‡†åŒ–æ•°æ®
                doc = {
                    "trade_date": str(record.get("trade_date", trade_date)),
                    "ts_code": str(record.get("ts_code", "")),
                    "name": str(record.get("name", "")),
                    "z_t_num": record.get("z_t_num"),
                    "up_num": record.get("up_num"),
                    "data_source": "tushare",
                    "updated_at": now_iso
                }
                
                # ä½¿ç”¨ trade_date + ts_code ä½œä¸ºå”¯ä¸€é”®
                operations.append(
                    UpdateOne(
                        {"trade_date": doc["trade_date"], "ts_code": doc["ts_code"]},
                        {"$set": doc},
                        upsert=True
                    )
                )
            
            # æ‰§è¡Œæ‰¹é‡å†™å…¥
            if operations:
                try:
                    result = await self.db["kpl_concept"].bulk_write(operations, ordered=False)
                    stats["inserted"] = result.upserted_count
                    stats["updated"] = result.modified_count
                    logger.info(f"âœ… å¼€ç›˜å•¦é¢˜æåº“åŒæ­¥å®Œæˆ: æ–°å¢ {stats['inserted']} æ¡, æ›´æ–° {stats['updated']} æ¡")
                except BulkWriteError as e:
                    stats["errors"] = len(e.details.get('writeErrors', []))
                    logger.error(f"âŒ æ‰¹é‡å†™å…¥å¤±è´¥: {e}")
                    stats["errors_list"].append(str(e))
            
            stats["end_time"] = datetime.utcnow()
            stats["duration"] = (stats["end_time"] - stats["start_time"]).total_seconds()
            
            return stats
            
        except Exception as e:
            logger.exception(f"âŒ åŒæ­¥å¼€ç›˜å•¦é¢˜æåº“å¤±è´¥: {e}")
            stats["errors"] = 1
            stats["errors_list"].append(str(e))
            stats["end_time"] = datetime.utcnow()
            return stats
    
    # ==================== å¼€ç›˜å•¦é¢˜ææˆåˆ†åŒæ­¥ ====================
    
    async def sync_kpl_concept_cons(self, trade_date: Optional[str] = None) -> Dict[str, Any]:
        """
        åŒæ­¥å¼€ç›˜å•¦é¢˜ææˆåˆ†æ•°æ®
        
        é€»è¾‘ï¼šå…ˆä» kpl_concept é›†åˆè·å–è¯¥æ—¥æœŸçš„æ‰€æœ‰é¢˜æä»£ç ï¼Œç„¶åå¾ªç¯è°ƒç”¨ kpl_concept_cons æ¥å£
        è·å–æ¯ä¸ªé¢˜æçš„æˆåˆ†è‚¡æ•°æ®
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼‰ï¼Œä¸ºç©ºåˆ™ä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥
        
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥å¼€ç›˜å•¦é¢˜ææˆåˆ†æ•°æ®...")
        
        stats = {
            "total_processed": 0,
            "inserted": 0,
            "updated": 0,
            "errors": 0,
            "concepts_processed": 0,
            "concepts_failed": 0,
            "start_time": datetime.utcnow(),
            "errors_list": []
        }
        
        try:
            # ç¡®ä¿ç´¢å¼•å­˜åœ¨
            await self._ensure_indexes("kpl_concept_cons")
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸï¼Œä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥
            if not trade_date:
                trade_date = await self._get_latest_trade_date()
            
            logger.info(f"ğŸ“… åŒæ­¥æ—¥æœŸ: {trade_date}")
            
            # 1. ä» kpl_concept é›†åˆè·å–è¯¥æ—¥æœŸçš„æ‰€æœ‰é¢˜æä»£ç 
            concept_cursor = self.db["kpl_concept"].find(
                {"trade_date": trade_date},
                {"ts_code": 1, "name": 1}
            )
            concepts = await concept_cursor.to_list(length=None)
            
            if not concepts:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ—¥æœŸ {trade_date} çš„é¢˜ææ•°æ®ï¼Œè¯·å…ˆåŒæ­¥ kpl_concept")
                stats["errors"] = 1
                stats["errors_list"].append(f"æœªæ‰¾åˆ°æ—¥æœŸ {trade_date} çš„é¢˜ææ•°æ®")
                return stats
            
            concept_list = [(c.get("ts_code"), c.get("name", "")) for c in concepts if c.get("ts_code")]
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(concept_list)} ä¸ªé¢˜æï¼Œå¼€å§‹å¾ªç¯è·å–æˆåˆ†è‚¡...")
            
            # 2. å¾ªç¯æ¯ä¸ªé¢˜æä»£ç ï¼Œè°ƒç”¨ kpl_concept_cons æ¥å£
            all_operations = []
            now_iso = datetime.utcnow().isoformat()
            
            for idx, (concept_code, concept_name) in enumerate(concept_list, 1):
                try:
                    # ç­‰å¾…é€Ÿç‡é™åˆ¶
                    await self.rate_limiter.acquire()
                    
                    # è°ƒç”¨Tushare APIè·å–è¯¥é¢˜æçš„æˆåˆ†è‚¡
                    df = await asyncio.to_thread(
                        self.provider.api.kpl_concept_cons,
                        trade_date=trade_date,
                        ts_code=concept_code
                    )
                    
                    if df is None or df.empty:
                        logger.debug(f"âš ï¸ é¢˜æ {concept_code} ({concept_name}) æ— æˆåˆ†è‚¡æ•°æ®")
                        stats["concepts_failed"] += 1
                        continue
                    
                    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                    records = df.to_dict('records')
                    stats["total_processed"] += len(records)
                    
                    # å¤„ç†æ¯æ¡è®°å½•
                    for record in records:
                        # æ ¹æ®APIæ–‡æ¡£ï¼Œå­—æ®µæ˜ å°„ï¼š
                        # ts_code -> concept_code (é¢˜æä»£ç )
                        # name -> concept_name (é¢˜æåç§°)
                        # con_code -> ts_code (è‚¡ç¥¨ä»£ç )
                        # con_name -> stock_name (è‚¡ç¥¨åç§°)
                        doc = {
                            "trade_date": str(record.get("trade_date", trade_date)),
                            "concept_code": str(record.get("ts_code", concept_code)),  # é¢˜æä»£ç 
                            "ts_code": str(record.get("con_code", "")),  # è‚¡ç¥¨ä»£ç 
                            "concept_name": str(record.get("name", concept_name)),  # é¢˜æåç§°
                            "stock_name": str(record.get("con_name", "")),  # è‚¡ç¥¨åç§°
                            "desc": str(record.get("desc", "")),  # æè¿°
                            "hot_num": record.get("hot_num"),  # äººæ°”å€¼
                            "data_source": "tushare",
                            "updated_at": now_iso
                        }
                        
                        # ä¿ç•™æ‰€æœ‰åŸå§‹å­—æ®µï¼ˆç”¨äºè°ƒè¯•å’Œæ‰©å±•ï¼‰
                        for key, value in record.items():
                            if key not in doc and value is not None:
                                doc[f"raw_{key}"] = value
                        
                        # ä½¿ç”¨ trade_date + concept_code + ts_code ä½œä¸ºå”¯ä¸€é”®
                        all_operations.append(
                            UpdateOne(
                                {
                                    "trade_date": doc["trade_date"],
                                    "concept_code": doc["concept_code"],
                                    "ts_code": doc["ts_code"]
                                },
                                {"$set": doc},
                                upsert=True
                            )
                        )
                    
                    stats["concepts_processed"] += 1
                    
                    # æ¯å¤„ç†10ä¸ªé¢˜æè¾“å‡ºä¸€æ¬¡è¿›åº¦
                    if idx % 10 == 0:
                        logger.info(f"ğŸ“ˆ è¿›åº¦: {idx}/{len(concept_list)} ä¸ªé¢˜æå·²å¤„ç†ï¼Œå·²è·å– {stats['total_processed']} æ¡æˆåˆ†è‚¡æ•°æ®")
                    
                except Exception as e:
                    logger.error(f"âŒ è·å–é¢˜æ {concept_code} ({concept_name}) æˆåˆ†è‚¡å¤±è´¥: {e}")
                    stats["concepts_failed"] += 1
                    stats["errors_list"].append(f"é¢˜æ {concept_code}: {str(e)}")
                    continue
            
            # 3. æ‰¹é‡å†™å…¥MongoDBï¼ˆåˆ†æ‰¹å†™å…¥ï¼Œé¿å…å•æ¬¡æ“ä½œè¿‡å¤§ï¼‰
            if all_operations:
                batch_size = 1000
                total_inserted = 0
                total_updated = 0
                
                for i in range(0, len(all_operations), batch_size):
                    batch = all_operations[i:i + batch_size]
                    try:
                        result = await self.db["kpl_concept_cons"].bulk_write(batch, ordered=False)
                        total_inserted += result.upserted_count
                        total_updated += result.modified_count
                    except BulkWriteError as e:
                        write_errors = len(e.details.get('writeErrors', []))
                        stats["errors"] += write_errors
                        logger.error(f"âŒ æ‰¹é‡å†™å…¥å¤±è´¥ï¼ˆæ‰¹æ¬¡ {i//batch_size + 1}ï¼‰: {write_errors} æ¡é”™è¯¯")
                        stats["errors_list"].append(f"æ‰¹é‡å†™å…¥æ‰¹æ¬¡ {i//batch_size + 1}: {str(e)}")
                
                stats["inserted"] = total_inserted
                stats["updated"] = total_updated
                logger.info(
                    f"âœ… å¼€ç›˜å•¦é¢˜ææˆåˆ†åŒæ­¥å®Œæˆ: "
                    f"å¤„ç† {stats['concepts_processed']} ä¸ªé¢˜æ, "
                    f"å¤±è´¥ {stats['concepts_failed']} ä¸ªé¢˜æ, "
                    f"æ–°å¢ {stats['inserted']} æ¡, "
                    f"æ›´æ–° {stats['updated']} æ¡, "
                    f"æ€»è®¡ {stats['total_processed']} æ¡æˆåˆ†è‚¡æ•°æ®"
                )
            else:
                logger.warning(f"âš ï¸ æœªè·å–åˆ°ä»»ä½•æˆåˆ†è‚¡æ•°æ®")
            
            stats["end_time"] = datetime.utcnow()
            stats["duration"] = (stats["end_time"] - stats["start_time"]).total_seconds()
            
            return stats
            
        except Exception as e:
            logger.exception(f"âŒ åŒæ­¥å¼€ç›˜å•¦é¢˜ææˆåˆ†å¤±è´¥: {e}")
            stats["errors"] = 1
            stats["errors_list"].append(str(e))
            stats["end_time"] = datetime.utcnow()
            return stats
    
    # ==================== å¼€ç›˜å•¦æ¦œå•æ•°æ®åŒæ­¥ ====================
    
    async def sync_kpl_list(self, trade_date: Optional[str] = None) -> Dict[str, Any]:
        """
        åŒæ­¥å¼€ç›˜å•¦æ¦œå•æ•°æ®
        
        é€»è¾‘ï¼šä» kpl_concept é›†åˆè·å– trade_dateï¼Œç„¶åå¾ªç¯è°ƒç”¨ kpl_list æ¥å£
        åˆ†åˆ«ä½¿ç”¨ tag='æ¶¨åœ'ã€'è·Œåœ'ã€'ç‚¸æ¿' å„è°ƒç”¨ä¸€æ¬¡
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼‰ï¼Œä¸ºç©ºåˆ™ä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥
        
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥å¼€ç›˜å•¦æ¦œå•æ•°æ®...")
        
        stats = {
            "total_processed": 0,
            "inserted": 0,
            "updated": 0,
            "errors": 0,
            "tags_processed": 0,
            "tags_failed": 0,
            "start_time": datetime.utcnow(),
            "errors_list": []
        }
        
        try:
            # ç¡®ä¿ç´¢å¼•å­˜åœ¨
            await self._ensure_indexes("kpl_list")
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸï¼Œä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥
            if not trade_date:
                trade_date = await self._get_latest_trade_date()
            
            logger.info(f"ğŸ“… åŒæ­¥æ—¥æœŸ: {trade_date}")
            
            # 1. ä» kpl_concept é›†åˆè·å–è¯¥æ—¥æœŸï¼ˆéªŒè¯æ•°æ®æ˜¯å¦å­˜åœ¨ï¼‰
            concept_count = await self.db["kpl_concept"].count_documents({"trade_date": trade_date})
            if concept_count == 0:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ—¥æœŸ {trade_date} çš„é¢˜ææ•°æ®ï¼Œè¯·å…ˆåŒæ­¥ kpl_concept")
                stats["errors"] = 1
                stats["errors_list"].append(f"æœªæ‰¾åˆ°æ—¥æœŸ {trade_date} çš„é¢˜ææ•°æ®")
                return stats
            
            # 2. å®šä¹‰éœ€è¦åŒæ­¥çš„æ¦œå•ç±»å‹
            tags = ['æ¶¨åœ', 'è·Œåœ', 'ç‚¸æ¿', 'è‡ªç„¶æ¶¨åœ', 'ç«ä»·']            
            logger.info(f"ğŸ“Š å¼€å§‹å¾ªç¯è·å–æ¦œå•æ•°æ®ï¼Œç±»å‹: {tags}")
            
            # 3. å¾ªç¯æ¯ä¸ªæ¦œå•ç±»å‹ï¼Œè°ƒç”¨ kpl_list æ¥å£
            all_operations = []
            now_iso = datetime.utcnow().isoformat()
            
            for tag in tags:
                try:
                    # ç­‰å¾…é€Ÿç‡é™åˆ¶
                    await self.rate_limiter.acquire()
                    
                    # æ˜ç¡®æŒ‡å®šéœ€è¦è¿”å›çš„å­—æ®µï¼Œç¡®ä¿åŒ…å« pct_chg
                    fields = "ts_code,name,trade_date,lu_time,ld_time,open_time,last_time,lu_desc,tag,theme,net_change,bid_amount,status,bid_change,bid_turnover,lu_bid_vol,pct_chg,bid_pct_chg,rt_pct_chg,limit_order,amount,turnover_rate,free_float,lu_limit_order"
                    
                    # è°ƒç”¨Tushare APIè·å–è¯¥ç±»å‹çš„æ¦œå•æ•°æ®
                    df = await asyncio.to_thread(
                        self.provider.api.kpl_list,
                        trade_date=trade_date,
                        tag=tag,
                        fields=fields
                    )
                    
                    if df is None or df.empty:
                        logger.debug(f"âš ï¸ æ¦œå•ç±»å‹ {tag} æ— æ•°æ®ï¼ˆæ—¥æœŸ: {trade_date}ï¼‰")
                        stats["tags_failed"] += 1
                        continue
                    
                    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                    records = df.to_dict('records')
                    stats["total_processed"] += len(records)
                    
                    # å¤„ç†æ¯æ¡è®°å½•
                    for record in records:
                        # éªŒè¯å¿…éœ€å­—æ®µ
                        ts_code = str(record.get("ts_code", "")).strip()
                        if not ts_code:
                            logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆè®°å½•ï¼ˆts_codeä¸ºç©ºï¼‰: {record}")
                            continue
                        
                        # æ ¹æ®APIæ–‡æ¡£ï¼Œå­˜å‚¨æ‰€æœ‰å­—æ®µ
                        doc = {
                            "trade_date": str(record.get("trade_date", trade_date)),
                            "tag": str(record.get("tag", tag)),  # æ¦œå•ç±»å‹
                            "ts_code": ts_code,  # è‚¡ç¥¨ä»£ç ï¼ˆå·²éªŒè¯éç©ºï¼‰
                            "name": str(record.get("name", "")),  # è‚¡ç¥¨åç§°
                            "lu_time": str(record.get("lu_time", "")),  # æ¶¨åœæ—¶é—´
                            "ld_time": str(record.get("ld_time", "")),  # è·Œåœæ—¶é—´
                            "open_time": str(record.get("open_time", "")),  # å¼€æ¿æ—¶é—´
                            "last_time": str(record.get("last_time", "")),  # æœ€åæ¶¨åœæ—¶é—´
                            "lu_desc": str(record.get("lu_desc", "")),  # æ¶¨åœåŸå› 
                            "theme": str(record.get("theme", "")),  # æ¿å—
                            "net_change": record.get("net_change"),  # ä¸»åŠ›å‡€é¢(å…ƒ)
                            "bid_amount": record.get("bid_amount"),  # ç«ä»·æˆäº¤é¢(å…ƒ)
                            "status": str(record.get("status", "")),  # çŠ¶æ€ï¼ˆNè¿æ¿ï¼‰
                            "bid_change": record.get("bid_change"),  # ç«ä»·å‡€é¢
                            "bid_turnover": record.get("bid_turnover"),  # ç«ä»·æ¢æ‰‹%
                            "lu_bid_vol": record.get("lu_bid_vol"),  # æ¶¨åœå§”ä¹°é¢
                            "pct_chg": self._safe_float(record.get("pct_chg")),  # æ¶¨è·Œå¹…%
                            "bid_pct_chg": self._safe_float(record.get("bid_pct_chg")),  # ç«ä»·æ¶¨å¹…%
                            "rt_pct_chg": self._safe_float(record.get("rt_pct_chg")),  # å®æ—¶æ¶¨å¹…%
                            "limit_order": record.get("limit_order"),  # å°å•
                            "amount": record.get("amount"),  # æˆäº¤é¢
                            "turnover_rate": record.get("turnover_rate"),  # æ¢æ‰‹ç‡%
                            "free_float": record.get("free_float"),  # å®é™…æµé€š
                            "lu_limit_order": record.get("lu_limit_order"),  # æœ€å¤§å°å•
                            "data_source": "tushare",
                            "updated_at": now_iso
                        }
                        
                        # ä¿ç•™æ‰€æœ‰åŸå§‹å­—æ®µï¼ˆç”¨äºè°ƒè¯•å’Œæ‰©å±•ï¼‰
                        for key, value in record.items():
                            if key not in doc and value is not None:
                                doc[key] = value
                        
                        # ä½¿ç”¨ trade_date + tag + ts_code ä½œä¸ºå”¯ä¸€é”®
                        all_operations.append(
                            UpdateOne(
                                {
                                    "trade_date": doc["trade_date"],
                                    "tag": doc["tag"],
                                    "ts_code": doc["ts_code"]
                                },
                                {"$set": doc},
                                upsert=True
                            )
                        )
                    
                    stats["tags_processed"] += 1
                    logger.info(f"âœ… æ¦œå•ç±»å‹ {tag} è·å–å®Œæˆ: {len(records)} æ¡æ•°æ®")
                    
                except Exception as e:
                    logger.error(f"âŒ è·å–æ¦œå•ç±»å‹ {tag} å¤±è´¥: {e}")
                    stats["tags_failed"] += 1
                    stats["errors_list"].append(f"æ¦œå•ç±»å‹ {tag}: {str(e)}")
                    continue
            
            # 4. æ‰¹é‡å†™å…¥MongoDBï¼ˆåˆ†æ‰¹å†™å…¥ï¼Œé¿å…å•æ¬¡æ“ä½œè¿‡å¤§ï¼‰
            if all_operations:
                batch_size = 1000
                total_inserted = 0
                total_updated = 0
                
                for i in range(0, len(all_operations), batch_size):
                    batch = all_operations[i:i + batch_size]
                    try:
                        result = await self.db["kpl_list"].bulk_write(batch, ordered=False)
                        total_inserted += result.upserted_count
                        total_updated += result.modified_count
                    except BulkWriteError as e:
                        write_errors = e.details.get('writeErrors', [])
                        error_count = len(write_errors)
                        stats["errors"] += error_count
                        
                        # è¾“å‡ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                        logger.error(f"âŒ æ‰¹é‡å†™å…¥å¤±è´¥ï¼ˆæ‰¹æ¬¡ {i//batch_size + 1}ï¼‰: {error_count} æ¡é”™è¯¯")
                        
                        # è®°å½•å‰5ä¸ªé”™è¯¯çš„è¯¦ç»†ä¿¡æ¯
                        for idx, error in enumerate(write_errors[:5], 1):
                            error_code = error.get('code', 'N/A')
                            error_msg = error.get('errmsg', 'Unknown error')
                            error_index = error.get('index', 'N/A')
                            logger.error(f"   é”™è¯¯ {idx}: [Code {error_code}] {error_msg} (ç´¢å¼•: {error_index})")
                        
                        if error_count > 5:
                            logger.error(f"   ... è¿˜æœ‰ {error_count - 5} ä¸ªé”™è¯¯æœªæ˜¾ç¤º")
                        
                        # ç»Ÿè®¡æˆåŠŸå†™å…¥çš„æ•°é‡ï¼ˆå³ä½¿æœ‰é”™è¯¯ï¼Œéƒ¨åˆ†æ•°æ®å¯èƒ½å·²å†™å…¥ï¼‰
                        if hasattr(e, 'details'):
                            n_inserted = e.details.get('nInserted', 0)
                            n_modified = e.details.get('nModified', 0)
                            if n_inserted > 0 or n_modified > 0:
                                total_inserted += n_inserted
                                total_updated += n_modified
                                logger.info(f"   â„¹ï¸ éƒ¨åˆ†æˆåŠŸ: æ–°å¢ {n_inserted} æ¡, æ›´æ–° {n_modified} æ¡")
                        
                        stats["errors_list"].append(f"æ‰¹é‡å†™å…¥æ‰¹æ¬¡ {i//batch_size + 1}: {error_count} æ¡é”™è¯¯")
                
                stats["inserted"] = total_inserted
                stats["updated"] = total_updated
                logger.info(
                    f"âœ… å¼€ç›˜å•¦æ¦œå•æ•°æ®åŒæ­¥å®Œæˆ: "
                    f"å¤„ç† {stats['tags_processed']} ä¸ªæ¦œå•ç±»å‹, "
                    f"å¤±è´¥ {stats['tags_failed']} ä¸ªæ¦œå•ç±»å‹, "
                    f"æ–°å¢ {stats['inserted']} æ¡, "
                    f"æ›´æ–° {stats['updated']} æ¡, "
                    f"æ€»è®¡ {stats['total_processed']} æ¡æ¦œå•æ•°æ®"
                )
                
                # 5. ç»Ÿè®¡é¢˜ææ•°æ®å¹¶å†™å…¥æ–°è¡¨
                concept_stats_result = await self._sync_concept_stats(trade_date)
                stats["concept_stats"] = concept_stats_result
            else:
                logger.warning(f"âš ï¸ æœªè·å–åˆ°ä»»ä½•æ¦œå•æ•°æ®")
            
            stats["end_time"] = datetime.utcnow()
            stats["duration"] = (stats["end_time"] - stats["start_time"]).total_seconds()
            
            return stats
            
        except Exception as e:
            logger.exception(f"âŒ åŒæ­¥å¼€ç›˜å•¦æ¦œå•æ•°æ®å¤±è´¥: {e}")
            stats["errors"] = 1
            stats["errors_list"].append(str(e))
            stats["end_time"] = datetime.utcnow()
            return stats
    
    # ==================== é¢˜æç»Ÿè®¡æ•°æ®åŒæ­¥ ====================
    
    async def _sync_concept_stats(self, trade_date: str) -> Dict[str, Any]:
        """
        ç»Ÿè®¡æ¯ä¸ªé¢˜æçš„æ¶¨åœã€è·Œåœã€ç‚¸æ¿ã€æ¶¨å¹…è¶…è¿‡9%çš„ä¸ªæ•°
        
        é€»è¾‘ï¼š
        1. ä» kpl_concept è·å–è¯¥æ—¥æœŸçš„æ‰€æœ‰é¢˜æ
        2. å¯¹æ¯ä¸ªé¢˜æï¼Œä» kpl_concept_cons è·å–è¯¥é¢˜æåŒ…å«çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        3. ä» kpl_list ä¸­æŸ¥æ‰¾è¿™äº›è‚¡ç¥¨çš„æ¶¨è·Œåœä¿¡æ¯è¿›è¡Œç»Ÿè®¡
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼‰
        
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        logger.info("ğŸ”„ å¼€å§‹ç»Ÿè®¡é¢˜ææ•°æ®...")
        
        try:
            # ç¡®ä¿ç´¢å¼•å­˜åœ¨
            await self._ensure_indexes("kpl_concept_stats")
            
            # 1. ä» kpl_concept è·å–è¯¥æ—¥æœŸçš„æ‰€æœ‰é¢˜æ
            concept_cursor = self.db["kpl_concept"].find(
                {"trade_date": trade_date},
                {"ts_code": 1, "name": 1}
            )
            concepts = await concept_cursor.to_list(length=None)
            
            if not concepts:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ—¥æœŸ {trade_date} çš„é¢˜ææ•°æ®ï¼Œè¯·å…ˆåŒæ­¥ kpl_concept")
                return {"inserted": 0, "updated": 0}
            
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(concepts)} ä¸ªé¢˜æï¼Œå¼€å§‹ç»Ÿè®¡...")
            
            # 2. ä» kpl_list è·å–è¯¥æ—¥æœŸçš„æ‰€æœ‰è‚¡ç¥¨æ¶¨è·Œåœä¿¡æ¯ï¼ˆå»ºç«‹ç´¢å¼•ï¼‰
            list_cursor = self.db["kpl_list"].find(
                {"trade_date": trade_date},
                {"ts_code": 1, "tag": 1, "pct_chg": 1}
            )
            list_records = await list_cursor.to_list(length=None)
            
            # å»ºç«‹è‚¡ç¥¨ä»£ç åˆ°æ¶¨è·Œåœä¿¡æ¯çš„æ˜ å°„ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
            stock_info_map = {}
            for record in list_records:
                ts_code = record.get("ts_code", "")
                if not ts_code:
                    continue
                
                # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼šæå–6ä½æ•°å­—ä»£ç 
                # å¤„ç†æ ¼å¼ï¼š000001.SZ, 000001.SH, 000001, 600001 ç­‰
                code_6digit = self._normalize_stock_code(ts_code)
                if not code_6digit:
                    continue
                
                if code_6digit not in stock_info_map:
                    stock_info_map[code_6digit] = {
                        "limit_up": False,
                        "limit_down": False,
                        "zha_ban": False,
                        "high_gain": False
                    }
                
                # è®°å½•æ¶¨è·Œåœä¿¡æ¯
                tag = record.get("tag", "")
                if tag == "æ¶¨åœ":
                    stock_info_map[code_6digit]["limit_up"] = True
                elif tag == "è·Œåœ":
                    stock_info_map[code_6digit]["limit_down"] = True
                elif tag == "ç‚¸æ¿":
                    stock_info_map[code_6digit]["zha_ban"] = True
                
                # æ£€æŸ¥æ¶¨å¹…ï¼ˆæ¶¨å¹…è¶…è¿‡9%çš„ç»Ÿè®¡ï¼‰
                pct_chg = record.get("pct_chg")
                if pct_chg is not None and isinstance(pct_chg, (int, float)) and pct_chg > 9:
                    stock_info_map[code_6digit]["high_gain"] = True
            
            logger.info(f"ğŸ“ˆ ä» kpl_list è·å–åˆ° {len(stock_info_map)} åªè‚¡ç¥¨çš„æ¶¨è·Œåœä¿¡æ¯")
            
            # 3. å¯¹æ¯ä¸ªé¢˜æï¼Œç»Ÿè®¡å…¶åŒ…å«è‚¡ç¥¨çš„æ¶¨è·Œåœä¿¡æ¯
            operations = []
            now_iso = datetime.utcnow().isoformat()
            concepts_processed = 0
            
            for concept in concepts:
                concept_code = concept.get("ts_code", "")
                concept_name = concept.get("name", "")
                
                if not concept_code:
                    continue
                
                # ä» kpl_concept_cons è·å–è¯¥é¢˜æåŒ…å«çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
                cons_cursor = self.db["kpl_concept_cons"].find(
                    {
                        "trade_date": trade_date,
                        "concept_code": concept_code
                    },
                    {"ts_code": 1}
                )
                cons_stocks = await cons_cursor.to_list(length=None)
                
                if not cons_stocks:
                    continue
                
                # ç»Ÿè®¡è¯¥é¢˜æçš„æ¶¨è·Œåœä¿¡æ¯
                limit_up_count = 0
                limit_down_count = 0
                zha_ban_count = 0
                high_gain_count = 0
                
                for cons_stock in cons_stocks:
                    stock_code = cons_stock.get("ts_code", "")
                    if not stock_code:
                        continue
                    
                    # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼šæå–6ä½æ•°å­—ä»£ç 
                    code_6digit = self._normalize_stock_code(stock_code)
                    if not code_6digit:
                        continue
                    
                    # ä»æ˜ å°„ä¸­æŸ¥æ‰¾è¯¥è‚¡ç¥¨çš„æ¶¨è·Œåœä¿¡æ¯
                    if code_6digit in stock_info_map:
                        stock_info = stock_info_map[code_6digit]
                        if stock_info["limit_up"]:
                            limit_up_count += 1
                        if stock_info["limit_down"]:
                            limit_down_count += 1
                        if stock_info["zha_ban"]:
                            zha_ban_count += 1
                        if stock_info["high_gain"]:
                            high_gain_count += 1
                
                # å‡†å¤‡å†™å…¥æ•°æ®
                doc = {
                    "trade_date": trade_date,
                    "concept_code": concept_code,
                    "concept_name": concept_name,
                    "limit_up_count": limit_up_count,
                    "limit_down_count": limit_down_count,
                    "zha_ban_count": zha_ban_count,
                    "high_gain_count": high_gain_count,
                    "total_stocks": len(cons_stocks),  # è¯¥é¢˜æåŒ…å«çš„è‚¡ç¥¨æ€»æ•°
                    "data_source": "tushare",
                    "updated_at": now_iso
                }
                
                # ä½¿ç”¨ trade_date + concept_code ä½œä¸ºå”¯ä¸€é”®
                operations.append(
                    UpdateOne(
                        {
                            "trade_date": doc["trade_date"],
                            "concept_code": doc["concept_code"]
                        },
                        {"$set": doc},
                        upsert=True
                    )
                )
                
                concepts_processed += 1
                
                # æ¯å¤„ç†50ä¸ªé¢˜æè¾“å‡ºä¸€æ¬¡è¿›åº¦
                if concepts_processed % 50 == 0:
                    logger.info(f"ğŸ“ˆ è¿›åº¦: {concepts_processed}/{len(concepts)} ä¸ªé¢˜æå·²ç»Ÿè®¡")
            
            # 4. æ‰¹é‡å†™å…¥
            if operations:
                try:
                    result = await self.db["kpl_concept_stats"].bulk_write(operations, ordered=False)
                    logger.info(
                        f"âœ… é¢˜æç»Ÿè®¡æ•°æ®åŒæ­¥å®Œæˆ: "
                        f"æ–°å¢ {result.upserted_count} æ¡, "
                        f"æ›´æ–° {result.modified_count} æ¡, "
                        f"å…± {concepts_processed} ä¸ªé¢˜æ"
                    )
                    return {
                        "inserted": result.upserted_count,
                        "updated": result.modified_count,
                        "total": concepts_processed
                    }
                except BulkWriteError as e:
                    write_errors = len(e.details.get('writeErrors', []))
                    logger.error(f"âŒ é¢˜æç»Ÿè®¡æ•°æ®æ‰¹é‡å†™å…¥å¤±è´¥: {write_errors} æ¡é”™è¯¯")
                    # å³ä½¿æœ‰é”™è¯¯ï¼Œä¹Ÿè¿”å›éƒ¨åˆ†æˆåŠŸçš„æ•°æ®
                    n_inserted = e.details.get('nInserted', 0)
                    n_modified = e.details.get('nModified', 0)
                    if n_inserted > 0 or n_modified > 0:
                        logger.info(f"   â„¹ï¸ éƒ¨åˆ†æˆåŠŸ: æ–°å¢ {n_inserted} æ¡, æ›´æ–° {n_modified} æ¡")
                    return {
                        "inserted": n_inserted,
                        "updated": n_modified,
                        "errors": write_errors
                    }
            else:
                logger.warning(f"âš ï¸ æœªç”Ÿæˆä»»ä½•é¢˜æç»Ÿè®¡æ•°æ®")
                return {"inserted": 0, "updated": 0}
                
        except Exception as e:
            logger.exception(f"âŒ ç»Ÿè®¡é¢˜ææ•°æ®å¤±è´¥: {e}")
            return {"inserted": 0, "updated": 0, "error": str(e)}
    
    # ==================== ç»Ÿä¸€åŒæ­¥å…¥å£ ====================
    
    async def sync_all(self, trade_date: Optional[str] = None) -> Dict[str, Any]:
        """
        åŒæ­¥æ‰€æœ‰å¼€ç›˜å•¦æ•°æ®
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼‰ï¼Œä¸ºç©ºåˆ™ä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥
        
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥æ‰€æœ‰å¼€ç›˜å•¦æ•°æ®...")
        
        overall_stats = {
            "start_time": datetime.utcnow(),
            "concept": {},
            "concept_cons": {},
            "list": {},
            "total_duration": 0
        }
        
        # åŒæ­¥é¢˜æåº“
        concept_stats = await self.sync_kpl_concept(trade_date)
        overall_stats["concept"] = concept_stats
        
        # åŒæ­¥é¢˜ææˆåˆ†
        concept_cons_stats = await self.sync_kpl_concept_cons(trade_date)
        overall_stats["concept_cons"] = concept_cons_stats
        
        # åŒæ­¥æ¦œå•æ•°æ®
        list_stats = await self.sync_kpl_list(trade_date)
        overall_stats["list"] = list_stats
        
        overall_stats["end_time"] = datetime.utcnow()
        overall_stats["total_duration"] = (overall_stats["end_time"] - overall_stats["start_time"]).total_seconds()
        
        logger.info(f"âœ… æ‰€æœ‰å¼€ç›˜å•¦æ•°æ®åŒæ­¥å®Œæˆï¼Œæ€»è€—æ—¶: {overall_stats['total_duration']:.2f}ç§’")
        
        return overall_stats
    
    # ==================== å·¥å…·æ–¹æ³• ====================
    
    def _normalize_stock_code(self, code: str) -> str:
        """
        æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ä¸º6ä½æ•°å­—
        
        å¤„ç†ä»¥ä¸‹æ ¼å¼ï¼š
        - 000001.SZ -> 000001
        - 000001.SH -> 000001
        - 600001.SS -> 600001
        - 000001 -> 000001
        - 600001 -> 600001
        
        Args:
            code: åŸå§‹è‚¡ç¥¨ä»£ç 
        
        Returns:
            str: æ ‡å‡†åŒ–åçš„6ä½è‚¡ç¥¨ä»£ç ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        if not code:
            return ""
        
        code_str = str(code).strip()
        
        # å¦‚æœåŒ…å«ç‚¹å·ï¼Œæå–ç‚¹å·å‰çš„éƒ¨åˆ†
        if "." in code_str:
            code_str = code_str.split(".")[0]
        
        # æå–æ‰€æœ‰æ•°å­—å­—ç¬¦
        code_digits = ''.join(filter(str.isdigit, code_str))
        
        if not code_digits:
            return ""
        
        # å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œè¡¥é½åˆ°6ä½
        if code_digits.isdigit():
            # ç§»é™¤å‰å¯¼0ï¼Œç„¶åè¡¥é½åˆ°6ä½
            code_clean = code_digits.lstrip('0') or '0'
            return code_clean.zfill(6)
        
        return ""
    
    async def _get_latest_trade_date(self) -> str:
        """è·å–æœ€æ–°äº¤æ˜“æ—¥"""
        try:
            # ä½¿ç”¨Tushare APIè·å–äº¤æ˜“æ—¥å†
            await self.rate_limiter.acquire()
            cal_df = await asyncio.to_thread(
                self.provider.api.trade_cal,
                exchange='SSE',
                start_date=(datetime.now() - timedelta(days=30)).strftime('%Y%m%d'),
                end_date=datetime.now().strftime('%Y%m%d'),
                is_open=1
            )
            
            if cal_df is not None and not cal_df.empty:
                # è·å–æœ€åä¸€ä¸ªäº¤æ˜“æ—¥
                latest_date = cal_df.iloc[-1]['cal_date']
                return str(latest_date)
            
            # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨æ˜¨å¤©ä½œä¸ºé»˜è®¤å€¼
            yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
            logger.warning(f"âš ï¸ æ— æ³•è·å–æœ€æ–°äº¤æ˜“æ—¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {yesterday}")
            return yesterday
            
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–æœ€æ–°äº¤æ˜“æ—¥å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
            return yesterday


# å•ä¾‹æ¨¡å¼
_kpl_sync_service: Optional[KPLSyncService] = None


async def get_kpl_sync_service() -> KPLSyncService:
    """è·å–å¼€ç›˜å•¦åŒæ­¥æœåŠ¡å•ä¾‹"""
    global _kpl_sync_service
    if _kpl_sync_service is None:
        _kpl_sync_service = KPLSyncService()
        await _kpl_sync_service.initialize()
    return _kpl_sync_service

