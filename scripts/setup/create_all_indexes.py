#!/usr/bin/env python3
"""
åˆ›å»ºæ‰€æœ‰ä¸»è¦é›†åˆçš„ç´¢å¼•
ä¸ºä»¥ä¸‹é›†åˆåˆ›å»ºä¼˜åŒ–ç´¢å¼•ï¼š
  - stock_daily_quotes: å†å²Kçº¿æ•°æ®ï¼ˆ12ä¸ªç´¢å¼•ï¼‰
  - market_quotes: å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆ3ä¸ªç´¢å¼•ï¼‰
  - stock_basic_info: è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆ12ä¸ªç´¢å¼•ï¼‰
  - stock_news: è‚¡ç¥¨æ–°é—»æ•°æ®ï¼ˆ7ä¸ªç´¢å¼•ï¼‰
  - stock_financial_data: è´¢åŠ¡æ•°æ®ï¼ˆ10ä¸ªç´¢å¼•ï¼‰
  - scheduler_history: è°ƒåº¦å™¨å†å²ï¼ˆ3ä¸ªç´¢å¼•ï¼‰
  - scheduler_metadata: è°ƒåº¦å™¨å…ƒæ•°æ®ï¼ˆ1ä¸ªç´¢å¼•ï¼‰

ç”¨æ³•ï¼š
  python scripts/setup/create_all_indexes.py

æ³¨æ„ï¼šæ­¤è„šæœ¬ä»…åˆ›å»ºç´¢å¼•ï¼Œä¸ä¼šåˆ é™¤å·²æœ‰ç´¢å¼•ã€‚å¦‚æœç´¢å¼•å·²å­˜åœ¨ï¼Œä¼šè·³è¿‡åˆ›å»ºã€‚
"""

import os
import sys
import logging
from pymongo import MongoClient, ASCENDING, DESCENDING
from pymongo.errors import OperationFailure

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.insert(0, project_root)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def build_mongo_uri():
    """æ„å»ºMongoDBè¿æ¥URI"""
    host = os.getenv("MONGODB_HOST", "localhost")
    port = int(os.getenv("MONGODB_PORT", "27017"))
    db = os.getenv("MONGODB_DATABASE", "tradingagents")
    user = os.getenv("MONGODB_USERNAME", "")
    pwd = os.getenv("MONGODB_PASSWORD", "")
    auth_src = os.getenv("MONGODB_AUTH_SOURCE", "admin")
    
    if user and pwd:
        return f"mongodb://{user}:{pwd}@{host}:{port}/{db}?authSource={auth_src}"
    return f"mongodb://{host}:{port}/{db}"


def create_index_safe(collection, index_spec, name=None, unique=False, sparse=False, background=True):
    """
    å®‰å…¨åˆ›å»ºç´¢å¼•ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡ï¼‰
    
    Args:
        collection: MongoDBé›†åˆå¯¹è±¡
        index_spec: ç´¢å¼•è§„èŒƒï¼Œå¦‚ [("field", 1)]
        name: ç´¢å¼•åç§°
        unique: æ˜¯å¦å”¯ä¸€ç´¢å¼•
        sparse: æ˜¯å¦ç¨€ç–ç´¢å¼•
        background: æ˜¯å¦åå°åˆ›å»º
    """
    try:
        collection.create_index(
            index_spec,
            unique=unique,
            sparse=sparse,
            background=background,
            name=name
        )
        logger.info(f"âœ… åˆ›å»ºç´¢å¼•: {name or str(index_spec)}")
        return True
    except OperationFailure as e:
        if "already exists" in str(e) or "duplicate key" in str(e).lower():
            logger.info(f"âš ï¸ ç´¢å¼•å·²å­˜åœ¨ï¼Œè·³è¿‡: {name or str(index_spec)}")
            return True
        else:
            logger.error(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥ {name or str(index_spec)}: {e}")
            return False
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥ {name or str(index_spec)}: {e}")
        return False


def create_stock_daily_quotes_indexes(db):
    """åˆ›å»º stock_daily_quotes é›†åˆç´¢å¼•"""
    logger.info("\nğŸ“Š åˆ›å»º stock_daily_quotes é›†åˆç´¢å¼•...")
    collection = db.stock_daily_quotes
    
    indexes_created = 0
    
    # 1. å¤åˆå”¯ä¸€ç´¢å¼•ï¼šè‚¡ç¥¨ä»£ç +äº¤æ˜“æ—¥æœŸ+æ•°æ®æº+å‘¨æœŸï¼ˆä¸»é”®ç´¢å¼•ï¼‰
    if create_index_safe(
        collection,
        [("symbol", ASCENDING), ("trade_date", ASCENDING), ("data_source", ASCENDING), ("period", ASCENDING)],
        name="symbol_date_source_period_unique",
        unique=True
    ):
        indexes_created += 1
    
    # 2. è‚¡ç¥¨ä»£ç ç´¢å¼•ï¼ˆæŸ¥è¯¢å•åªè‚¡ç¥¨çš„å†å²æ•°æ®ï¼‰
    if create_index_safe(
        collection,
        [("symbol", ASCENDING)],
        name="symbol_index"
    ):
        indexes_created += 1
    
    # 3. äº¤æ˜“æ—¥æœŸç´¢å¼•ï¼ˆæŒ‰æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼Œé™åºï¼‰
    if create_index_safe(
        collection,
        [("trade_date", DESCENDING)],
        name="trade_date_index"
    ):
        indexes_created += 1
    
    # 4. æ•°æ®æºç´¢å¼•ï¼ˆæŒ‰æ•°æ®æºæŸ¥è¯¢ï¼‰
    if create_index_safe(
        collection,
        [("data_source", ASCENDING)],
        name="data_source_index"
    ):
        indexes_created += 1
    
    # 5. å¤åˆç´¢å¼•ï¼šè‚¡ç¥¨ä»£ç +äº¤æ˜“æ—¥æœŸï¼ˆå¸¸ç”¨æŸ¥è¯¢ï¼‰
    if create_index_safe(
        collection,
        [("symbol", ASCENDING), ("trade_date", DESCENDING)],
        name="symbol_date_index"
    ):
        indexes_created += 1
    
    # 6. å¸‚åœºç±»å‹ç´¢å¼•
    if create_index_safe(
        collection,
        [("market", ASCENDING)],
        name="market_index"
    ):
        indexes_created += 1
    
    # 7. æ›´æ–°æ—¶é—´ç´¢å¼•ï¼ˆæ•°æ®ç»´æŠ¤ï¼‰
    if create_index_safe(
        collection,
        [("updated_at", DESCENDING)],
        name="updated_at_index"
    ):
        indexes_created += 1
    
    # 8. å¤åˆç´¢å¼•ï¼šå¸‚åœº+äº¤æ˜“æ—¥æœŸï¼ˆå¸‚åœºçº§åˆ«æŸ¥è¯¢ï¼‰
    if create_index_safe(
        collection,
        [("market", ASCENDING), ("trade_date", DESCENDING)],
        name="market_date_index"
    ):
        indexes_created += 1
    
    # 9. å¤åˆç´¢å¼•ï¼šæ•°æ®æº+æ›´æ–°æ—¶é—´ï¼ˆæ•°æ®åŒæ­¥ç›‘æ§ï¼‰
    if create_index_safe(
        collection,
        [("data_source", ASCENDING), ("updated_at", DESCENDING)],
        name="source_updated_index"
    ):
        indexes_created += 1
    
    # 10. ç¨€ç–ç´¢å¼•ï¼šæˆäº¤é‡ï¼ˆç”¨äºç­›é€‰æ´»è·ƒè‚¡ç¥¨ï¼‰
    if create_index_safe(
        collection,
        [("volume", DESCENDING)],
        name="volume_index",
        sparse=True
    ):
        indexes_created += 1
    
    # 11. å‘¨æœŸç´¢å¼•ï¼ˆç”¨äºæŒ‰å‘¨æœŸæŸ¥è¯¢ï¼‰
    if create_index_safe(
        collection,
        [("period", ASCENDING)],
        name="period_index"
    ):
        indexes_created += 1
    
    # 12. å¤åˆç´¢å¼•ï¼šè‚¡ç¥¨+å‘¨æœŸ+æ—¥æœŸï¼ˆå¸¸ç”¨æŸ¥è¯¢ï¼‰
    if create_index_safe(
        collection,
        [("symbol", ASCENDING), ("period", ASCENDING), ("trade_date", DESCENDING)],
        name="symbol_period_date_index"
    ):
        indexes_created += 1
    
    logger.info(f"âœ… stock_daily_quotes ç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå…± {indexes_created} ä¸ªç´¢å¼•")
    return indexes_created


def create_market_quotes_indexes(db):
    """åˆ›å»º market_quotes é›†åˆç´¢å¼•"""
    logger.info("\nğŸ“Š åˆ›å»º market_quotes é›†åˆç´¢å¼•...")
    collection = db.market_quotes
    
    indexes_created = 0
    
    # 1. å”¯ä¸€ç´¢å¼•ï¼šè‚¡ç¥¨ä»£ç ï¼ˆä¸»é”®ï¼‰
    if create_index_safe(
        collection,
        [("code", ASCENDING)],
        name="code_unique",
        unique=True
    ):
        indexes_created += 1
    
    # 2. æ›´æ–°æ—¶é—´ç´¢å¼•ï¼ˆç”¨äºæŸ¥è¯¢æœ€æ–°æ•°æ®ï¼‰
    if create_index_safe(
        collection,
        [("updated_at", DESCENDING)],
        name="updated_at_index"
    ):
        indexes_created += 1
    
    # 3. äº¤æ˜“æ—¥æœŸç´¢å¼•
    if create_index_safe(
        collection,
        [("trade_date", DESCENDING)],
        name="trade_date_index"
    ):
        indexes_created += 1
    
    logger.info(f"âœ… market_quotes ç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå…± {indexes_created} ä¸ªç´¢å¼•")
    return indexes_created


def create_stock_basic_info_indexes(db):
    """åˆ›å»º stock_basic_info é›†åˆç´¢å¼•"""
    logger.info("\nğŸ“Š åˆ›å»º stock_basic_info é›†åˆç´¢å¼•...")
    collection = db.stock_basic_info
    
    indexes_created = 0
    
    # 1. è”åˆå”¯ä¸€ç´¢å¼•ï¼š(code, source) - å…è®¸åŒä¸€è‚¡ç¥¨æœ‰å¤šä¸ªæ•°æ®æº
    if create_index_safe(
        collection,
        [("code", ASCENDING), ("source", ASCENDING)],
        name="uniq_code_source",
        unique=True
    ):
        indexes_created += 1
    
    # 2. è‚¡ç¥¨ä»£ç ç´¢å¼•ï¼ˆéå”¯ä¸€ï¼Œç”¨äºæŸ¥è¯¢æ‰€æœ‰æ•°æ®æºï¼‰
    if create_index_safe(
        collection,
        [("code", ASCENDING)],
        name="idx_code"
    ):
        indexes_created += 1
    
    # 3. æ•°æ®æºç´¢å¼•
    if create_index_safe(
        collection,
        [("source", ASCENDING)],
        name="idx_source"
    ):
        indexes_created += 1
    
    # 4. è‚¡ç¥¨åç§°ç´¢å¼•
    if create_index_safe(
        collection,
        [("name", ASCENDING)],
        name="idx_name"
    ):
        indexes_created += 1
    
    # 5. è¡Œä¸šç´¢å¼•
    if create_index_safe(
        collection,
        [("industry", ASCENDING)],
        name="idx_industry"
    ):
        indexes_created += 1
    
    # 6. å¸‚åœºç´¢å¼•
    if create_index_safe(
        collection,
        [("market", ASCENDING)],
        name="idx_market"
    ):
        indexes_created += 1
    
    # 7. æ€»å¸‚å€¼ç´¢å¼•ï¼ˆé™åºï¼Œä¾¿äºæ’åºï¼‰
    if create_index_safe(
        collection,
        [("total_mv", DESCENDING)],
        name="idx_total_mv_desc"
    ):
        indexes_created += 1
    
    # 8. æµé€šå¸‚å€¼ç´¢å¼•ï¼ˆé™åºï¼‰
    if create_index_safe(
        collection,
        [("circ_mv", DESCENDING)],
        name="idx_circ_mv_desc"
    ):
        indexes_created += 1
    
    # 9. æ›´æ–°æ—¶é—´ç´¢å¼•ï¼ˆé™åºï¼‰
    if create_index_safe(
        collection,
        [("updated_at", DESCENDING)],
        name="idx_updated_at_desc"
    ):
        indexes_created += 1
    
    # 10. PE ç´¢å¼•
    if create_index_safe(
        collection,
        [("pe", ASCENDING)],
        name="idx_pe"
    ):
        indexes_created += 1
    
    # 11. PB ç´¢å¼•
    if create_index_safe(
        collection,
        [("pb", ASCENDING)],
        name="idx_pb"
    ):
        indexes_created += 1
    
    # 12. æ¢æ‰‹ç‡ç´¢å¼•ï¼ˆé™åºï¼‰
    if create_index_safe(
        collection,
        [("turnover_rate", DESCENDING)],
        name="idx_turnover_rate_desc"
    ):
        indexes_created += 1
    
    logger.info(f"âœ… stock_basic_info ç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå…± {indexes_created} ä¸ªç´¢å¼•")
    return indexes_created


def create_stock_news_indexes(db):
    """åˆ›å»º stock_news é›†åˆç´¢å¼•"""
    logger.info("\nğŸ“Š åˆ›å»º stock_news é›†åˆç´¢å¼•...")
    collection = db.stock_news
    
    indexes_created = 0
    
    # 1. å”¯ä¸€ç´¢å¼•ï¼šURL+æ ‡é¢˜+å‘å¸ƒæ—¶é—´ï¼ˆé˜²æ­¢é‡å¤æ–°é—»ï¼‰
    if create_index_safe(
        collection,
        [("url", ASCENDING), ("title", ASCENDING), ("publish_time", ASCENDING)],
        name="url_title_time_unique",
        unique=True
    ):
        indexes_created += 1
    
    # 2. è‚¡ç¥¨ä»£ç ç´¢å¼•
    if create_index_safe(
        collection,
        [("symbol", ASCENDING)],
        name="symbol_index"
    ):
        indexes_created += 1
    
    # 3. å¤šè‚¡ç¥¨ä»£ç ç´¢å¼•
    if create_index_safe(
        collection,
        [("symbols", ASCENDING)],
        name="symbols_index"
    ):
        indexes_created += 1
    
    # 4. å‘å¸ƒæ—¶é—´ç´¢å¼•ï¼ˆé™åºï¼Œç”¨äºæ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼‰
    if create_index_safe(
        collection,
        [("publish_time", DESCENDING)],
        name="publish_time_desc"
    ):
        indexes_created += 1
    
    # 5. å¤åˆç´¢å¼•ï¼šè‚¡ç¥¨+æ—¶é—´ï¼ˆæœ€å¸¸ç”¨æŸ¥è¯¢ï¼‰
    if create_index_safe(
        collection,
        [("symbol", ASCENDING), ("publish_time", DESCENDING)],
        name="symbol_time_desc"
    ):
        indexes_created += 1
    
    # 6. å¤åˆç´¢å¼•ï¼šå¤šè‚¡ç¥¨+æ—¶é—´
    if create_index_safe(
        collection,
        [("symbols", ASCENDING), ("publish_time", DESCENDING)],
        name="symbols_time_desc"
    ):
        indexes_created += 1
    
    # 7. æ•°æ®æºç´¢å¼•
    if create_index_safe(
        collection,
        [("data_source", ASCENDING)],
        name="data_source_index"
    ):
        indexes_created += 1
    
    logger.info(f"âœ… stock_news ç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå…± {indexes_created} ä¸ªç´¢å¼•")
    return indexes_created


def create_stock_financial_data_indexes(db):
    """åˆ›å»º stock_financial_data é›†åˆç´¢å¼•"""
    logger.info("\nğŸ“Š åˆ›å»º stock_financial_data é›†åˆç´¢å¼•...")
    collection = db.stock_financial_data
    
    indexes_created = 0
    
    # 1. å”¯ä¸€ç´¢å¼•ï¼šsymbol + report_period + data_sourceï¼ˆä¸»é”®ç´¢å¼•ï¼‰
    if create_index_safe(
        collection,
        [("symbol", ASCENDING), ("report_period", DESCENDING), ("data_source", ASCENDING)],
        name="symbol_period_source_unique",
        unique=True
    ):
        indexes_created += 1
    
    # 2. å¤åˆç´¢å¼•ï¼šfull_symbol + report_period
    if create_index_safe(
        collection,
        [("full_symbol", ASCENDING), ("report_period", DESCENDING)],
        name="full_symbol_period"
    ):
        indexes_created += 1
    
    # 3. å¤åˆç´¢å¼•ï¼šmarket + report_period
    if create_index_safe(
        collection,
        [("market", ASCENDING), ("report_period", DESCENDING)],
        name="market_period"
    ):
        indexes_created += 1
    
    # 4. æŠ¥å‘ŠæœŸç´¢å¼•ï¼ˆé™åºï¼‰
    if create_index_safe(
        collection,
        [("report_period", DESCENDING)],
        name="report_period_desc"
    ):
        indexes_created += 1
    
    # 5. å…¬å‘Šæ—¥æœŸç´¢å¼•ï¼ˆé™åºï¼‰
    if create_index_safe(
        collection,
        [("ann_date", DESCENDING)],
        name="ann_date_desc"
    ):
        indexes_created += 1
    
    # 6. æ•°æ®æºç´¢å¼•
    if create_index_safe(
        collection,
        [("data_source", ASCENDING)],
        name="data_source"
    ):
        indexes_created += 1
    
    # 7. æŠ¥å‘Šç±»å‹ç´¢å¼•
    if create_index_safe(
        collection,
        [("report_type", ASCENDING)],
        name="report_type"
    ):
        indexes_created += 1
    
    # 8. æ›´æ–°æ—¶é—´ç´¢å¼•ï¼ˆé™åºï¼‰
    if create_index_safe(
        collection,
        [("updated_at", DESCENDING)],
        name="updated_at_desc"
    ):
        indexes_created += 1
    
    # 9. å¤åˆç´¢å¼•ï¼šsymbol + report_type + report_period
    if create_index_safe(
        collection,
        [("symbol", ASCENDING), ("report_type", ASCENDING), ("report_period", DESCENDING)],
        name="symbol_type_period"
    ):
        indexes_created += 1
    
    # 10. å¤åˆç´¢å¼•ï¼šsymbol + report_periodï¼ˆç”¨äºè·¨æ•°æ®æºå¯¹æ¯”ï¼‰
    if create_index_safe(
        collection,
        [("symbol", ASCENDING), ("report_period", DESCENDING)],
        name="symbol_period_compare"
    ):
        indexes_created += 1
    
    logger.info(f"âœ… stock_financial_data ç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå…± {indexes_created} ä¸ªç´¢å¼•")
    return indexes_created


def create_scheduler_indexes(db):
    """åˆ›å»ºè°ƒåº¦å™¨ç›¸å…³é›†åˆç´¢å¼•"""
    logger.info("\nğŸ“Š åˆ›å»ºè°ƒåº¦å™¨ç›¸å…³é›†åˆç´¢å¼•...")
    
    indexes_created = 0
    
    # scheduler_history ç´¢å¼•
    history_collection = db.scheduler_history
    if create_index_safe(
        history_collection,
        [("job_id", ASCENDING)],
        name="job_id_index"
    ):
        indexes_created += 1
    
    if create_index_safe(
        history_collection,
        [("execution_time", DESCENDING)],
        name="execution_time_index"
    ):
        indexes_created += 1
    
    if create_index_safe(
        history_collection,
        [("status", ASCENDING)],
        name="status_index"
    ):
        indexes_created += 1
    
    # scheduler_metadata ç´¢å¼•
    metadata_collection = db.scheduler_metadata
    if create_index_safe(
        metadata_collection,
        [("job_id", ASCENDING)],
        name="job_id_unique",
        unique=True
    ):
        indexes_created += 1
    
    logger.info(f"âœ… è°ƒåº¦å™¨ç›¸å…³é›†åˆç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå…± {indexes_created} ä¸ªç´¢å¼•")
    return indexes_created


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹åˆ›å»ºæ‰€æœ‰é›†åˆç´¢å¼•...")
    logger.info("=" * 60)
    
    try:
        # è¿æ¥MongoDB
        uri = build_mongo_uri()
        client = MongoClient(uri)
        dbname = os.getenv("MONGODB_DATABASE", "tradingagents")
        db = client[dbname]
        
        # æµ‹è¯•è¿æ¥
        try:
            client.admin.command('ping')
            logger.info(f"âœ… MongoDBè¿æ¥æˆåŠŸ: {dbname}")
        except Exception as e:
            logger.error(f"âŒ MongoDBè¿æ¥å¤±è´¥: {e}")
            return False
        
        total_indexes = 0
        
        # åˆ›å»ºå„é›†åˆç´¢å¼•
        total_indexes += create_stock_daily_quotes_indexes(db)
        total_indexes += create_market_quotes_indexes(db)
        total_indexes += create_stock_basic_info_indexes(db)
        total_indexes += create_stock_news_indexes(db)
        total_indexes += create_stock_financial_data_indexes(db)
        total_indexes += create_scheduler_indexes(db)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        logger.info("\n" + "=" * 60)
        logger.info(f"ğŸ“Š ç´¢å¼•åˆ›å»ºç»Ÿè®¡:")
        logger.info(f"  - æ€»ç´¢å¼•æ•°: {total_indexes}")
        
        # æ˜¾ç¤ºå„é›†åˆçš„ç´¢å¼•åˆ—è¡¨
        collections = [
            "stock_daily_quotes",
            "market_quotes",
            "stock_basic_info",
            "stock_news",
            "stock_financial_data",
            "scheduler_history",
            "scheduler_metadata"
        ]
        
        logger.info("\nğŸ“‹ å„é›†åˆç´¢å¼•è¯¦æƒ…:")
        for coll_name in collections:
            try:
                collection = db[coll_name]
                indexes = list(collection.list_indexes())
                logger.info(f"\n  {coll_name}:")
                for idx in indexes:
                    idx_name = idx.get('name', 'N/A')
                    idx_key = idx.get('key', {})
                    idx_unique = idx.get('unique', False)
                    unique_str = " (å”¯ä¸€)" if idx_unique else ""
                    logger.info(f"    - {idx_name}: {idx_key}{unique_str}")
            except Exception as e:
                logger.warning(f"  âš ï¸ æ— æ³•è·å– {coll_name} çš„ç´¢å¼•ä¿¡æ¯: {e}")
        
        logger.info("\nğŸ‰ æ‰€æœ‰ç´¢å¼•åˆ›å»ºå®Œæˆï¼")
        client.close()
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

