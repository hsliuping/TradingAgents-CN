#!/usr/bin/env python3
"""
ç¼“å­˜ç®¡ç†Webç»„ä»¶
æä¾›åˆ†æç»“æœç¼“å­˜çš„æŸ¥çœ‹ã€ç®¡ç†åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
from datetime import date, datetime, timedelta
from typing import List, Dict, Any

from tradingagents.utils.logging_manager import get_logger
logger = get_logger('cache_management')

try:
    from tradingagents.utils.analysis_cache import get_global_cache, cache_analysis_result, load_cached_analysis, is_analysis_cached
    CACHE_AVAILABLE = True
except ImportError as e:
    logger.warning(f"âš ï¸ ç¼“å­˜æ¨¡å—æœªåŠ è½½: {e}")
    CACHE_AVAILABLE = False


def render_cache_management():
    """æ¸²æŸ“ç¼“å­˜ç®¡ç†ç•Œé¢"""
    st.markdown("### ğŸ“¦ åˆ†æç»“æœç¼“å­˜ç®¡ç†")
    
    if not CACHE_AVAILABLE:
        st.error("ğŸš« ç¼“å­˜ç³»ç»Ÿæœªå°±ç»ª")
        st.info("è¯·ç¡®ä¿ç¼“å­˜æ¨¡å—æ­£ç¡®å®‰è£…")
        return
    
    cache = get_global_cache()
    
    # è·å–ç¼“å­˜ç»Ÿè®¡
    stats = cache.get_cache_stats()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ€»ç¼“å­˜æ•°", stats.get('total_files', 0))
    
    with col2:
        st.metric("ç¼“å­˜å¤§å°", f"{stats.get('total_size_mb', 0)} MB")
    
    with col3:
        st.metric("è‚¡ç¥¨æ•°é‡", stats.get('symbol_count', 0))
    
    with col4:
        cache_dir = stats.get('cache_directory', 'unknown')
        st.metric("ç¼“å­˜ç›®å½•", "å·²é…ç½®" if cache_dir != 'unknown' else "æœªé…ç½®")
    
    st.markdown("---")
    
    # ç¼“å­˜åˆ—è¡¨
    st.markdown("#### ğŸ“‹ ç¼“å­˜åˆ—è¡¨")
    
    cached_list = cache.list_cached_analyses()
    
    if not cached_list:
        st.info("ğŸ“­ æš‚æ— ç¼“å­˜æ•°æ®")
        return
    
    # è½¬æ¢ä¸ºDataFrame
    df_data = []
    for item in cached_list:
        df_data.append({
            'è‚¡ç¥¨ä»£ç ': item['symbol'],
            'åˆ†ææ—¥æœŸ': item['date'],
            'æ–‡ä»¶å¤§å°': f"{item['file_size'] / 1024:.1f} KB",
            'ä¿®æ”¹æ—¶é—´': datetime.fromisoformat(item['modified_time']).strftime('%Y-%m-%d %H:%M'),
            'ç¼“å­˜é”®': item['cache_key']
        })
    
    df = pd.DataFrame(df_data)
    
    # ç­›é€‰é€‰é¡¹
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # è‚¡ç¥¨ä»£ç ç­›é€‰
        symbols = ['å…¨éƒ¨'] + sorted(list(set([item['symbol'] for item in cached_list])))
        selected_symbol = st.selectbox("ç­›é€‰è‚¡ç¥¨ä»£ç ", symbols)
    
    with col2:
        # æ—¥æœŸèŒƒå›´ç­›é€‰
        date_range = st.date_input(
            "ç­›é€‰æ—¥æœŸèŒƒå›´",
            value=(date.today() - timedelta(days=30), date.today()),
            max_value=date.today()
        )
    
    # åº”ç”¨ç­›é€‰
    filtered_df = df.copy()
    
    if selected_symbol != 'å…¨éƒ¨':
        filtered_df = filtered_df[filtered_df['è‚¡ç¥¨ä»£ç '] == selected_symbol]
    
    if len(date_range) == 2:
        start_date, end_date = date_range
        filtered_df = filtered_df[
            (pd.to_datetime(filtered_df['åˆ†ææ—¥æœŸ']) >= pd.Timestamp(start_date)) &
            (pd.to_datetime(filtered_df['åˆ†ææ—¥æœŸ']) <= pd.Timestamp(end_date))
        ]
    
    # æ˜¾ç¤ºç­›é€‰åçš„æ•°æ®
    st.dataframe(
        filtered_df,
        use_container_width=True,
        hide_index=True
    )
    
    # ç¼“å­˜æ“ä½œ
    st.markdown("#### ğŸ”§ ç¼“å­˜æ“ä½œ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**æŸ¥çœ‹ç¼“å­˜**")
        if st.button("ğŸ” æŸ¥çœ‹é€‰ä¸­ç¼“å­˜"):
            if not filtered_df.empty:
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç¼“å­˜çš„è¯¦ç»†ä¿¡æ¯
                first_item = filtered_df.iloc[0]
                symbol = first_item['è‚¡ç¥¨ä»£ç ']
                analysis_date = first_item['åˆ†ææ—¥æœŸ']
                
                cached_data = cache.load_analysis(symbol, analysis_date)
                if cached_data:
                    st.json(cached_data)
                else:
                    st.error("æ— æ³•åŠ è½½ç¼“å­˜æ•°æ®")
            else:
                st.warning("æ²¡æœ‰å¯æŸ¥çœ‹çš„ç¼“å­˜")
    
    with col2:
        st.markdown("**æ‰‹åŠ¨ç¼“å­˜**")
        manual_symbol = st.text_input("è‚¡ç¥¨ä»£ç ", placeholder="ä¾‹å¦‚: 920005")
        if st.button("ğŸ’¾ æ‰‹åŠ¨åˆ›å»ºç¼“å­˜"):
            if manual_symbol:
                # åˆ›å»ºç®€å•çš„æµ‹è¯•ç¼“å­˜
                test_data = {
                    'type': 'manual_test',
                    'symbol': manual_symbol,
                    'created_time': datetime.now().isoformat(),
                    'note': 'æ‰‹åŠ¨åˆ›å»ºçš„æµ‹è¯•ç¼“å­˜'
                }
                
                success = cache.save_analysis(manual_symbol, test_data)
                if success:
                    st.success(f"âœ… å·²ä¸º {manual_symbol} åˆ›å»ºæµ‹è¯•ç¼“å­˜")
                    st.rerun()
                else:
                    st.error("åˆ›å»ºç¼“å­˜å¤±è´¥")
            else:
                st.warning("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ")
    
    with col3:
        st.markdown("**ç¼“å­˜æ¸…ç†**")
        if st.button("ğŸ—‘ï¸ æ¸…ç†æ—§ç¼“å­˜", help="æ¸…ç†30å¤©å‰çš„ç¼“å­˜"):
            # æ³¨æ„ï¼šåœ¨å¼€å‘é˜¶æ®µï¼Œæˆ‘ä»¬ä¸æ¸…ç†ç¼“å­˜
            st.warning("å¼€å‘é˜¶æ®µç¼“å­˜è®¾ä¸ºæ°¸ä¹…ä¿å­˜")
            # deleted_count = cache.cleanup_old_cache(30)
            # st.success(f"å·²æ¸…ç† {deleted_count} ä¸ªæ—§ç¼“å­˜æ–‡ä»¶")
    
    # æŒ‰è‚¡ç¥¨ç»Ÿè®¡
    st.markdown("#### ğŸ“Š æŒ‰è‚¡ç¥¨ç»Ÿè®¡")
    
    symbol_stats = stats.get('symbol_stats', {})
    if symbol_stats:
        stat_data = []
        for symbol, count in symbol_stats.items():
            stat_data.append({
                'è‚¡ç¥¨ä»£ç ': symbol,
                'ç¼“å­˜æ•°é‡': count
            })
        
        stat_df = pd.DataFrame(stat_data)
        stat_df = stat_df.sort_values('ç¼“å­˜æ•°é‡', ascending=False)
        
        st.dataframe(stat_df, use_container_width=True, hide_index=True)
        
        # å›¾è¡¨æ˜¾ç¤º
        if len(stat_df) > 0:
            st.bar_chart(stat_df.set_index('è‚¡ç¥¨ä»£ç ')['ç¼“å­˜æ•°é‡'])


def check_and_suggest_cache(symbol: str, analysis_date: str = None) -> bool:
    """
    æ£€æŸ¥å¹¶å»ºè®®ä½¿ç”¨ç¼“å­˜
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        
    Returns:
        bool: æ˜¯å¦å­˜åœ¨ç¼“å­˜
    """
    if not CACHE_AVAILABLE:
        return False
    
    if is_analysis_cached(symbol, analysis_date):
        st.info(f"ğŸ’¡ æ£€æµ‹åˆ° {symbol} çš„ç¼“å­˜æ•°æ®ï¼Œå¯ä»¥ç›´æ¥åŠ è½½ä»¥èŠ‚çœæ—¶é—´")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“¦ åŠ è½½ç¼“å­˜"):
                return True
        with col2:
            if st.button("ğŸ”„ é‡æ–°åˆ†æ"):
                return False
        
        return True
    
    return False


def auto_cache_analysis_result(symbol: str, analysis_data: Dict[str, Any], analysis_date: str = None) -> bool:
    """
    è‡ªåŠ¨ç¼“å­˜åˆ†æç»“æœ
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        analysis_data: åˆ†ææ•°æ®
        analysis_date: åˆ†ææ—¥æœŸ
        
    Returns:
        bool: æ˜¯å¦ç¼“å­˜æˆåŠŸ
    """
    if not CACHE_AVAILABLE:
        logger.warning("ç¼“å­˜ç³»ç»Ÿä¸å¯ç”¨ï¼Œè·³è¿‡è‡ªåŠ¨ç¼“å­˜")
        return False
    
    try:
        success = cache_analysis_result(symbol, analysis_data, analysis_date)
        if success:
            logger.info(f"âœ… è‡ªåŠ¨ç¼“å­˜åˆ†æç»“æœ: {symbol}")
            st.success(f"ğŸ“¦ åˆ†æç»“æœå·²è‡ªåŠ¨ç¼“å­˜: {symbol}")
        else:
            logger.error(f"âŒ è‡ªåŠ¨ç¼“å­˜å¤±è´¥: {symbol}")
            st.warning(f"âš ï¸ è‡ªåŠ¨ç¼“å­˜å¤±è´¥: {symbol}")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ è‡ªåŠ¨ç¼“å­˜å¼‚å¸¸: {symbol} - {e}")
        return False


def load_cached_analysis_if_exists(symbol: str, analysis_date: str = None) -> Dict[str, Any]:
    """
    å¦‚æœå­˜åœ¨ç¼“å­˜åˆ™åŠ è½½
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        
    Returns:
        Dict: ç¼“å­˜çš„åˆ†ææ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
    """
    if not CACHE_AVAILABLE:
        return None
    
    try:
        cached_data = load_cached_analysis(symbol, analysis_date)
        if cached_data:
            logger.info(f"ğŸ“¦ å·²åŠ è½½ç¼“å­˜åˆ†æ: {symbol}")
            st.info(f"ğŸ“¦ å·²ä»ç¼“å­˜åŠ è½½ {symbol} çš„åˆ†æç»“æœ")
            return cached_data
        
        return None
        
    except Exception as e:
        logger.error(f"âŒ åŠ è½½ç¼“å­˜å¤±è´¥: {symbol} - {e}")
        return None


def render_cache_info_sidebar():
    """åœ¨ä¾§è¾¹æ æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯"""
    if not CACHE_AVAILABLE:
        return
    
    with st.sidebar:
        st.markdown("### ğŸ“¦ ç¼“å­˜ä¿¡æ¯")
        
        cache = get_global_cache()
        stats = cache.get_cache_stats()
        
        st.metric("æ€»ç¼“å­˜", stats.get('total_files', 0))
        st.metric("ç¼“å­˜å¤§å°", f"{stats.get('total_size_mb', 0):.1f} MB")
        
        # æœ€è¿‘ç¼“å­˜
        recent_cache = cache.list_cached_analyses()[:3]
        if recent_cache:
            st.markdown("**æœ€è¿‘ç¼“å­˜**")
            for item in recent_cache:
                st.write(f"ğŸ“Š {item['symbol']} ({item['date']})")