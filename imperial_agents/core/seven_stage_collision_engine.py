"""
å¸å›½AIä¸ƒé˜¶æ®µå¯¹æ’å†³ç­–å¼•æ“
Phase 4H-H1: æ ¸å¿ƒåŠŸèƒ½æ‰©å±• - å¯¹æ’æœºåˆ¶å®ç°

åˆ›å»ºæ—¶é—´: 2025-08-16
ç‰ˆæœ¬: v1.0
ä½œè€…: å¸å›½AIé¡¹ç›®å›¢é˜Ÿ
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import time
import json
from pathlib import Path

# å¯¼å…¥å¸å›½AIåŸºç¡€ç»„ä»¶
from imperial_agents.core.imperial_agent_wrapper import ImperialAgentWrapper
from imperial_agents.core.collaboration_system import CollaborationSystem


class CollisionStage(Enum):
    """ä¸ƒé˜¶æ®µå¯¹æ’æµç¨‹æšä¸¾"""
    INITIAL_ANALYSIS = "åˆæ­¥åˆ†æ"
    OPINION_COLLECTION = "æ„è§æ”¶é›†"
    COLLISION_DISCUSSION = "å¯¹æ’è®¨è®º"
    DISSENT_HANDLING = "å¼‚è®®å¤„ç†"
    DEEP_ANALYSIS = "æ·±åº¦åˆ†æ"
    COMPREHENSIVE_DECISION = "ç»¼åˆå†³ç­–"
    EXECUTION_CONFIRMATION = "æ‰§è¡Œç¡®è®¤"


@dataclass
class CollisionOpinion:
    """å¯¹æ’æ„è§æ•°æ®ç»“æ„"""
    agent_name: str
    stage: CollisionStage
    opinion: str
    confidence: float
    reasoning: str
    supporting_data: Dict[str, Any] = field(default_factory=dict)
    timestamp: float = field(default_factory=time.time)


@dataclass
class CollisionResult:
    """å¯¹æ’ç»“æœæ•°æ®ç»“æ„"""
    final_decision: str
    confidence_score: float
    consensus_level: float
    dissent_points: List[str]
    execution_plan: Dict[str, Any]
    process_log: List[Dict[str, Any]]
    total_duration: float
    stage_durations: Dict[CollisionStage, float]


class SevenStageCollisionEngine:
    """
    ä¸ƒé˜¶æ®µå¯¹æ’å†³ç­–å¼•æ“
    
    å®ç°å¸å›½ç‰¹è‰²çš„æ™ºèƒ½å†³ç­–å¯¹æ’æœºåˆ¶ï¼Œé€šè¿‡ä¸ƒä¸ªé˜¶æ®µçš„æ·±åº¦åˆ†æå’Œè®¨è®ºï¼Œ
    ç¡®ä¿å†³ç­–çš„ç§‘å­¦æ€§ã€å…¨é¢æ€§å’Œå¯æ‰§è¡Œæ€§ã€‚
    """
    
    def __init__(self, agents: List[ImperialAgentWrapper], config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–å¯¹æ’å¼•æ“
        
        Args:
            agents: å‚ä¸å¯¹æ’çš„æ™ºèƒ½ä½“åˆ—è¡¨
            config: å¼•æ“é…ç½®å‚æ•°
        """
        self.agents = agents
        self.config = config or self._get_default_config()
        self.logger = self._setup_logger()
        self.collaboration_system = CollaborationSystem(agents)
        
        # å¯¹æ’è¿‡ç¨‹çŠ¶æ€
        self.current_stage = None
        self.opinions_history: List[CollisionOpinion] = []
        self.process_log: List[Dict[str, Any]] = []
        self.start_time = None
        
        self.logger.info(f"ä¸ƒé˜¶æ®µå¯¹æ’å¼•æ“åˆå§‹åŒ–å®Œæˆï¼Œå‚ä¸æ™ºèƒ½ä½“: {[a.agent_name for a in agents]}")
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "max_stage_duration": 60.0,  # æ¯é˜¶æ®µæœ€å¤§æ—¶é—´ï¼ˆç§’ï¼‰
            "min_consensus_threshold": 0.7,  # æœ€å°å…±è¯†é˜ˆå€¼
            "max_dissent_rounds": 3,  # æœ€å¤§å¼‚è®®å¤„ç†è½®æ•°
            "confidence_weight": 0.4,  # ç½®ä¿¡åº¦æƒé‡
            "consensus_weight": 0.6,  # å…±è¯†åº¦æƒé‡
            "enable_deep_analysis": True,  # å¯ç”¨æ·±åº¦åˆ†æ
            "save_process_log": True,  # ä¿å­˜è¿‡ç¨‹æ—¥å¿—
        }
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger("CollisionEngine")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    async def run_collision_process(self, task_data: Dict[str, Any]) -> CollisionResult:
        """
        è¿è¡Œå®Œæ•´çš„ä¸ƒé˜¶æ®µå¯¹æ’æµç¨‹
        
        Args:
            task_data: ä»»åŠ¡æ•°æ®ï¼ŒåŒ…å«åˆ†æç›®æ ‡ã€æ•°æ®ç­‰
            
        Returns:
            CollisionResult: å¯¹æ’å†³ç­–ç»“æœ
        """
        self.start_time = time.time()
        self.logger.info(f"å¼€å§‹ä¸ƒé˜¶æ®µå¯¹æ’æµç¨‹ï¼Œä»»åŠ¡: {task_data.get('task_name', 'Unknown')}")
        
        try:
            stage_results = {}
            
            # æ‰§è¡Œä¸ƒä¸ªé˜¶æ®µ
            for stage in CollisionStage:
                self.current_stage = stage
                self.logger.info(f"è¿›å…¥{stage.value}é˜¶æ®µ")
                
                stage_start_time = time.time()
                stage_result = await self._execute_stage(stage, task_data, stage_results)
                stage_duration = time.time() - stage_start_time
                
                stage_results[stage] = {
                    "result": stage_result,
                    "duration": stage_duration
                }
                
                self._log_stage_completion(stage, stage_duration, stage_result)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æå‰ç»ˆæ­¢
                if self._should_terminate_early(stage, stage_result):
                    self.logger.warning(f"åœ¨{stage.value}é˜¶æ®µæå‰ç»ˆæ­¢å¯¹æ’æµç¨‹")
                    break
            
            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            final_result = self._generate_final_result(task_data, stage_results)
            
            total_duration = time.time() - self.start_time
            final_result.total_duration = total_duration
            
            self.logger.info(f"ä¸ƒé˜¶æ®µå¯¹æ’æµç¨‹å®Œæˆï¼Œæ€»è€—æ—¶: {total_duration:.2f}ç§’")
            return final_result
            
        except Exception as e:
            self.logger.error(f"å¯¹æ’æµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}")
            raise
    
    async def _execute_stage(self, stage: CollisionStage, task_data: Dict[str, Any], 
                           previous_results: Dict) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªé˜¶æ®µ
        
        Args:
            stage: å½“å‰é˜¶æ®µ
            task_data: ä»»åŠ¡æ•°æ®
            previous_results: ä¹‹å‰é˜¶æ®µçš„ç»“æœ
            
        Returns:
            Dict: é˜¶æ®µæ‰§è¡Œç»“æœ
        """
        stage_methods = {
            CollisionStage.INITIAL_ANALYSIS: self._stage_initial_analysis,
            CollisionStage.OPINION_COLLECTION: self._stage_opinion_collection,
            CollisionStage.COLLISION_DISCUSSION: self._stage_collision_discussion,
            CollisionStage.DISSENT_HANDLING: self._stage_dissent_handling,
            CollisionStage.DEEP_ANALYSIS: self._stage_deep_analysis,
            CollisionStage.COMPREHENSIVE_DECISION: self._stage_comprehensive_decision,
            CollisionStage.EXECUTION_CONFIRMATION: self._stage_execution_confirmation,
        }
        
        method = stage_methods.get(stage)
        if not method:
            raise ValueError(f"æœªçŸ¥é˜¶æ®µ: {stage}")
        
        return await method(task_data, previous_results)
    
    async def _stage_initial_analysis(self, task_data: Dict[str, Any], 
                                    previous_results: Dict) -> Dict[str, Any]:
        """ç¬¬ä¸€é˜¶æ®µï¼šåˆæ­¥åˆ†æ"""
        self.logger.info("æ‰§è¡Œåˆæ­¥åˆ†æé˜¶æ®µ")
        
        # æ¯ä¸ªæ™ºèƒ½ä½“è¿›è¡Œç‹¬ç«‹çš„åˆæ­¥åˆ†æ
        analysis_tasks = []
        for agent in self.agents:
            analysis_prompt = self._build_initial_analysis_prompt(task_data, agent)
            task = agent.analyze(analysis_prompt)
            analysis_tasks.append(task)
        
        # å¹¶è¡Œæ‰§è¡Œåˆ†æ
        initial_analyses = await asyncio.gather(*analysis_tasks, return_exceptions=True)
        
        # å¤„ç†åˆ†æç»“æœ
        valid_analyses = []
        for i, analysis in enumerate(initial_analyses):
            if isinstance(analysis, Exception):
                self.logger.warning(f"{self.agents[i].agent_name}åˆæ­¥åˆ†æå¤±è´¥: {analysis}")
                continue
            
            opinion = CollisionOpinion(
                agent_name=self.agents[i].agent_name,
                stage=CollisionStage.INITIAL_ANALYSIS,
                opinion=analysis.get('analysis', ''),
                confidence=analysis.get('confidence', 0.5),
                reasoning=analysis.get('reasoning', ''),
                supporting_data=analysis.get('supporting_data', {})
            )
            
            self.opinions_history.append(opinion)
            valid_analyses.append(analysis)
        
        return {
            "analyses": valid_analyses,
            "participant_count": len(valid_analyses),
            "average_confidence": sum(a.get('confidence', 0.5) for a in valid_analyses) / max(len(valid_analyses), 1)
        }
    
    async def _stage_opinion_collection(self, task_data: Dict[str, Any], 
                                      previous_results: Dict) -> Dict[str, Any]:
        """ç¬¬äºŒé˜¶æ®µï¼šæ„è§æ”¶é›†"""
        self.logger.info("æ‰§è¡Œæ„è§æ”¶é›†é˜¶æ®µ")
        
        initial_analyses = previous_results.get(CollisionStage.INITIAL_ANALYSIS, {}).get("analyses", [])
        
        # åŸºäºåˆæ­¥åˆ†æï¼Œæ”¶é›†å„æ™ºèƒ½ä½“çš„è¯¦ç»†æ„è§
        opinion_tasks = []
        for i, agent in enumerate(self.agents):
            if i < len(initial_analyses):
                opinion_prompt = self._build_opinion_collection_prompt(
                    task_data, agent, initial_analyses[i], initial_analyses
                )
                task = agent.analyze(opinion_prompt)
                opinion_tasks.append(task)
        
        detailed_opinions = await asyncio.gather(*opinion_tasks, return_exceptions=True)
        
        # åˆ†ææ„è§åˆ†æ­§ç¨‹åº¦
        valid_opinions = []
        for i, opinion in enumerate(detailed_opinions):
            if isinstance(opinion, Exception):
                continue
            
            opinion_obj = CollisionOpinion(
                agent_name=self.agents[i].agent_name,
                stage=CollisionStage.OPINION_COLLECTION,
                opinion=opinion.get('detailed_opinion', ''),
                confidence=opinion.get('confidence', 0.5),
                reasoning=opinion.get('reasoning', ''),
                supporting_data=opinion.get('supporting_data', {})
            )
            
            self.opinions_history.append(opinion_obj)
            valid_opinions.append(opinion)
        
        # è®¡ç®—æ„è§åˆ†æ­§åº¦
        divergence_score = self._calculate_opinion_divergence(valid_opinions)
        
        return {
            "detailed_opinions": valid_opinions,
            "divergence_score": divergence_score,
            "consensus_areas": self._identify_consensus_areas(valid_opinions),
            "conflict_areas": self._identify_conflict_areas(valid_opinions)
        }
    
    async def _stage_collision_discussion(self, task_data: Dict[str, Any], 
                                        previous_results: Dict) -> Dict[str, Any]:
        """ç¬¬ä¸‰é˜¶æ®µï¼šå¯¹æ’è®¨è®º"""
        self.logger.info("æ‰§è¡Œå¯¹æ’è®¨è®ºé˜¶æ®µ")
        
        opinion_data = previous_results.get(CollisionStage.OPINION_COLLECTION, {})
        conflict_areas = opinion_data.get("conflict_areas", [])
        
        if not conflict_areas:
            self.logger.info("æ— æ˜æ˜¾å†²çªï¼Œè·³è¿‡å¯¹æ’è®¨è®º")
            return {"collision_required": False, "discussions": []}
        
        # é’ˆå¯¹æ¯ä¸ªå†²çªç‚¹è¿›è¡Œå¯¹æ’è®¨è®º
        collision_discussions = []
        for conflict in conflict_areas:
            discussion_result = await self._conduct_collision_discussion(
                task_data, conflict, previous_results
            )
            collision_discussions.append(discussion_result)
        
        return {
            "collision_required": True,
            "discussions": collision_discussions,
            "resolution_count": len([d for d in collision_discussions if d.get("resolved", False)])
        }
    
    async def _stage_dissent_handling(self, task_data: Dict[str, Any], 
                                    previous_results: Dict) -> Dict[str, Any]:
        """ç¬¬å››é˜¶æ®µï¼šå¼‚è®®å¤„ç†"""
        self.logger.info("æ‰§è¡Œå¼‚è®®å¤„ç†é˜¶æ®µ")
        
        collision_data = previous_results.get(CollisionStage.COLLISION_DISCUSSION, {})
        discussions = collision_data.get("discussions", [])
        
        # è¯†åˆ«æœªè§£å†³çš„å¼‚è®®
        unresolved_dissents = [d for d in discussions if not d.get("resolved", False)]
        
        if not unresolved_dissents:
            self.logger.info("æ— æœªè§£å†³å¼‚è®®")
            return {"dissents_handled": True, "resolutions": []}
        
        # å¤„ç†æ¯ä¸ªå¼‚è®®
        dissent_resolutions = []
        for dissent in unresolved_dissents:
            resolution = await self._handle_dissent(task_data, dissent, previous_results)
            dissent_resolutions.append(resolution)
        
        return {
            "dissents_handled": len(dissent_resolutions) > 0,
            "resolutions": dissent_resolutions,
            "remaining_conflicts": len([r for r in dissent_resolutions if not r.get("resolved", False)])
        }
    
    async def _stage_deep_analysis(self, task_data: Dict[str, Any], 
                                 previous_results: Dict) -> Dict[str, Any]:
        """ç¬¬äº”é˜¶æ®µï¼šæ·±åº¦åˆ†æ"""
        self.logger.info("æ‰§è¡Œæ·±åº¦åˆ†æé˜¶æ®µ")
        
        if not self.config.get("enable_deep_analysis", True):
            self.logger.info("æ·±åº¦åˆ†æå·²ç¦ç”¨ï¼Œè·³è¿‡æ­¤é˜¶æ®µ")
            return {"deep_analysis_enabled": False}
        
        # æ±‡æ€»å‰é¢é˜¶æ®µçš„æ‰€æœ‰ä¿¡æ¯
        consolidated_info = self._consolidate_previous_stages(previous_results)
        
        # é€‰æ‹©æœ€æƒå¨çš„æ™ºèƒ½ä½“è¿›è¡Œæ·±åº¦åˆ†æ
        primary_analyst = self._select_primary_analyst(task_data)
        
        # æ‰§è¡Œæ·±åº¦åˆ†æ
        deep_analysis_prompt = self._build_deep_analysis_prompt(
            task_data, consolidated_info, previous_results
        )
        
        deep_analysis_result = await primary_analyst.analyze(deep_analysis_prompt)
        
        return {
            "deep_analysis_enabled": True,
            "primary_analyst": primary_analyst.agent_name,
            "deep_insights": deep_analysis_result.get("insights", []),
            "risk_assessment": deep_analysis_result.get("risk_assessment", {}),
            "opportunity_analysis": deep_analysis_result.get("opportunities", {}),
            "recommendation": deep_analysis_result.get("recommendation", "")
        }
    
    async def _stage_comprehensive_decision(self, task_data: Dict[str, Any], 
                                          previous_results: Dict) -> Dict[str, Any]:
        """ç¬¬å…­é˜¶æ®µï¼šç»¼åˆå†³ç­–"""
        self.logger.info("æ‰§è¡Œç»¼åˆå†³ç­–é˜¶æ®µ")
        
        # æ±‡æ€»æ‰€æœ‰é˜¶æ®µçš„ç»“æœ
        all_opinions = [op for op in self.opinions_history]
        consensus_level = self._calculate_final_consensus(previous_results)
        
        # ç”Ÿæˆç»¼åˆå†³ç­–
        decision_data = {
            "all_opinions": all_opinions,
            "consensus_level": consensus_level,
            "previous_results": previous_results,
            "task_data": task_data
        }
        
        # ä½¿ç”¨åŠ æƒæŠ•ç¥¨æœºåˆ¶ç”Ÿæˆæœ€ç»ˆå†³ç­–
        final_decision = await self._generate_comprehensive_decision(decision_data)
        
        return {
            "final_decision": final_decision.get("decision", ""),
            "confidence_score": final_decision.get("confidence", 0.0),
            "consensus_level": consensus_level,
            "decision_rationale": final_decision.get("rationale", ""),
            "supporting_evidence": final_decision.get("evidence", [])
        }
    
    async def _stage_execution_confirmation(self, task_data: Dict[str, Any], 
                                          previous_results: Dict) -> Dict[str, Any]:
        """ç¬¬ä¸ƒé˜¶æ®µï¼šæ‰§è¡Œç¡®è®¤"""
        self.logger.info("æ‰§è¡Œæ‰§è¡Œç¡®è®¤é˜¶æ®µ")
        
        decision_data = previous_results.get(CollisionStage.COMPREHENSIVE_DECISION, {})
        final_decision = decision_data.get("final_decision", "")
        
        if not final_decision:
            raise ValueError("ç¼ºå°‘ç»¼åˆå†³ç­–ç»“æœ")
        
        # ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        execution_plan = await self._generate_execution_plan(
            final_decision, task_data, previous_results
        )
        
        # æ‰§è¡Œé£é™©è¯„ä¼°
        risk_assessment = await self._conduct_execution_risk_assessment(
            execution_plan, previous_results
        )
        
        # æœ€ç»ˆç¡®è®¤
        confirmation_result = await self._final_execution_confirmation(
            execution_plan, risk_assessment
        )
        
        return {
            "execution_plan": execution_plan,
            "risk_assessment": risk_assessment,
            "confirmed": confirmation_result.get("confirmed", False),
            "execution_steps": execution_plan.get("steps", []),
            "timeline": execution_plan.get("timeline", {}),
            "success_metrics": execution_plan.get("metrics", {})
        }
    
    def _build_initial_analysis_prompt(self, task_data: Dict[str, Any], 
                                     agent: ImperialAgentWrapper) -> str:
        """æ„å»ºåˆæ­¥åˆ†ææç¤º"""
        return f"""
è¯·åŸºäºä½ çš„ä¸“ä¸šçŸ¥è¯†å¯¹ä»¥ä¸‹ä»»åŠ¡è¿›è¡Œåˆæ­¥åˆ†æï¼š

ä»»åŠ¡ä¿¡æ¯ï¼š
{json.dumps(task_data, ensure_ascii=False, indent=2)}

è¯·ä»ä½ çš„ä¸“ä¸šè§’åº¦ï¼ˆ{agent.agent_name}ï¼‰æä¾›ï¼š
1. åˆæ­¥åˆ†æå’Œè§‚ç‚¹
2. å…³é”®é£é™©ç‚¹è¯†åˆ«
3. æœºä¼šç‚¹è¯†åˆ«
4. ä½ çš„å»ºè®®æ–¹å‘
5. åˆ†æç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚
"""
    
    def _build_opinion_collection_prompt(self, task_data: Dict[str, Any], 
                                       agent: ImperialAgentWrapper,
                                       own_analysis: Dict[str, Any],
                                       all_analyses: List[Dict[str, Any]]) -> str:
        """æ„å»ºæ„è§æ”¶é›†æç¤º"""
        return f"""
åŸºäºä½ çš„åˆæ­¥åˆ†æå’Œå…¶ä»–ä¸“å®¶çš„åˆ†æï¼Œè¯·æä¾›æ›´è¯¦ç»†çš„æ„è§ï¼š

ä½ çš„åˆæ­¥åˆ†æï¼š
{json.dumps(own_analysis, ensure_ascii=False, indent=2)}

å…¶ä»–ä¸“å®¶åˆ†æï¼š
{json.dumps(all_analyses, ensure_ascii=False, indent=2)}

è¯·æä¾›ï¼š
1. è¯¦ç»†çš„ä¸“ä¸šæ„è§
2. å¯¹å…¶ä»–ä¸“å®¶è§‚ç‚¹çš„è¯„ä»·
3. ä½ åšæŒçš„æ ¸å¿ƒè§‚ç‚¹
4. å¯èƒ½çš„å¦¥åç©ºé—´
5. æ›´æ–°åçš„ç½®ä¿¡åº¦

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚
"""
    
    def _calculate_opinion_divergence(self, opinions: List[Dict[str, Any]]) -> float:
        """è®¡ç®—æ„è§åˆ†æ­§åº¦"""
        if len(opinions) < 2:
            return 0.0
        
        # ç®€åŒ–çš„åˆ†æ­§åº¦è®¡ç®—é€»è¾‘
        confidences = [op.get('confidence', 0.5) for op in opinions]
        variance = sum((c - sum(confidences)/len(confidences))**2 for c in confidences) / len(confidences)
        
        return min(variance * 2, 1.0)  # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
    
    def _identify_consensus_areas(self, opinions: List[Dict[str, Any]]) -> List[str]:
        """è¯†åˆ«å…±è¯†é¢†åŸŸ"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ç”¨NLPåˆ†ææ„è§ç›¸ä¼¼æ€§
        return ["åŸºæœ¬é¢åˆ†æé‡è¦æ€§", "é£é™©æ§åˆ¶å¿…è¦æ€§"]
    
    def _identify_conflict_areas(self, opinions: List[Dict[str, Any]]) -> List[str]:
        """è¯†åˆ«å†²çªé¢†åŸŸ"""
        # ç®€åŒ–å®ç°
        return ["å¸‚åœºè¶‹åŠ¿åˆ¤æ–­", "æ—¶æœºé€‰æ‹©ç­–ç•¥"]
    
    async def _conduct_collision_discussion(self, task_data: Dict[str, Any], 
                                          conflict: str, previous_results: Dict) -> Dict[str, Any]:
        """è¿›è¡Œå¯¹æ’è®¨è®º"""
        # ç»„ç»‡ç›¸å…³æ™ºèƒ½ä½“è¿›è¡Œé’ˆå¯¹æ€§è®¨è®º
        discussion_prompt = f"""
é’ˆå¯¹å†²çªç‚¹ï¼š{conflict}

è¯·å„è‡ªé˜è¿°è§‚ç‚¹å¹¶å°è¯•å¯»æ‰¾å…±åŒç‚¹æˆ–åˆç†å¦¥åã€‚
åŸºäºå‰æœŸåˆ†æç»“æœï¼š{json.dumps(previous_results, ensure_ascii=False)}

è¯·æä¾›è§£å†³æ–¹æ¡ˆå»ºè®®ã€‚
"""
        
        # ç®€åŒ–å®ç°ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªæ™ºèƒ½ä½“å›ç­”
        if self.agents:
            result = await self.agents[0].analyze(discussion_prompt)
            return {"conflict": conflict, "discussion": result, "resolved": True}
        
        return {"conflict": conflict, "discussion": {}, "resolved": False}
    
    async def _handle_dissent(self, task_data: Dict[str, Any], 
                            dissent: Dict[str, Any], previous_results: Dict) -> Dict[str, Any]:
        """å¤„ç†å¼‚è®®"""
        # å¼‚è®®å¤„ç†é€»è¾‘
        return {"dissent": dissent, "resolution": "é€šè¿‡æ·±åº¦åˆ†æè§£å†³", "resolved": True}
    
    def _consolidate_previous_stages(self, previous_results: Dict) -> Dict[str, Any]:
        """æ±‡æ€»å‰é¢é˜¶æ®µçš„ä¿¡æ¯"""
        return {
            "stage_summaries": {k.value: v for k, v in previous_results.items()},
            "key_insights": [],
            "unresolved_issues": [],
            "consensus_points": []
        }
    
    def _select_primary_analyst(self, task_data: Dict[str, Any]) -> ImperialAgentWrapper:
        """é€‰æ‹©ä¸»è¦åˆ†æå¸ˆ"""
        # ç®€åŒ–ï¼šé€‰æ‹©ç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“
        return self.agents[0] if self.agents else None
    
    def _build_deep_analysis_prompt(self, task_data: Dict[str, Any], 
                                  consolidated_info: Dict[str, Any],
                                  previous_results: Dict) -> str:
        """æ„å»ºæ·±åº¦åˆ†ææç¤º"""
        return f"""
è¯·åŸºäºå‰æœŸæ‰€æœ‰é˜¶æ®µçš„åˆ†æç»“æœï¼Œè¿›è¡Œæ·±åº¦åˆ†æï¼š

æ±‡æ€»ä¿¡æ¯ï¼š
{json.dumps(consolidated_info, ensure_ascii=False, indent=2)}

ä»»åŠ¡æ•°æ®ï¼š
{json.dumps(task_data, ensure_ascii=False, indent=2)}

è¯·æä¾›ï¼š
1. æ·±å±‚æ¬¡æ´å¯Ÿ
2. é£é™©å…¨é¢è¯„ä¼°
3. æœºä¼šæ·±åº¦æŒ–æ˜
4. æˆ˜ç•¥å»ºè®®

ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚
"""
    
    def _calculate_final_consensus(self, previous_results: Dict) -> float:
        """è®¡ç®—æœ€ç»ˆå…±è¯†åº¦"""
        # åŸºäºå„é˜¶æ®µç»“æœè®¡ç®—å…±è¯†åº¦
        consensus_scores = []
        
        # ä»æ„è§æ”¶é›†é˜¶æ®µè·å–åˆ†æ­§åº¦
        opinion_data = previous_results.get(CollisionStage.OPINION_COLLECTION, {})
        divergence = opinion_data.get("divergence_score", 0.5)
        consensus_scores.append(1.0 - divergence)
        
        # ä»å¯¹æ’è®¨è®ºé˜¶æ®µè·å–è§£å†³ç‡
        collision_data = previous_results.get(CollisionStage.COLLISION_DISCUSSION, {})
        discussions = collision_data.get("discussions", [])
        if discussions:
            resolution_rate = len([d for d in discussions if d.get("resolved", False)]) / len(discussions)
            consensus_scores.append(resolution_rate)
        
        return sum(consensus_scores) / max(len(consensus_scores), 1)
    
    async def _generate_comprehensive_decision(self, decision_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆå†³ç­–"""
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“ç”Ÿæˆç»¼åˆå†³ç­–
        if not self.agents:
            return {"decision": "æ— æ™ºèƒ½ä½“å‚ä¸", "confidence": 0.0}
        
        decision_prompt = f"""
åŸºäºæ‰€æœ‰é˜¶æ®µçš„åˆ†æå’Œè®¨è®ºï¼Œè¯·ç”Ÿæˆæœ€ç»ˆç»¼åˆå†³ç­–ï¼š

å†³ç­–æ•°æ®ï¼š
{json.dumps(decision_data, ensure_ascii=False, indent=2)}

è¯·æä¾›ï¼š
1. æœ€ç»ˆå†³ç­–
2. å†³ç­–ç½®ä¿¡åº¦
3. å†³ç­–ç†ç”±
4. æ”¯æŒè¯æ®

ä»¥JSONæ ¼å¼è¿”å›ã€‚
"""
        
        result = await self.agents[0].analyze(decision_prompt)
        return result
    
    async def _generate_execution_plan(self, decision: str, task_data: Dict[str, Any],
                                     previous_results: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
        return {
            "decision": decision,
            "steps": [
                {"step": 1, "action": "å‡†å¤‡æ‰§è¡Œ", "timeline": "ç«‹å³"},
                {"step": 2, "action": "ç›‘æ§æ‰§è¡Œ", "timeline": "æŒç»­"},
                {"step": 3, "action": "è¯„ä¼°ç»“æœ", "timeline": "æ‰§è¡Œå"}
            ],
            "timeline": {"start": "ç«‹å³", "duration": "è§†æƒ…å†µè€Œå®š"},
            "metrics": {"success_rate": ">80%", "risk_level": "<20%"}
        }
    
    async def _conduct_execution_risk_assessment(self, execution_plan: Dict[str, Any],
                                               previous_results: Dict) -> Dict[str, Any]:
        """æ‰§è¡Œé£é™©è¯„ä¼°"""
        return {
            "overall_risk": "ä¸­ç­‰",
            "key_risks": ["å¸‚åœºå˜åŒ–", "æ‰§è¡Œåå·®"],
            "mitigation_measures": ["å¯†åˆ‡ç›‘æ§", "åŠæ—¶è°ƒæ•´"],
            "acceptable": True
        }
    
    async def _final_execution_confirmation(self, execution_plan: Dict[str, Any],
                                          risk_assessment: Dict[str, Any]) -> Dict[str, Any]:
        """æœ€ç»ˆæ‰§è¡Œç¡®è®¤"""
        acceptable = risk_assessment.get("acceptable", False)
        return {
            "confirmed": acceptable,
            "confirmation_reason": "é£é™©å¯æ§ï¼Œæ‰§è¡Œè®¡åˆ’å¯è¡Œ" if acceptable else "é£é™©è¿‡é«˜ï¼Œéœ€è¦è°ƒæ•´"
        }
    
    def _generate_final_result(self, task_data: Dict[str, Any], 
                             stage_results: Dict) -> CollisionResult:
        """ç”Ÿæˆæœ€ç»ˆç»“æœ"""
        # ä»ç»¼åˆå†³ç­–é˜¶æ®µè·å–ç»“æœ
        decision_data = stage_results.get(CollisionStage.COMPREHENSIVE_DECISION, {}).get("result", {})
        execution_data = stage_results.get(CollisionStage.EXECUTION_CONFIRMATION, {}).get("result", {})
        
        # æå–å¼‚è®®ç‚¹
        dissent_data = stage_results.get(CollisionStage.DISSENT_HANDLING, {}).get("result", {})
        dissent_points = [r.get("dissent", {}) for r in dissent_data.get("resolutions", [])]
        
        return CollisionResult(
            final_decision=decision_data.get("final_decision", ""),
            confidence_score=decision_data.get("confidence_score", 0.0),
            consensus_level=decision_data.get("consensus_level", 0.0),
            dissent_points=[str(d) for d in dissent_points],
            execution_plan=execution_data.get("execution_plan", {}),
            process_log=self.process_log.copy(),
            total_duration=0.0,  # å°†åœ¨è°ƒç”¨å¤„è®¾ç½®
            stage_durations={stage: data["duration"] for stage, data in stage_results.items()}
        )
    
    def _should_terminate_early(self, stage: CollisionStage, stage_result: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æå‰ç»ˆæ­¢"""
        # å¦‚æœåœ¨å¼‚è®®å¤„ç†é˜¶æ®µä»æœ‰å¤§é‡æœªè§£å†³å†²çªï¼Œå¯èƒ½éœ€è¦ç»ˆæ­¢
        if stage == CollisionStage.DISSENT_HANDLING:
            remaining_conflicts = stage_result.get("remaining_conflicts", 0)
            if remaining_conflicts > len(self.agents):
                return True
        
        return False
    
    def _log_stage_completion(self, stage: CollisionStage, duration: float, result: Dict[str, Any]):
        """è®°å½•é˜¶æ®µå®Œæˆæ—¥å¿—"""
        log_entry = {
            "stage": stage.value,
            "duration": duration,
            "timestamp": time.time(),
            "result_summary": self._summarize_stage_result(stage, result)
        }
        
        self.process_log.append(log_entry)
        self.logger.info(f"{stage.value}é˜¶æ®µå®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
    
    def _summarize_stage_result(self, stage: CollisionStage, result: Dict[str, Any]) -> str:
        """æ€»ç»“é˜¶æ®µç»“æœ"""
        if stage == CollisionStage.INITIAL_ANALYSIS:
            return f"å‚ä¸è€…: {result.get('participant_count', 0)}, å¹³å‡ç½®ä¿¡åº¦: {result.get('average_confidence', 0):.2f}"
        elif stage == CollisionStage.OPINION_COLLECTION:
            return f"åˆ†æ­§åº¦: {result.get('divergence_score', 0):.2f}"
        elif stage == CollisionStage.COMPREHENSIVE_DECISION:
            return f"æœ€ç»ˆå†³ç­–ç½®ä¿¡åº¦: {result.get('confidence_score', 0):.2f}"
        else:
            return "é˜¶æ®µå®Œæˆ"


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•ä»£ç 
async def demo_collision_engine():
    """ä¸ƒé˜¶æ®µå¯¹æ’å¼•æ“æ¼”ç¤º"""
    print("ğŸ¯ å¸å›½AIä¸ƒé˜¶æ®µå¯¹æ’å¼•æ“æ¼”ç¤º")
    print("=" * 50)
    
    try:
        # æ¨¡æ‹Ÿæ™ºèƒ½ä½“ï¼ˆå®é™…ä½¿ç”¨æ—¶åº”è¯¥æ˜¯çœŸå®çš„ImperialAgentWrapperå®ä¾‹ï¼‰
        class MockAgent:
            def __init__(self, name):
                self.agent_name = name
            
            async def analyze(self, prompt):
                await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿåˆ†ææ—¶é—´
                return {
                    "analysis": f"{self.agent_name}çš„åˆ†æç»“æœ",
                    "confidence": 0.8,
                    "reasoning": f"{self.agent_name}åŸºäºä¸“ä¸šç»éªŒçš„åˆ¤æ–­",
                    "supporting_data": {"data_point": "mock_data"}
                }
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ™ºèƒ½ä½“
        agents = [
            MockAgent("å¨ç§‘å¤«AI"),
            MockAgent("é©¬ä»è¾‰AI"),
            MockAgent("é³„é±¼å¯¼å¸ˆAI")
        ]
        
        # åˆå§‹åŒ–å¯¹æ’å¼•æ“
        engine = SevenStageCollisionEngine(agents)
        
        # å‡†å¤‡ä»»åŠ¡æ•°æ®
        task_data = {
            "task_name": "è‚¡ç¥¨æŠ•èµ„å†³ç­–",
            "target_stock": "000001.SZ",
            "analysis_period": "çŸ­æœŸ",
            "market_condition": "éœ‡è¡",
            "risk_preference": "ä¸­ç­‰"
        }
        
        print(f"ğŸ“‹ ä»»åŠ¡ä¿¡æ¯: {task_data['task_name']}")
        print(f"ğŸ­ å‚ä¸æ™ºèƒ½ä½“: {[agent.agent_name for agent in agents]}")
        print("\nå¼€å§‹æ‰§è¡Œä¸ƒé˜¶æ®µå¯¹æ’æµç¨‹...")
        
        # æ‰§è¡Œå¯¹æ’æµç¨‹
        start_time = time.time()
        result = await engine.run_collision_process(task_data)
        execution_time = time.time() - start_time
        
        # è¾“å‡ºç»“æœ
        print(f"\nğŸ† å¯¹æ’å†³ç­–ç»“æœ:")
        print(f"æœ€ç»ˆå†³ç­–: {result.final_decision}")
        print(f"ç½®ä¿¡åº¦è¯„åˆ†: {result.confidence_score:.2f}")
        print(f"å…±è¯†åº¦: {result.consensus_level:.2f}")
        print(f"æ€»æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        
        if result.dissent_points:
            print(f"å¼‚è®®ç‚¹: {len(result.dissent_points)}ä¸ª")
        
        print(f"\nğŸ“Š å„é˜¶æ®µè€—æ—¶:")
        for stage, duration in result.stage_durations.items():
            print(f"  {stage.value}: {duration:.2f}ç§’")
        
        print(f"\nâœ… æ‰§è¡Œè®¡åˆ’: {result.execution_plan.get('steps', [])}")
        
        return result
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºæ‰§è¡Œå¤±è´¥: {str(e)}")
        raise


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(demo_collision_engine())
