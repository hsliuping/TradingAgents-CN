"""
å¸å›½AIåŸºç¡€åä½œæœºåˆ¶ v4.0
Imperial AI Basic Collaboration System v4.0

åŸºäºçœŸå®æ•°æ®çš„ä¸‰æ ¸å¿ƒè§’è‰²åä½œåˆ†æç³»ç»Ÿï¼Œæ”¯æŒç»“æœèšåˆå’Œå†²çªæ£€æµ‹ã€‚
"""

import asyncio
import json
import traceback
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
from enum import Enum

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from imperial_agents.core.imperial_agent_wrapper import (
    ImperialAgentWrapper,
    AnalysisResult, 
    AnalysisType, 
    DecisionLevel
)
from imperial_agents.roles.wyckoff_ai import WyckoffAI
from imperial_agents.roles.marenhui_ai import MarenhuiAI
from imperial_agents.roles.crocodile_mentor_ai import CrocodileMentorAI

from tradingagents.utils.logging_init import get_logger
from tradingagents.agents.utils.agent_utils import Toolkit

logger = get_logger("collaboration_system")


class CollaborationMode(Enum):
    """åä½œæ¨¡å¼æšä¸¾"""
    SEQUENTIAL = "sequential"      # é¡ºåºåä½œ
    PARALLEL = "parallel"          # å¹¶è¡Œåä½œ  
    EMERGENCY = "emergency"        # ç´§æ€¥åä½œ


class ConflictLevel(Enum):
    """å†²çªçº§åˆ«æšä¸¾"""
    NO_CONFLICT = "æ— å†²çª"
    MINOR_CONFLICT = "è½»å¾®å†²çª"
    MAJOR_CONFLICT = "é‡å¤§å†²çª"
    CRITICAL_CONFLICT = "ä¸¥é‡å†²çª"


@dataclass
class CollaborationResult:
    """åä½œåˆ†æç»“æœ"""
    symbol: str                                    # è‚¡ç¥¨ä»£ç 
    collaboration_mode: CollaborationMode         # åä½œæ¨¡å¼
    individual_results: List[AnalysisResult]     # ä¸ªä½“åˆ†æç»“æœ
    consensus_decision: DecisionLevel             # å…±è¯†å†³ç­–
    consensus_confidence: float                   # å…±è¯†ç½®ä¿¡åº¦
    conflict_level: ConflictLevel                 # å†²çªçº§åˆ«
    conflict_details: List[str]                   # å†²çªè¯¦æƒ…
    final_reasoning: str                          # æœ€ç»ˆåˆ†æç†ç”±
    risk_alerts: List[str]                        # é£é™©è­¦æŠ¥
    execution_time: float                         # æ‰§è¡Œæ—¶é—´(ç§’)
    timestamp: datetime                           # åä½œæ—¶é—´
    raw_data: Optional[Dict[str, Any]] = None     # åŸå§‹æ•°æ®
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        result = asdict(self)
        result['collaboration_mode'] = self.collaboration_mode.value
        result['consensus_decision'] = self.consensus_decision.value
        result['conflict_level'] = self.conflict_level.value
        result['timestamp'] = self.timestamp.isoformat()
        result['individual_results'] = [r.to_dict() for r in self.individual_results]
        return result


class RealDataCollaborationSystem:
    """
    åŸºäºçœŸå®æ•°æ®çš„åä½œç³»ç»Ÿ
    
    æ•´åˆå¨ç§‘å¤«AIã€é©¬ä»è¾‰AIã€é³„é±¼å¯¼å¸ˆAIä¸‰ä¸ªæ ¸å¿ƒè§’è‰²ï¼Œ
    å®ç°åŸºäºçœŸå®å¸‚åœºæ•°æ®çš„æ™ºèƒ½åä½œåˆ†æã€‚
    """
    
    def __init__(self, llm: Any, toolkit: Optional[Toolkit] = None):
        """
        åˆå§‹åŒ–åä½œç³»ç»Ÿ
        
        Args:
            llm: è¯­è¨€æ¨¡å‹å®ä¾‹
            toolkit: TradingAgentså·¥å…·é›†
        """
        self.llm = llm
        self.toolkit = toolkit or Toolkit()
        
        # åˆå§‹åŒ–ä¸‰ä¸ªæ ¸å¿ƒè§’è‰²
        self.agents = {
            "å¨ç§‘å¤«AI": WyckoffAI(llm, toolkit),
            "é©¬ä»è¾‰AI": MarenhuiAI(llm, toolkit), 
            "é³„é±¼å¯¼å¸ˆAI": CrocodileMentorAI(llm, toolkit)
        }
        
        # åä½œç³»ç»Ÿé…ç½®
        self.decision_weights = {
            "å¨ç§‘å¤«AI": 0.35,      # æŠ€æœ¯åˆ†ææƒé‡
            "é©¬ä»è¾‰AI": 0.30,      # çŸ­çº¿éªŒè¯æƒé‡
            "é³„é±¼å¯¼å¸ˆAI": 0.35     # é£é™©æ§åˆ¶æƒé‡
        }
        
        # é£é™©æ§åˆ¶é˜ˆå€¼
        self.risk_thresholds = {
            'confidence_threshold': 0.6,    # æœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼
            'conflict_threshold': 0.7,      # å†²çªæ£€æµ‹é˜ˆå€¼
            'emergency_timeout': 30.0       # ç´§æ€¥æ¨¡å¼è¶…æ—¶(ç§’)
        }
        
        # åä½œå†å²
        self.collaboration_history: List[CollaborationResult] = []
        
        logger.info("ğŸ¤ [åä½œç³»ç»Ÿ] v4.0 åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“Š [åä½œé…ç½®] æƒé‡åˆ†é…: {self.decision_weights}")
        logger.info(f"ğŸ›¡ï¸ [é£é™©æ§åˆ¶] é˜ˆå€¼è®¾ç½®: {self.risk_thresholds}")
    
    async def analyze_stock_collaboration(
        self,
        symbol: str,
        mode: CollaborationMode = CollaborationMode.PARALLEL,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        additional_context: Optional[str] = None
    ) -> CollaborationResult:
        """
        æ‰§è¡Œåä½œè‚¡ç¥¨åˆ†æ
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            mode: åä½œæ¨¡å¼
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            CollaborationResult: åä½œåˆ†æç»“æœ
        """
        start_time = datetime.now()
        
        try:
            logger.info(f"ğŸš€ [åä½œç³»ç»Ÿ] å¼€å§‹åä½œåˆ†æ: {symbol} (æ¨¡å¼: {mode.value})")
            
            # è·å–å¸‚åœºæ•°æ®ä¸Šä¸‹æ–‡
            market_context = await self._prepare_market_context(symbol, start_date, end_date)
            
            # æ ¹æ®æ¨¡å¼æ‰§è¡Œåä½œåˆ†æ
            if mode == CollaborationMode.SEQUENTIAL:
                individual_results = await self._sequential_analysis(
                    symbol, market_context, additional_context
                )
            elif mode == CollaborationMode.PARALLEL:
                individual_results = await self._parallel_analysis(
                    symbol, market_context, additional_context
                )
            elif mode == CollaborationMode.EMERGENCY:
                individual_results = await self._emergency_analysis(
                    symbol, market_context, additional_context
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„åä½œæ¨¡å¼: {mode}")
            
            # æ‰§è¡Œç»“æœèšåˆå’Œå†²çªæ£€æµ‹
            collaboration_result = await self._aggregate_results(
                symbol, mode, individual_results, start_time
            )
            
            # ä¿å­˜åä½œå†å²
            self.collaboration_history.append(collaboration_result)
            
            # è®°å½•æˆåŠŸæ—¥å¿—
            execution_time = collaboration_result.execution_time
            logger.info(f"âœ… [åä½œç³»ç»Ÿ] åˆ†æå®Œæˆ: {symbol}")
            logger.info(f"ğŸ“Š [åä½œç»“æœ] å†³ç­–: {collaboration_result.consensus_decision.value}")
            logger.info(f"ğŸ¯ [åä½œè´¨é‡] ç½®ä¿¡åº¦: {collaboration_result.consensus_confidence:.2%}")
            logger.info(f"âš¡ [åä½œæ€§èƒ½] æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
            logger.info(f"ğŸ” [å†²çªæ£€æµ‹] å†²çªçº§åˆ«: {collaboration_result.conflict_level.value}")
            
            return collaboration_result
            
        except Exception as e:
            logger.error(f"âŒ [åä½œç³»ç»Ÿ] åˆ†æå¤±è´¥: {symbol} - {e}")
            traceback.print_exc()
            
            # è¿”å›é”™è¯¯ç»“æœ
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return CollaborationResult(
                symbol=symbol,
                collaboration_mode=mode,
                individual_results=[],
                consensus_decision=DecisionLevel.NEUTRAL,
                consensus_confidence=0.0,
                conflict_level=ConflictLevel.CRITICAL_CONFLICT,
                conflict_details=[f"åä½œåˆ†æå¤±è´¥: {str(e)}"],
                final_reasoning=f"åä½œè¿‡ç¨‹ä¸­å‡ºç°ç³»ç»Ÿé”™è¯¯: {str(e)}",
                risk_alerts=[f"ç³»ç»Ÿé”™è¯¯: {str(e)}", "å»ºè®®æš‚åœäº¤æ˜“ï¼Œç­‰å¾…ç³»ç»Ÿæ¢å¤"],
                execution_time=execution_time,
                timestamp=datetime.now()
            )
    
    async def _prepare_market_context(
        self, 
        symbol: str, 
        start_date: Optional[str], 
        end_date: Optional[str]
    ) -> str:
        """
        å‡†å¤‡å¸‚åœºæ•°æ®ä¸Šä¸‹æ–‡
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            str: å¸‚åœºæ•°æ®ä¸Šä¸‹æ–‡
        """
        try:
            logger.info(f"ğŸ“Š [åä½œç³»ç»Ÿ] å‡†å¤‡å¸‚åœºæ•°æ®: {symbol}")
            
            # è®¾ç½®é»˜è®¤æ—¥æœŸ
            if not end_date:
                end_date = datetime.now().strftime('%Y-%m-%d')
            if not start_date:
                start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            
            # è·å–ç»Ÿä¸€å¸‚åœºæ•°æ®
            market_data = self.toolkit.get_stock_market_data_unified.invoke({
                'ticker': symbol,
                'start_date': start_date,
                'end_date': end_date
            })
            
            # æ ¼å¼åŒ–ä¸ºä¸Šä¸‹æ–‡
            context = f"""
## å¸‚åœºæ•°æ®ä¸Šä¸‹æ–‡ ({symbol})
- æ•°æ®æœŸé—´: {start_date} è‡³ {end_date}
- æ•°æ®é•¿åº¦: {len(market_data)} æ¡è®°å½•
- æ•°æ®è·å–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

{market_data}
"""
            
            logger.info(f"âœ… [åä½œç³»ç»Ÿ] å¸‚åœºæ•°æ®å‡†å¤‡å®Œæˆ: {len(market_data)} æ¡è®°å½•")
            return context
            
        except Exception as e:
            logger.warning(f"âš ï¸ [åä½œç³»ç»Ÿ] å¸‚åœºæ•°æ®è·å–å¤±è´¥: {e}")
            return f"å¸‚åœºæ•°æ®è·å–å¤±è´¥: {str(e)}"
    
    async def _sequential_analysis(
        self, 
        symbol: str, 
        market_context: str, 
        additional_context: Optional[str]
    ) -> List[AnalysisResult]:
        """
        é¡ºåºåä½œåˆ†æ
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            market_context: å¸‚åœºæ•°æ®ä¸Šä¸‹æ–‡
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            List[AnalysisResult]: åˆ†æç»“æœåˆ—è¡¨
        """
        logger.info(f"ğŸ”„ [é¡ºåºåä½œ] å¼€å§‹é¡ºåºåˆ†æ: {symbol}")
        
        results = []
        analysis_chain = [
            ("å¨ç§‘å¤«AI", AnalysisType.TECHNICAL_ANALYSIS),
            ("é©¬ä»è¾‰AI", AnalysisType.RISK_ANALYSIS),
            ("é³„é±¼å¯¼å¸ˆAI", AnalysisType.RISK_ANALYSIS)
        ]
        
        accumulated_context = market_context or ""
        if additional_context:
            accumulated_context += f"\n\n{additional_context}"
        
        for agent_name, analysis_type in analysis_chain:
            try:
                logger.info(f"ğŸ¯ [é¡ºåºåä½œ] {agent_name} å¼€å§‹åˆ†æ")
                
                agent = self.agents[agent_name]
                
                # ä¸ºåç»­è§’è‰²æ·»åŠ å‰é¢çš„åˆ†æç»“æœ
                if results:
                    previous_results = "\n\n## å‰åºåˆ†æç»“æœ\n"
                    for prev_result in results:
                        previous_results += f"\n**{prev_result.role_name}**: {prev_result.decision.value} (ç½®ä¿¡åº¦: {prev_result.confidence:.2%})\n"
                        previous_results += f"å…³é”®è§‚ç‚¹: {prev_result.reasoning[:200]}...\n"
                    accumulated_context += previous_results
                
                result = await agent.analyze_stock_async(
                    symbol=symbol,
                    analysis_type=analysis_type,
                    additional_context=accumulated_context
                )
                
                results.append(result)
                logger.info(f"âœ… [é¡ºåºåä½œ] {agent_name} åˆ†æå®Œæˆ: {result.decision.value}")
                
            except Exception as e:
                logger.error(f"âŒ [é¡ºåºåä½œ] {agent_name} åˆ†æå¤±è´¥: {e}")
                # åˆ›å»ºé”™è¯¯ç»“æœï¼Œä½†ç»§ç»­æ‰§è¡Œ
                error_result = AnalysisResult(
                    role_name=agent_name,
                    analysis_type=analysis_type,
                    symbol=symbol,
                    decision=DecisionLevel.NEUTRAL,
                    confidence=0.0,
                    reasoning=f"åˆ†æå¤±è´¥: {str(e)}",
                    key_factors=[],
                    risk_warnings=[f"åˆ†æå¤±è´¥: {str(e)}"],
                    timestamp=datetime.now()
                )
                results.append(error_result)
        
        logger.info(f"ğŸ [é¡ºåºåä½œ] å®Œæˆï¼Œå…±è·å¾— {len(results)} ä¸ªåˆ†æç»“æœ")
        return results
    
    async def _parallel_analysis(
        self, 
        symbol: str, 
        market_context: str, 
        additional_context: Optional[str]
    ) -> List[AnalysisResult]:
        """
        å¹¶è¡Œåä½œåˆ†æ
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            market_context: å¸‚åœºæ•°æ®ä¸Šä¸‹æ–‡
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            List[AnalysisResult]: åˆ†æç»“æœåˆ—è¡¨
        """
        logger.info(f"âš¡ [å¹¶è¡Œåä½œ] å¼€å§‹å¹¶è¡Œåˆ†æ: {symbol}")
        
        # å‡†å¤‡åˆ†æä¸Šä¸‹æ–‡
        full_context = market_context or ""
        if additional_context:
            full_context += f"\n\n{additional_context}"
        
        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        tasks = []
        analysis_configs = [
            ("å¨ç§‘å¤«AI", AnalysisType.TECHNICAL_ANALYSIS),
            ("é©¬ä»è¾‰AI", AnalysisType.RISK_ANALYSIS),
            ("é³„é±¼å¯¼å¸ˆAI", AnalysisType.RISK_ANALYSIS)
        ]
        
        for agent_name, analysis_type in analysis_configs:
            agent = self.agents[agent_name]
            task = asyncio.create_task(
                agent.analyze_stock_async(
                    symbol=symbol,
                    analysis_type=analysis_type,
                    additional_context=full_context
                )
            )
            tasks.append((agent_name, task))
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = []
        for agent_name, task in tasks:
            try:
                result = await task
                results.append(result)
                logger.info(f"âœ… [å¹¶è¡Œåä½œ] {agent_name} åˆ†æå®Œæˆ: {result.decision.value}")
            except Exception as e:
                logger.error(f"âŒ [å¹¶è¡Œåä½œ] {agent_name} åˆ†æå¤±è´¥: {e}")
                # åˆ›å»ºé”™è¯¯ç»“æœ
                error_result = AnalysisResult(
                    role_name=agent_name,
                    analysis_type=AnalysisType.RISK_ANALYSIS,
                    symbol=symbol,
                    decision=DecisionLevel.NEUTRAL,
                    confidence=0.0,
                    reasoning=f"å¹¶è¡Œåˆ†æå¤±è´¥: {str(e)}",
                    key_factors=[],
                    risk_warnings=[f"åˆ†æå¤±è´¥: {str(e)}"],
                    timestamp=datetime.now()
                )
                results.append(error_result)
        
        logger.info(f"ğŸ [å¹¶è¡Œåä½œ] å®Œæˆï¼Œå…±è·å¾— {len(results)} ä¸ªåˆ†æç»“æœ")
        return results
    
    async def _emergency_analysis(
        self, 
        symbol: str, 
        market_context: str, 
        additional_context: Optional[str]
    ) -> List[AnalysisResult]:
        """
        ç´§æ€¥åä½œåˆ†æï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            market_context: å¸‚åœºæ•°æ®ä¸Šä¸‹æ–‡
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            List[AnalysisResult]: åˆ†æç»“æœåˆ—è¡¨
        """
        logger.info(f"ğŸš¨ [ç´§æ€¥åä½œ] å¼€å§‹ç´§æ€¥åˆ†æ: {symbol}")
        
        # å‡†å¤‡ç´§æ€¥åˆ†æä¸Šä¸‹æ–‡
        emergency_context = f"""
{market_context}

## ç´§æ€¥åˆ†ææ¨¡å¼
å½“å‰ä¸ºç´§æ€¥åˆ†ææ¨¡å¼ï¼Œè¦æ±‚å¿«é€Ÿç»™å‡ºæ ¸å¿ƒåˆ¤æ–­ï¼š
1. å¿«é€Ÿè¯†åˆ«ä¸»è¦é£é™©
2. ç»™å‡ºæ˜ç¡®çš„æ“ä½œå»ºè®®
3. é‡ç‚¹å…³æ³¨æ­¢æŸå’Œé£é™©æ§åˆ¶

{additional_context or ""}
"""
        
        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡ï¼ˆä½†è®¾ç½®è¶…æ—¶ï¼‰
        tasks = []
        for agent_name in ["é³„é±¼å¯¼å¸ˆAI", "é©¬ä»è¾‰AI"]:  # ç´§æ€¥æ¨¡å¼åªç”¨é£é™©æ§åˆ¶è§’è‰²
            agent = self.agents[agent_name]
            task = asyncio.create_task(
                agent.analyze_stock_async(
                    symbol=symbol,
                    analysis_type=AnalysisType.RISK_ANALYSIS,
                    additional_context=emergency_context
                )
            )
            tasks.append((agent_name, task))
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆå¸¦è¶…æ—¶ï¼‰
        results = []
        timeout = self.risk_thresholds['emergency_timeout']
        
        try:
            for agent_name, task in tasks:
                try:
                    result = await asyncio.wait_for(task, timeout=timeout)
                    results.append(result)
                    logger.info(f"ğŸš¨ [ç´§æ€¥åä½œ] {agent_name} å¿«é€Ÿåˆ†æå®Œæˆ")
                except asyncio.TimeoutError:
                    logger.warning(f"â° [ç´§æ€¥åä½œ] {agent_name} åˆ†æè¶…æ—¶")
                    # åˆ›å»ºè¶…æ—¶ç»“æœ
                    timeout_result = AnalysisResult(
                        role_name=agent_name,
                        analysis_type=AnalysisType.RISK_ANALYSIS,
                        symbol=symbol,
                        decision=DecisionLevel.NEUTRAL,
                        confidence=0.0,
                        reasoning="ç´§æ€¥åˆ†æè¶…æ—¶ï¼Œå»ºè®®è°¨æ…æ“ä½œ",
                        key_factors=["åˆ†æè¶…æ—¶"],
                        risk_warnings=["åˆ†æè¶…æ—¶", "å»ºè®®æš‚åœæ“ä½œ"],
                        timestamp=datetime.now()
                    )
                    results.append(timeout_result)
                except Exception as e:
                    logger.error(f"âŒ [ç´§æ€¥åä½œ] {agent_name} åˆ†æå¤±è´¥: {e}")
                    error_result = AnalysisResult(
                        role_name=agent_name,
                        analysis_type=AnalysisType.RISK_ANALYSIS,
                        symbol=symbol,
                        decision=DecisionLevel.NEUTRAL,
                        confidence=0.0,
                        reasoning=f"ç´§æ€¥åˆ†æå¤±è´¥: {str(e)}",
                        key_factors=[],
                        risk_warnings=[f"åˆ†æå¤±è´¥: {str(e)}"],
                        timestamp=datetime.now()
                    )
                    results.append(error_result)
        
        except Exception as e:
            logger.error(f"âŒ [ç´§æ€¥åä½œ] æ•´ä½“å¤±è´¥: {e}")
        
        logger.info(f"ğŸš¨ [ç´§æ€¥åä½œ] å®Œæˆï¼Œå…±è·å¾— {len(results)} ä¸ªåˆ†æç»“æœ")
        return results
    
    async def _aggregate_results(
        self, 
        symbol: str, 
        mode: CollaborationMode,
        individual_results: List[AnalysisResult],
        start_time: datetime
    ) -> CollaborationResult:
        """
        èšåˆåˆ†æç»“æœå¹¶æ£€æµ‹å†²çª
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            mode: åä½œæ¨¡å¼
            individual_results: ä¸ªä½“åˆ†æç»“æœ
            start_time: å¼€å§‹æ—¶é—´
            
        Returns:
            CollaborationResult: èšåˆåçš„åä½œç»“æœ
        """
        logger.info(f"ğŸ”„ [ç»“æœèšåˆ] å¼€å§‹èšåˆ {len(individual_results)} ä¸ªåˆ†æç»“æœ")
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        execution_time = (datetime.now() - start_time).total_seconds()
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç»“æœï¼Œè¿”å›é”™è¯¯
        if not individual_results:
            return CollaborationResult(
                symbol=symbol,
                collaboration_mode=mode,
                individual_results=[],
                consensus_decision=DecisionLevel.NEUTRAL,
                consensus_confidence=0.0,
                conflict_level=ConflictLevel.CRITICAL_CONFLICT,
                conflict_details=["æ— æœ‰æ•ˆåˆ†æç»“æœ"],
                final_reasoning="åä½œåˆ†ææœªè·å¾—æœ‰æ•ˆç»“æœ",
                risk_alerts=["æ— æ³•è¿›è¡Œæœ‰æ•ˆåˆ†æ", "å»ºè®®æš‚åœæ“ä½œ"],
                execution_time=execution_time,
                timestamp=datetime.now()
            )
        
        # è®¡ç®—åŠ æƒå…±è¯†å†³ç­–
        consensus_decision, consensus_confidence = self._calculate_weighted_consensus(individual_results)
        
        # æ£€æµ‹å†²çª
        conflict_level, conflict_details = self._detect_conflicts(individual_results)
        
        # èšåˆé£é™©è­¦æŠ¥
        risk_alerts = self._aggregate_risk_alerts(individual_results)
        
        # ç”Ÿæˆæœ€ç»ˆåˆ†æç†ç”±
        final_reasoning = self._generate_final_reasoning(individual_results, consensus_decision, conflict_level)
        
        result = CollaborationResult(
            symbol=symbol,
            collaboration_mode=mode,
            individual_results=individual_results,
            consensus_decision=consensus_decision,
            consensus_confidence=consensus_confidence,
            conflict_level=conflict_level,
            conflict_details=conflict_details,
            final_reasoning=final_reasoning,
            risk_alerts=risk_alerts,
            execution_time=execution_time,
            timestamp=datetime.now()
        )
        
        logger.info(f"âœ… [ç»“æœèšåˆ] èšåˆå®Œæˆ")
        logger.info(f"ğŸ“Š [å…±è¯†ç»“æœ] å†³ç­–: {consensus_decision.value}, ç½®ä¿¡åº¦: {consensus_confidence:.2%}")
        logger.info(f"ğŸ” [å†²çªæ£€æµ‹] çº§åˆ«: {conflict_level.value}")
        
        return result
    
    def _calculate_weighted_consensus(self, results: List[AnalysisResult]) -> Tuple[DecisionLevel, float]:
        """
        è®¡ç®—åŠ æƒå…±è¯†å†³ç­–
        
        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            
        Returns:
            Tuple[DecisionLevel, float]: å…±è¯†å†³ç­–å’Œç½®ä¿¡åº¦
        """
        if not results:
            return DecisionLevel.NEUTRAL, 0.0
        
        # å†³ç­–æ˜ å°„åˆ°æ•°å€¼
        decision_values = {
            DecisionLevel.STRONG_SELL: -2,
            DecisionLevel.SELL: -1,
            DecisionLevel.NEUTRAL: 0,
            DecisionLevel.HOLD: 0,
            DecisionLevel.BUY: 1,
            DecisionLevel.STRONG_BUY: 2
        }
        
        # è®¡ç®—åŠ æƒå†³ç­–å€¼
        weighted_sum = 0.0
        weight_sum = 0.0
        confidence_sum = 0.0
        
        for result in results:
            agent_name = result.role_name
            weight = self.decision_weights.get(agent_name, 0.33)  # é»˜è®¤æƒé‡
            decision_value = decision_values.get(result.decision, 0)
            
            weighted_sum += decision_value * weight * result.confidence
            weight_sum += weight
            confidence_sum += result.confidence * weight
        
        # è®¡ç®—å¹³å‡å€¼
        if weight_sum > 0:
            avg_decision_value = weighted_sum / weight_sum
            avg_confidence = confidence_sum / weight_sum
        else:
            avg_decision_value = 0.0
            avg_confidence = 0.0
        
        # å°†æ•°å€¼æ˜ å°„å›å†³ç­–çº§åˆ«
        if avg_decision_value >= 1.5:
            consensus_decision = DecisionLevel.STRONG_BUY
        elif avg_decision_value >= 0.5:
            consensus_decision = DecisionLevel.BUY
        elif avg_decision_value <= -1.5:
            consensus_decision = DecisionLevel.STRONG_SELL
        elif avg_decision_value <= -0.5:
            consensus_decision = DecisionLevel.SELL
        elif abs(avg_decision_value) <= 0.2:
            consensus_decision = DecisionLevel.NEUTRAL
        else:
            consensus_decision = DecisionLevel.HOLD
        
        return consensus_decision, avg_confidence
    
    def _detect_conflicts(self, results: List[AnalysisResult]) -> Tuple[ConflictLevel, List[str]]:
        """
        æ£€æµ‹åˆ†æç»“æœå†²çª
        
        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            
        Returns:
            Tuple[ConflictLevel, List[str]]: å†²çªçº§åˆ«å’Œè¯¦æƒ…
        """
        if len(results) < 2:
            return ConflictLevel.NO_CONFLICT, []
        
        # æå–å†³ç­–æ–¹å‘
        decisions = [r.decision for r in results]
        confidence_levels = [r.confidence for r in results]
        
        # æ£€æŸ¥å†³ç­–ä¸€è‡´æ€§
        buy_decisions = [d for d in decisions if d in [DecisionLevel.BUY, DecisionLevel.STRONG_BUY]]
        sell_decisions = [d for d in decisions if d in [DecisionLevel.SELL, DecisionLevel.STRONG_SELL]]
        neutral_decisions = [d for d in decisions if d in [DecisionLevel.NEUTRAL, DecisionLevel.HOLD]]
        
        conflict_details = []
        
        # ä¸¥é‡å†²çªï¼šåŒæ—¶æœ‰å¼ºçƒˆä¹°å…¥å’Œå¼ºçƒˆå–å‡º
        if DecisionLevel.STRONG_BUY in decisions and DecisionLevel.STRONG_SELL in decisions:
            conflict_details.append("å­˜åœ¨å¼ºçƒˆä¹°å…¥ä¸å¼ºçƒˆå–å‡ºçš„ç›´æ¥å†²çª")
            return ConflictLevel.CRITICAL_CONFLICT, conflict_details
        
        # é‡å¤§å†²çªï¼šä¹°å…¥å’Œå–å‡ºåŒæ—¶å­˜åœ¨
        if buy_decisions and sell_decisions:
            conflict_details.append(f"ä¹°å…¥å»ºè®®({len(buy_decisions)}ä¸ª)ä¸å–å‡ºå»ºè®®({len(sell_decisions)}ä¸ª)å­˜åœ¨å†²çª")
            return ConflictLevel.MAJOR_CONFLICT, conflict_details
        
        # è½»å¾®å†²çªï¼šç½®ä¿¡åº¦å·®å¼‚å¾ˆå¤§
        if confidence_levels:
            max_confidence = max(confidence_levels)
            min_confidence = min(confidence_levels)
            confidence_spread = max_confidence - min_confidence
            
            if confidence_spread > 0.4:
                conflict_details.append(f"ç½®ä¿¡åº¦å·®å¼‚è¾ƒå¤§: {min_confidence:.2%} - {max_confidence:.2%}")
                return ConflictLevel.MINOR_CONFLICT, conflict_details
        
        # è½»å¾®å†²çªï¼šé£é™©æç¤ºå·®å¼‚
        risk_warnings_count = sum(len(r.risk_warnings) for r in results)
        if risk_warnings_count > len(results) * 2:  # å¹³å‡æ¯ä¸ªè§’è‰²è¶…è¿‡2ä¸ªé£é™©æç¤º
            conflict_details.append("é£é™©æç¤ºå­˜åœ¨è¾ƒå¤§å·®å¼‚")
            return ConflictLevel.MINOR_CONFLICT, conflict_details
        
        return ConflictLevel.NO_CONFLICT, []
    
    def _aggregate_risk_alerts(self, results: List[AnalysisResult]) -> List[str]:
        """
        èšåˆé£é™©è­¦æŠ¥
        
        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            
        Returns:
            List[str]: èšåˆåçš„é£é™©è­¦æŠ¥
        """
        all_risks = []
        
        for result in results:
            for warning in result.risk_warnings:
                if warning not in all_risks:  # å»é‡
                    all_risks.append(f"[{result.role_name}] {warning}")
        
        # æ·»åŠ åä½œç³»ç»Ÿçº§åˆ«çš„é£é™©è­¦æŠ¥
        avg_confidence = sum(r.confidence for r in results) / len(results) if results else 0.0
        
        if avg_confidence < self.risk_thresholds['confidence_threshold']:
            all_risks.insert(0, f"âš ï¸ æ•´ä½“ç½®ä¿¡åº¦åä½ ({avg_confidence:.2%})ï¼Œå»ºè®®è°¨æ…æ“ä½œ")
        
        return all_risks
    
    def _generate_final_reasoning(
        self, 
        results: List[AnalysisResult], 
        consensus_decision: DecisionLevel,
        conflict_level: ConflictLevel
    ) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆåˆ†æç†ç”±
        
        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            consensus_decision: å…±è¯†å†³ç­–
            conflict_level: å†²çªçº§åˆ«
            
        Returns:
            str: æœ€ç»ˆåˆ†æç†ç”±
        """
        reasoning = "## å¸å›½AIä¸‰è§’è‰²åä½œåˆ†ææŠ¥å‘Š\n\n"
        
        # å„è§’è‰²è§‚ç‚¹æ‘˜è¦
        reasoning += "### ğŸ­ å„è§’è‰²åˆ†æè§‚ç‚¹\n\n"
        for result in results:
            reasoning += f"**{result.role_name}**: {result.decision.value} (ç½®ä¿¡åº¦: {result.confidence:.2%})\n"
            reasoning += f"æ ¸å¿ƒè§‚ç‚¹: {result.reasoning[:150]}...\n\n"
        
        # å…±è¯†å†³ç­–è¯´æ˜
        reasoning += f"### ğŸ¤ åä½œå…±è¯†å†³ç­–\n\n"
        reasoning += f"ç»è¿‡ä¸‰è§’è‰²åä½œåˆ†æï¼Œå½¢æˆå…±è¯†å†³ç­–: **{consensus_decision.value}**\n\n"
        
        # å†²çªæƒ…å†µè¯´æ˜
        if conflict_level != ConflictLevel.NO_CONFLICT:
            reasoning += f"### âš ï¸ å†²çªåˆ†æ\n\n"
            reasoning += f"æ£€æµ‹åˆ° {conflict_level.value}ï¼Œè¯·æ³¨æ„:\n"
            reasoning += "- ä¸åŒè§’è‰²åœ¨æŸäº›åˆ¤æ–­ä¸Šå­˜åœ¨åˆ†æ­§\n"
            reasoning += "- å»ºè®®ç»¼åˆè€ƒè™‘å„æ–¹è§‚ç‚¹\n"
            reasoning += "- é‡ç‚¹å…³æ³¨é£é™©æ§åˆ¶\n\n"
        
        # æ“ä½œå»ºè®®
        reasoning += "### ğŸ’¡ æ“ä½œå»ºè®®\n\n"
        reasoning += f"åŸºäºä¸‰è§’è‰²åä½œåˆ†æï¼Œå»ºè®®é‡‡å– **{consensus_decision.value}** ç­–ç•¥ã€‚\n"
        reasoning += "å…·ä½“æ“ä½œè¯·ç»“åˆä¸ªäººé£é™©æ‰¿å—èƒ½åŠ›å’Œèµ„é‡‘ç®¡ç†åŸåˆ™ã€‚\n\n"
        
        reasoning += "---\n"
        reasoning += "*æœ¬åˆ†æç”±å¸å›½AIä¸‰è§’è‰²åä½œç³»ç»Ÿç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…ã€‚*"
        
        return reasoning
    
    def get_collaboration_summary(self, limit: int = 10) -> Dict[str, Any]:
        """
        è·å–åä½œå†å²æ‘˜è¦
        
        Args:
            limit: è¿”å›è®°å½•æ•°é‡é™åˆ¶
            
        Returns:
            Dict[str, Any]: åä½œæ‘˜è¦
        """
        recent_collaborations = self.collaboration_history[-limit:] if self.collaboration_history else []
        
        if not recent_collaborations:
            return {
                'total_collaborations': 0,
                'recent_collaborations': [],
                'avg_execution_time': 0.0,
                'avg_confidence': 0.0,
                'conflict_distribution': {},
                'decision_distribution': {}
            }
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_execution_time = sum(c.execution_time for c in recent_collaborations)
        avg_execution_time = total_execution_time / len(recent_collaborations)
        
        total_confidence = sum(c.consensus_confidence for c in recent_collaborations)
        avg_confidence = total_confidence / len(recent_collaborations)
        
        # å†²çªåˆ†å¸ƒ
        conflict_dist = {}
        for collab in recent_collaborations:
            conflict_name = collab.conflict_level.value
            conflict_dist[conflict_name] = conflict_dist.get(conflict_name, 0) + 1
        
        # å†³ç­–åˆ†å¸ƒ
        decision_dist = {}
        for collab in recent_collaborations:
            decision_name = collab.consensus_decision.value
            decision_dist[decision_name] = decision_dist.get(decision_name, 0) + 1
        
        return {
            'total_collaborations': len(self.collaboration_history),
            'recent_collaborations': [c.to_dict() for c in recent_collaborations],
            'avg_execution_time': avg_execution_time,
            'avg_confidence': avg_confidence,
            'conflict_distribution': conflict_dist,
            'decision_distribution': decision_dist
        }


# å¯¼å‡ºä¸»è¦ç±»
__all__ = [
    'RealDataCollaborationSystem',
    'CollaborationResult',
    'CollaborationMode',
    'ConflictLevel'
]
