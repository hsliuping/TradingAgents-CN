# é˜¶æ®µä¸€ï¼šInternational News Analystå®ç°

## ğŸ“‹ é˜¶æ®µæ¦‚è¿°

**ç›®æ ‡**ï¼šæ–°å¢å›½é™…æ–°é—»åˆ†æå¸ˆAgentï¼Œç›‘æ§å›½é™…åª’ä½“æ•æ‰æ”¿ç­–ä¼ é—»å’Œçªå‘äº‹ä»¶ï¼Œè¯„ä¼°æ–°é—»å½±å“å¼ºåº¦ï¼ˆâŒ ä¸è¾“å‡ºä»“ä½å»ºè®®ï¼‰

**é¢„è®¡æ—¶é—´**ï¼š3-4å¤©  
**ä¼˜å…ˆçº§**ï¼šğŸ”´ æœ€é«˜ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰  
**ä¾èµ–**ï¼šé˜¶æ®µä¸€å·²å®Œæˆï¼ˆMacro/Policy/Sector/Strategy Agentå·²å®ç°ï¼‰

---

## ğŸ¯ æœ¬é˜¶æ®µäº¤ä»˜ç‰©

### æ–°å»ºæ–‡ä»¶
1. `tradingagents/agents/analysts/international_news_analyst.py` - å›½é™…æ–°é—»åˆ†æå¸ˆAgent
2. `tradingagents/tools/international_news_tools.py` - å›½é™…æ–°é—»å·¥å…·
3. `tests/agents/test_international_news_analyst.py` - Agentå•å…ƒæµ‹è¯•
4. `tests/tools/test_international_news_tools.py` - å·¥å…·å•å…ƒæµ‹è¯•

### ä¾èµ–é¡¹
- NewsAPIï¼ˆä»˜è´¹ï¼‰æˆ– Google Newsï¼ˆå…è´¹é™çº§ï¼‰
- langchainï¼šå·¥å…·å°è£…
- pydanticï¼šæ•°æ®æ¨¡å‹

---

## ğŸ“ è¯¦ç»†å¼€å‘ä»»åŠ¡

### ä»»åŠ¡1.1ï¼šåˆ›å»ºå›½é™…æ–°é—»å·¥å…·

**æ–‡ä»¶**ï¼š`tradingagents/tools/international_news_tools.py`

**åŠŸèƒ½æ¸…å•**ï¼š
- [ ] `fetch_bloomberg_news` å·¥å…·
  - æ•°æ®æºï¼šNewsAPI (éœ€è®¢é˜…)
  - å‚æ•°ï¼škeywords (str), lookback_days (int)
  - è¿”å›ï¼šMarkdownæ ¼å¼çš„æ–°é—»æ‘˜è¦
- [ ] `fetch_reuters_news` å·¥å…·
  - æ•°æ®æºï¼šNewsAPI (éœ€è®¢é˜…)
  - é™çº§æ–¹æ¡ˆï¼šGoogle News
- [ ] `fetch_google_news` å·¥å…·
  - å…è´¹æ•°æ®æº
  - æ”¯æŒä¸­è‹±æ–‡å…³é”®è¯æœç´¢
- [ ] å·¥å…·æ³¨å†Œåˆ—è¡¨

**å®ç°è¦ç‚¹**ï¼š
```python
from langchain.tools import tool
from typing import Annotated
import requests
from datetime import datetime, timedelta

@tool
def fetch_bloomberg_news(
    keywords: Annotated[str, "æœç´¢å…³é”®è¯ï¼Œå¦‚'èŠ¯ç‰‡+æ”¿ç­–'"],
    lookback_days: Annotated[int, "å›æº¯å¤©æ•°ï¼Œé»˜è®¤7å¤©"] = 7
) -> str:
    """
    è·å–å½­åšç¤¾æ–°é—»
    
    æ•°æ®æº: NewsAPI (bloomberg.com)
    é™çº§æ–¹æ¡ˆ: Google News
    """
    try:
        # 1. æ£€æŸ¥NewsAPIå¯ç”¨æ€§
        if not NEWS_API_KEY:
            logger.warning("NewsAPIæœªé…ç½®,é™çº§åˆ°Google News")
            return fetch_google_news(keywords, lookback_days)
        
        # 2. è°ƒç”¨NewsAPI
        end_date = datetime.now()
        start_date = end_date - timedelta(days=lookback_days)
        
        url = "https://newsapi.org/v2/everything"
        params = {
            "apiKey": NEWS_API_KEY,
            "sources": "bloomberg",
            "q": keywords,
            "from": start_date.isoformat(),
            "to": end_date.isoformat(),
            "language": "en",
            "sortBy": "publishedAt"
        }
        
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        
        # 3. æ ¼å¼åŒ–ä¸ºMarkdown
        articles = response.json().get("articles", [])
        return format_news_to_markdown(articles, source="Bloomberg")
        
    except Exception as e:
        logger.error(f"å½­åšç¤¾æ–°é—»è·å–å¤±è´¥: {e}, é™çº§åˆ°Google News")
        return fetch_google_news(keywords, lookback_days)


@tool
def fetch_google_news(
    keywords: Annotated[str, "æœç´¢å…³é”®è¯"],
    lookback_days: Annotated[int, "å›æº¯å¤©æ•°"] = 7
) -> str:
    """
    è·å–Google Newsæ–°é—»ï¼ˆå…è´¹é™çº§æ–¹æ¡ˆï¼‰
    """
    try:
        from pygooglenews import GoogleNews
        
        gn = GoogleNews(lang='zh-CN', country='CN')
        search_result = gn.search(keywords)
        
        # æ ¼å¼åŒ–ä¸ºMarkdown
        entries = search_result.get('entries', [])[:10]
        return format_news_to_markdown(entries, source="Google News")
        
    except Exception as e:
        logger.error(f"Google Newsè·å–å¤±è´¥: {e}")
        return f"æ–°é—»è·å–å¤±è´¥: {str(e)}"


def format_news_to_markdown(articles: list, source: str) -> str:
    """æ ¼å¼åŒ–æ–°é—»ä¸ºMarkdown"""
    if not articles:
        return f"## {source}\n\næš‚æ— ç›¸å…³æ–°é—»"
    
    md = f"## {source} æ–°é—»æ‘˜è¦\n\n"
    for i, article in enumerate(articles[:10], 1):
        title = article.get('title', 'æ— æ ‡é¢˜')
        published = article.get('published', article.get('publishedAt', ''))
        description = article.get('description', article.get('summary', ''))
        
        md += f"### {i}. {title}\n"
        md += f"**å‘å¸ƒæ—¶é—´**: {published}\n"
        md += f"**æ‘˜è¦**: {description}\n\n"
    
    return md


# å·¥å…·åˆ—è¡¨
INTERNATIONAL_NEWS_TOOLS = [
    fetch_bloomberg_news,
    fetch_reuters_news,
    fetch_google_news
]
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… NewsAPIé…ç½®æ—¶ä½¿ç”¨ä»˜è´¹æº
- âœ… NewsAPIä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§åˆ°Google News
- âœ… è¿”å›æ ¼å¼åŒ–çš„Markdownæ–‡æœ¬
- âœ… å¼‚å¸¸å¤„ç†å®Œå–„

---

### ä»»åŠ¡1.2ï¼šåˆ›å»ºInternational News Analyst Agent

**æ–‡ä»¶**ï¼š`tradingagents/agents/analysts/international_news_analyst.py`

**åŠŸèƒ½æ¸…å•**ï¼š
- [ ] `create_international_news_analyst` å‡½æ•°
- [ ] èŠ‚ç‚¹å‡½æ•° `international_news_analyst_node`
- [ ] æ–°é—»åˆ†ç±»é€»è¾‘
- [ ] å½±å“æŒç»­æœŸè¯„ä¼°
- [ ] å½±å“å¼ºåº¦è¯„ä¼°ï¼ˆâŒ ä¸è¾“å‡ºä»“ä½ï¼‰
- [ ] å»é‡æœºåˆ¶ï¼ˆè¯»å–Policy AnalystæŠ¥å‘Šï¼‰
- [ ] å·¥å…·è°ƒç”¨è®¡æ•°å™¨ï¼ˆé˜²æ­»å¾ªç¯ï¼‰

**å®ç°è¦ç‚¹**ï¼š
```python
#!/usr/bin/env python3
"""
å›½é™…æ–°é—»åˆ†æå¸ˆ (International News Analyst)

èŒè´£:
- ç›‘æ§å½­åšã€è·¯é€ã€WSJç­‰å›½é™…åª’ä½“
- è¯†åˆ«çŸ­æœŸæ–°é—»äº‹ä»¶ï¼ˆæ”¿ç­–ä¼ é—»/è¡Œä¸šäº‹ä»¶/å¸‚åœºæƒ…ç»ªï¼‰
- è¯„ä¼°æ–°é—»å½±å“æŒç»­æœŸå’Œå½±å“å¼ºåº¦
- âŒ ä¸ç»™å‡ºä»“ä½è°ƒæ•´å»ºè®®ï¼ˆç”±Strategy Advisorå†³ç­–ï¼‰
"""

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import json
from datetime import datetime

from tradingagents.utils.logging_manager import get_logger

logger = get_logger("agents")


def create_international_news_analyst(llm, toolkit):
    """
    åˆ›å»ºå›½é™…æ–°é—»åˆ†æå¸ˆèŠ‚ç‚¹
    
    Args:
        llm: è¯­è¨€æ¨¡å‹å®ä¾‹
        toolkit: å·¥å…·åŒ…
        
    Returns:
        å›½é™…æ–°é—»åˆ†æå¸ˆèŠ‚ç‚¹å‡½æ•°
    """
    
    def international_news_analyst_node(state):
        """å›½é™…æ–°é—»åˆ†æå¸ˆèŠ‚ç‚¹"""
        logger.info("ğŸŒ [å›½é™…æ–°é—»åˆ†æå¸ˆ] èŠ‚ç‚¹å¼€å§‹")
        
        # 1. å·¥å…·è°ƒç”¨è®¡æ•°å™¨ï¼ˆé˜²æ­»å¾ªç¯ï¼‰
        tool_call_count = state.get("international_news_tool_call_count", 0)
        max_tool_calls = 3
        logger.info(f"ğŸ”§ å·¥å…·è°ƒç”¨æ¬¡æ•°: {tool_call_count}/{max_tool_calls}")
        
        # 2. æ£€æŸ¥æ˜¯å¦å·²æœ‰æŠ¥å‘Š
        existing_report = state.get("international_news_report", "")
        if existing_report and len(existing_report) > 100:
            logger.info(f"âœ… [å›½é™…æ–°é—»åˆ†æå¸ˆ] å·²æœ‰æŠ¥å‘Šï¼Œè·³è¿‡åˆ†æ")
            return {
                "messages": state["messages"],
                "international_news_report": existing_report,
                "international_news_tool_call_count": tool_call_count
            }
        
        # 3. é™çº§æ–¹æ¡ˆï¼ˆè¾¾åˆ°æœ€å¤§è°ƒç”¨æ¬¡æ•°ï¼‰
        if tool_call_count >= max_tool_calls:
            logger.warning(f"âš ï¸ [å›½é™…æ–°é—»åˆ†æå¸ˆ] è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°")
            fallback_report = json.dumps({
                "key_news": [],
                "overall_impact": "æ•°æ®è·å–å—é™",
                "impact_strength": "ä½",
                "confidence": 0.3
            }, ensure_ascii=False)
            
            return {
                "messages": state["messages"],
                "international_news_report": fallback_report,
                "international_news_tool_call_count": tool_call_count
            }
        
        # 4. è·å–æŒ‡æ•°ä¿¡æ¯
        index_code = state.get("company_of_interest", "")
        trade_date = state.get("trade_date", "")
        
        # 5. è¯†åˆ«æŒ‡æ•°ç±»å‹ï¼Œç”Ÿæˆæœç´¢å…³é”®è¯
        index_keywords = get_search_keywords(index_code)
        logger.info(f"ğŸŒ [å›½é™…æ–°é—»åˆ†æå¸ˆ] åˆ†ææŒ‡æ•°: {index_code}, å…³é”®è¯: {index_keywords}")
        
        # 6. è¯»å–ä¸Šæ¸¸Policy AnalystæŠ¥å‘Šï¼ˆç”¨äºå»é‡ï¼‰
        policy_report = state.get("policy_report", "")
        
        # 7. æ„å»ºPrompt
        system_prompt = """ä½ æ˜¯ä¸€ä½å›½é™…æ–°é—»åˆ†æå¸ˆï¼Œä¸“æ³¨äºç›‘æ§å½­åšã€è·¯é€ã€åå°”è¡—æ—¥æŠ¥ç­‰å›½é™…åª’ä½“ã€‚

ğŸ“‹ **æ ¸å¿ƒä»»åŠ¡**
- è·å–è¿‘7å¤©å›½é™…åª’ä½“å…³äºç›®æ ‡å¸‚åœº/è¡Œä¸šçš„æ–°é—»
- **é‡ç‚¹å…³æ³¨çŸ­æœŸå½±å“çš„æ–°é—»** (æ”¿ç­–ä¼ é—»ã€çªå‘äº‹ä»¶)
- åŒºåˆ†æ–°é—»ç±»å‹å’Œå½±å“æŒç»­æœŸ
- è¯„ä¼°æ–°é—»å½±å“å¼ºåº¦ (é«˜/ä¸­/ä½)

ğŸ¯ **æ–°é—»åˆ†ç±»æ ‡å‡†**
1. **æ”¿ç­–ä¼ é—»** (é‡ç‚¹å…³æ³¨)
   - å›½é™…åª’ä½“æå‰çˆ†æ–™ä½†å›½å†…æœªç¡®è®¤
   - ç¤ºä¾‹: 'å½­åšç¤¾:ä¸­å›½è®¡åˆ’åƒäº¿èŠ¯ç‰‡æ”¯æŒ'
   - å½±å“æŒç»­æœŸ: ä¸­æœŸ (1-4å‘¨)

2. **æ”¿ç­–å®˜å®£**
   - å·²è¢«å›½å†…å®˜æ–¹ç¡®è®¤çš„æ”¿ç­–
   - âš ï¸ å¦‚æœå·²åœ¨ä¸Šæ¸¸Policy AnalystæŠ¥å‘Šä¸­ â†’ è·³è¿‡
   - å½±å“æŒç»­æœŸ: é•¿æœŸ (æ•°æœˆ)

3. **è¡Œä¸šçªå‘äº‹ä»¶**
   - ç¤ºä¾‹: 'ASMLé™åˆ¶å¯¹åå‡ºå£', 'ç¾å›½èŠ¯ç‰‡æ³•æ¡ˆé€šè¿‡'
   - å½±å“æŒç»­æœŸ: ä¸­æœŸ (1-4å‘¨)

4. **å¸‚åœºæƒ…ç»ª**
   - ç¤ºä¾‹: 'å¤–èµ„å¤§å¹…å¢æŒä¸­å›½ç§‘æŠ€è‚¡'
   - å½±å“æŒç»­æœŸ: çŸ­æœŸ (1-7å¤©)

ğŸ” **å»é‡è§„åˆ™** (é¿å…ä¸Policy Analysté‡å¤)
- å¦‚æœæ–°é—»å·²åœ¨ä¸Šæ¸¸Policy AnalystæŠ¥å‘Šä¸­ â†’ æ ‡æ³¨ä¸º"å·²è¦†ç›–"
- ä»…ä¿ç•™**æœªè¢«Policy Analystè¦†ç›–**çš„çŸ­æœŸæ–°é—»

ğŸ“Š **ä¸Šæ¸¸Policy AnalystæŠ¥å‘Š**
{policy_report}

ğŸ¯ **è¾“å‡ºæ ¼å¼** (ä¸¥æ ¼JSON)
{{
  "key_news": [
    {{
      "source": "Bloomberg",
      "title": "...",
      "date": "2025-12-10",
      "type": "æ”¿ç­–ä¼ é—»" | "è¡Œä¸šäº‹ä»¶" | "å¸‚åœºæƒ…ç»ª",
      "impact": "åˆ©å¥½" | "åˆ©ç©º" | "ä¸­æ€§",
      "impact_duration": "çŸ­æœŸ(1-7å¤©)" | "ä¸­æœŸ(1-4å‘¨)" | "é•¿æœŸ(æ•°æœˆ)",
      "impact_strength": "é«˜" | "ä¸­" | "ä½",
      "credibility": 0.8,
      "covered_by_policy_analyst": false,
      "summary": "æ–°é—»æ‘˜è¦"
    }}
  ],
  "overall_impact": "é‡å¤§åˆ©å¥½" | "åˆ©å¥½" | "ä¸­æ€§" | "åˆ©ç©º" | "é‡å¤§åˆ©ç©º",
  "impact_strength": "é«˜" | "ä¸­" | "ä½",
  "confidence": 0.85
}}

âš ï¸ **é‡è¦**: 
- âŒ ä¸è¦è¾“å‡º position_adjustment å­—æ®µ
- âŒ ä¸è¦è¾“å‡º adjustment_rationale å­—æ®µ
- âœ… åªè¯„ä¼°å½±å“å¼ºåº¦,ä¸ç»™å‡ºä»“ä½å»ºè®®
- âœ… ä»“ä½å†³ç­–ç”±Strategy Advisorç»Ÿä¸€åˆ¶å®š

è¯·ä½¿ç”¨å·¥å…·è·å–å›½é™…æ–°é—»æ•°æ®ï¼Œç„¶åè¿›è¡Œåˆ†æã€‚
"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="messages"),
        ])
        
        prompt = prompt.partial(policy_report=policy_report)
        
        # 8. ç»‘å®šå·¥å…·å¹¶è°ƒç”¨LLM
        tools = [toolkit.get_tool("fetch_bloomberg_news")]
        chain = prompt | llm.bind_tools(tools)
        
        result = chain.invoke({"messages": state["messages"]})
        
        # 9. æ£€æŸ¥å·¥å…·è°ƒç”¨
        tool_calls = getattr(result, 'tool_calls', [])
        logger.info(f"[å›½é™…æ–°é—»åˆ†æå¸ˆ] LLMè°ƒç”¨äº† {len(tool_calls)} ä¸ªå·¥å…·")
        
        if len(tool_calls) == 0:
            # LLMæ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œå¯èƒ½ç›´æ¥ç”Ÿæˆäº†æŠ¥å‘Š
            report = result.content if hasattr(result, 'content') else ""
        else:
            # æœ‰å·¥å…·è°ƒç”¨ï¼Œä½¿ç”¨LangGraphçš„å·¥å…·èŠ‚ç‚¹å¤„ç†
            report = result.content
        
        # 10. æ¸…ç†æ¶ˆæ¯ï¼ˆç§»é™¤tool_callsï¼‰
        from langchain_core.messages import AIMessage
        clean_message = AIMessage(content=report)
        
        logger.info(f"[å›½é™…æ–°é—»åˆ†æå¸ˆ] âœ… åˆ†æå®Œæˆ")
        
        # 11. æ›´æ–°å·¥å…·è°ƒç”¨è®¡æ•°å™¨
        return {
            "messages": [clean_message],
            "international_news_report": report,
            "international_news_tool_call_count": tool_call_count + 1
        }
    
    return international_news_analyst_node


def get_search_keywords(index_code: str) -> str:
    """æ ¹æ®æŒ‡æ•°ä»£ç ç”Ÿæˆæœç´¢å…³é”®è¯"""
    keyword_map = {
        "sh931865": "èŠ¯ç‰‡ åŠå¯¼ä½“ æ”¿ç­–",  # ä¸­è¯èŠ¯ç‰‡äº§ä¸š
        "sz399006": "åˆ›ä¸šæ¿ ç§‘æŠ€ æ”¿ç­–",  # åˆ›ä¸šæ¿æŒ‡
        "sh000300": "Aè‚¡ å¤§ç›˜ æ”¿ç­–",    # æ²ªæ·±300
        "sh000016": "ä¸Šè¯50 è“ç­¹ æ”¿ç­–"   # ä¸Šè¯50
    }
    return keyword_map.get(index_code, "ä¸­å›½ è‚¡å¸‚ æ”¿ç­–")
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- âœ… æˆåŠŸè°ƒç”¨å›½é™…æ–°é—»å·¥å…·
- âœ… æ­£ç¡®åˆ†ç±»æ–°é—»ç±»å‹
- âœ… è¯„ä¼°å½±å“æŒç»­æœŸå’Œå¼ºåº¦
- âœ… å®ç°å»é‡æœºåˆ¶
- âœ… **ä¸è¾“å‡ºposition_adjustmentå­—æ®µ**
- âœ… å·¥å…·è°ƒç”¨è®¡æ•°å™¨ç”Ÿæ•ˆ

---

### ä»»åŠ¡1.3ï¼šç¼–å†™å•å…ƒæµ‹è¯•

**æ–‡ä»¶**ï¼š`tests/agents/test_international_news_analyst.py`

**æµ‹è¯•ç”¨ä¾‹æ¸…å•**ï¼š
- [ ] `test_international_news_analyst_basic()` - åŸºæœ¬åŠŸèƒ½æµ‹è¯•
- [ ] `test_news_classification()` - æ–°é—»åˆ†ç±»æµ‹è¯•
- [ ] `test_impact_assessment()` - å½±å“è¯„ä¼°æµ‹è¯•
- [ ] `test_deduplication()` - å»é‡æœºåˆ¶æµ‹è¯•
- [ ] `test_no_position_output()` - **éªŒè¯ä¸è¾“å‡ºä»“ä½** â­
- [ ] `test_tool_call_limit()` - å·¥å…·è°ƒç”¨ä¸Šé™æµ‹è¯•
- [ ] `test_fallback_mechanism()` - é™çº§æœºåˆ¶æµ‹è¯•

**æ ¸å¿ƒæµ‹è¯•ä»£ç **ï¼š
```python
import pytest
from tradingagents.agents.analysts.international_news_analyst import (
    create_international_news_analyst
)

def test_no_position_output(mock_llm, mock_toolkit):
    """éªŒè¯International News Analystä¸è¾“å‡ºä»“ä½å»ºè®®"""
    # Arrange
    analyst_node = create_international_news_analyst(mock_llm, mock_toolkit)
    state = {
        "company_of_interest": "sh931865",
        "trade_date": "2025-12-14",
        "policy_report": "...",
        "messages": []
    }
    
    # Act
    result = analyst_node(state)
    
    # Assert
    report = result.get("international_news_report", "")
    
    # éªŒè¯ä¸åŒ…å«ä»“ä½è°ƒæ•´å­—æ®µ
    if isinstance(report, str):
        import json
        try:
            report_json = json.loads(report)
            assert "position_adjustment" not in report_json, \
                "âŒ International News Analystä¸åº”è¾“å‡ºposition_adjustment"
            assert "adjustment_rationale" not in report_json, \
                "âŒ International News Analystä¸åº”è¾“å‡ºadjustment_rationale"
            
            # éªŒè¯åŒ…å«å½±å“å¼ºåº¦è¯„ä¼°
            assert "impact_strength" in report_json, \
                "âœ… åº”è¾“å‡ºimpact_strength"
            assert report_json["impact_strength"] in ["é«˜", "ä¸­", "ä½"], \
                "âœ… impact_strengthåº”ä¸ºé«˜/ä¸­/ä½"
                
        except json.JSONDecodeError:
            pytest.skip("æŠ¥å‘ŠéJSONæ ¼å¼,è·³è¿‡éªŒè¯")
```

---

## ğŸ“Š è¿›åº¦è·Ÿè¸ª

### ä»»åŠ¡æ¸…å•

- [ ] **ä»»åŠ¡1.1**: åˆ›å»ºå›½é™…æ–°é—»å·¥å…· (0.5å¤©)
  - [ ] fetch_bloomberg_news
  - [ ] fetch_reuters_news
  - [ ] fetch_google_news
  
- [ ] **ä»»åŠ¡1.2**: åˆ›å»ºInternational News Analyst (2å¤©)
  - [ ] èŠ‚ç‚¹å‡½æ•°å®ç°
  - [ ] Promptè®¾è®¡
  - [ ] å»é‡æœºåˆ¶
  - [ ] å½±å“å¼ºåº¦è¯„ä¼°
  
- [ ] **ä»»åŠ¡1.3**: ç¼–å†™å•å…ƒæµ‹è¯• (1å¤©)
  - [ ] åŸºæœ¬åŠŸèƒ½æµ‹è¯•
  - [ ] èŒè´£åˆ†ç¦»éªŒè¯
  - [ ] è¾¹ç•Œæƒ…å†µæµ‹è¯•

### éªŒæ”¶æ ‡å‡†

âœ… **åŠŸèƒ½éªŒæ”¶**ï¼š
- æˆåŠŸè·å–å›½é™…æ–°é—»
- æ­£ç¡®åˆ†ç±»å’Œè¯„ä¼°
- å»é‡æœºåˆ¶ç”Ÿæ•ˆ

âœ… **èŒè´£åˆ†ç¦»éªŒæ”¶** â­ï¼š
- **ä¸è¾“å‡ºposition_adjustmentå­—æ®µ**
- åªè¾“å‡ºimpact_strengthè¯„ä¼°

âœ… **è´¨é‡éªŒæ”¶**ï¼š
- å•å…ƒæµ‹è¯•è¦†ç›–ç‡â‰¥80%
- ä»£ç å®¡æŸ¥é€šè¿‡
- æ—¥å¿—è®°å½•å®Œæ•´

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### å¼€å‘æ³¨æ„
1. **NewsAPIé…ç½®**: éœ€è¦é…ç½®NEWS_API_KEYç¯å¢ƒå˜é‡
2. **é™çº§æ–¹æ¡ˆ**: Google Newsä½œä¸ºå…è´¹æ›¿ä»£
3. **å»é‡é€»è¾‘**: å¿…é¡»è¯»å–Policy AnalystæŠ¥å‘Š
4. **èŒè´£åˆ†ç¦»**: **ä¸¥ç¦è¾“å‡ºä»“ä½å­—æ®µ**

### æµ‹è¯•æ³¨æ„
1. **Mockå¤–éƒ¨API**: æµ‹è¯•æ—¶Mock NewsAPI
2. **èŒè´£éªŒè¯**: å¿…é¡»éªŒè¯ä¸è¾“å‡ºä»“ä½
3. **è¾¹ç•Œæƒ…å†µ**: æµ‹è¯•APIå¤±è´¥ã€ç©ºæ•°æ®ç­‰

### æ–‡æ¡£æ³¨æ„
1. æ›´æ–°APIæ–‡æ¡£
2. æ·»åŠ ä½¿ç”¨ç¤ºä¾‹
3. è¯´æ˜é™çº§æ–¹æ¡ˆ

---

**é˜¶æ®µè´Ÿè´£äºº**: ___________  
**é¢„è®¡å®Œæˆæ—¥æœŸ**: ___________  
**å®é™…å®Œæˆæ—¥æœŸ**: ___________
