# Reddit ç¤¾äº¤åª’ä½“æ•°æ®é…ç½®è¯´æ˜

## ğŸ“‹ æ¦‚è¿°

TradingAgents-CN çš„ç¾è‚¡ç¤¾äº¤åª’ä½“åˆ†æåŠŸèƒ½ä¾èµ– Reddit ç¦»çº¿æ•°æ®ã€‚æœ¬æ–‡æ¡£è¯´æ˜ Reddit æ•°æ®çš„å‡†å¤‡æ–¹æ³•ã€æ•°æ®æ ¼å¼è¦æ±‚ä»¥åŠæ›¿ä»£æ–¹æ¡ˆã€‚

## âš ï¸ é‡è¦è¯´æ˜

### å½“å‰çŠ¶æ€

- **Reddit åŠŸèƒ½é»˜è®¤ä¸å¯ç”¨**ï¼šé¡¹ç›®æœªåŒ…å« Reddit æ•°æ®ï¼Œä¹Ÿæœªæä¾›æ•°æ®ä¸‹è½½è„šæœ¬
- **æºé¡¹ç›®æƒ…å†µ**ï¼šä¸Šæ¸¸é¡¹ç›® [TauricResearch/TradingAgents](https://github.com/TauricResearch/TradingAgents) ä½¿ç”¨ç§æœ‰æ•°æ®é›† "Tauric TradingDB"ï¼Œè¯¥æ•°æ®é›†å°šæœªå…¬å¼€å‘å¸ƒ
- **è‡ªåŠ¨å›é€€æœºåˆ¶**ï¼šå½“ Reddit æ•°æ®ä¸å¯ç”¨æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨å…¶ä»–æ–°é—»æºï¼ˆAlpha Vantageã€Google News ç­‰ï¼‰

### å½±å“èŒƒå›´

- **ä»…å½±å“ç¾è‚¡åˆ†æ**ï¼šA è‚¡å’Œæ¸¯è‚¡ä¸ä½¿ç”¨ Reddit æ•°æ®
- **ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½**ï¼šå³ä½¿æ²¡æœ‰ Reddit æ•°æ®ï¼Œç¾è‚¡åˆ†æä»å¯æ­£å¸¸è¿›è¡Œ
- **å¯é€‰åŠŸèƒ½**ï¼šReddit æ•°æ®æ˜¯å¢å¼ºåŠŸèƒ½ï¼Œéå¿…éœ€

## ğŸ“ æ•°æ®ç›®å½•ç»“æ„

Reddit æ•°æ®åº”æ”¾ç½®åœ¨ä»¥ä¸‹ä»»ä¸€ç›®å½•ï¼š

```
data/reddit_data/
â”œâ”€â”€ company_news/          # å…¬å¸ç›¸å…³è®¨è®º
â”‚   â”œâ”€â”€ wallstreetbets.jsonl
â”‚   â”œâ”€â”€ stocks.jsonl
â”‚   â””â”€â”€ investing.jsonl
â””â”€â”€ global_news/           # å¸‚åœºæ•´ä½“è®¨è®º
    â”œâ”€â”€ wallstreetbets.jsonl
    â”œâ”€â”€ stocks.jsonl
    â””â”€â”€ investing.jsonl
```

æˆ–ï¼š

```
tradingagents/dataflows/data_cache/reddit_data/
â”œâ”€â”€ company_news/
â””â”€â”€ global_news/
```

## ğŸ“„ æ•°æ®æ ¼å¼è¦æ±‚

### JSONL æ–‡ä»¶æ ¼å¼

æ¯ä¸ª `.jsonl` æ–‡ä»¶åŒ…å«å¤šè¡Œ JSON å¯¹è±¡ï¼Œæ¯è¡Œä¸€ä¸ªå¸–å­ï¼š

```jsonl
{"title": "NVDA earnings beat expectations", "selftext": "Nvidia reported...", "url": "https://reddit.com/...", "ups": 1234, "created_utc": 1704067200}
{"title": "Tesla stock analysis", "selftext": "Looking at TSLA...", "url": "https://reddit.com/...", "ups": 567, "created_utc": 1704070800}
```

### å¿…éœ€å­—æ®µ

| å­—æ®µ | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|------|
| `title` | string | å¸–å­æ ‡é¢˜ | "NVDA earnings beat expectations" |
| `selftext` | string | å¸–å­æ­£æ–‡ | "Nvidia reported Q4 earnings..." |
| `url` | string | å¸–å­é“¾æ¥ | "https://reddit.com/r/wallstreetbets/..." |
| `ups` | integer | ç‚¹èµæ•° | 1234 |
| `created_utc` | integer | å‘å¸ƒæ—¶é—´ï¼ˆUnix æ—¶é—´æˆ³ï¼‰ | 1704067200 |

## ğŸ”§ æ•°æ®è·å–æ–¹æ³•

### æ–¹æ³• 1ï¼šç­‰å¾…å®˜æ–¹æ•°æ®é›†ï¼ˆæ¨èï¼‰

ä¸Šæ¸¸é¡¹ç›®è®¡åˆ’å‘å¸ƒ "Tauric TradingDB" æ•°æ®é›†ï¼ŒåŒ…å«ï¼š
- Reddit å†å²æ•°æ®
- Finnhub æ–°é—»æ•°æ®
- SimFin è´¢åŠ¡æ•°æ®

**çŠ¶æ€**ï¼šå¼€å‘ä¸­ï¼Œå‘å¸ƒæ—¶é—´æœªå®š

**å…³æ³¨æ¸ é“**ï¼š
- GitHub: https://github.com/TauricResearch/TradingAgents
- å®˜ç½‘: https://tauric.ai/

### æ–¹æ³• 2ï¼šä½¿ç”¨ Reddit API è‡ªè¡Œä¸‹è½½

#### å‰ç½®æ¡ä»¶

1. **æ³¨å†Œ Reddit åº”ç”¨**
   - è®¿é—®ï¼šhttps://www.reddit.com/prefs/apps
   - åˆ›å»ºåº”ç”¨ï¼Œé€‰æ‹© "script" ç±»å‹
   - è·å– `client_id` å’Œ `client_secret`

2. **å®‰è£… praw åº“**
   ```bash
   pip install praw
   ```

3. **é…ç½®ç¯å¢ƒå˜é‡**
   ```bash
   # .env æ–‡ä»¶
   REDDIT_CLIENT_ID=your_client_id_here
   REDDIT_CLIENT_SECRET=your_client_secret_here
   REDDIT_USER_AGENT=TradingAgents-CN/1.0
   ```

#### ä¸‹è½½è„šæœ¬ç¤ºä¾‹

åˆ›å»º `scripts/download_reddit_data.py`ï¼š

```python
import praw
import json
import os
from datetime import datetime, timedelta

# åˆå§‹åŒ– Reddit å®¢æˆ·ç«¯
reddit = praw.Reddit(
    client_id=os.getenv('REDDIT_CLIENT_ID'),
    client_secret=os.getenv('REDDIT_CLIENT_SECRET'),
    user_agent=os.getenv('REDDIT_USER_AGENT')
)

# ç›®æ ‡ subreddit
subreddits = ['wallstreetbets', 'stocks', 'investing']

# è¾“å‡ºç›®å½•
output_dir = 'data/reddit_data/company_news'
os.makedirs(output_dir, exist_ok=True)

# ä¸‹è½½æ•°æ®
for subreddit_name in subreddits:
    subreddit = reddit.subreddit(subreddit_name)
    output_file = os.path.join(output_dir, f'{subreddit_name}.jsonl')
    
    with open(output_file, 'w', encoding='utf-8') as f:
        # è·å–æœ€è¿‘ 7 å¤©çš„çƒ­é—¨å¸–å­
        for post in subreddit.hot(limit=1000):
            data = {
                'title': post.title,
                'selftext': post.selftext,
                'url': post.url,
                'ups': post.ups,
                'created_utc': int(post.created_utc)
            }
            f.write(json.dumps(data, ensure_ascii=False) + '\n')
    
    print(f'Downloaded {subreddit_name} data to {output_file}')
```

#### æ³¨æ„äº‹é¡¹

- **API é™åˆ¶**ï¼šReddit API æœ‰ä¸¥æ ¼çš„é€Ÿç‡é™åˆ¶ï¼ˆæ¯åˆ†é’Ÿçº¦ 60 æ¬¡è¯·æ±‚ï¼‰
- **æ•°æ®é‡**ï¼šå»ºè®®åˆ†æ‰¹ä¸‹è½½ï¼Œé¿å…ä¸€æ¬¡æ€§è¯·æ±‚è¿‡å¤š
- **æ—¶é—´èŒƒå›´**ï¼šæ ¹æ®éœ€è¦è°ƒæ•´æ—¶é—´èŒƒå›´ï¼ˆé»˜è®¤ 7 å¤©ï¼‰
- **å­˜å‚¨ç©ºé—´**ï¼šReddit æ•°æ®å¯èƒ½è¾ƒå¤§ï¼Œæ³¨æ„ç£ç›˜ç©ºé—´

### æ–¹æ³• 3ï¼šä½¿ç”¨ç¬¬ä¸‰æ–¹æ•°æ®é›†

#### Pushshift Reddit æ•°æ®é›†

- **ç½‘ç«™**ï¼šhttps://files.pushshift.io/reddit/
- **è¯´æ˜**ï¼šReddit å†å²æ•°æ®å½’æ¡£
- **æ ¼å¼**ï¼šéœ€è¦è½¬æ¢ä¸ºé¡¹ç›®æ‰€éœ€çš„ JSONL æ ¼å¼
- **ä¼˜ç‚¹**ï¼šæ•°æ®å®Œæ•´ï¼Œè¦†ç›–æ—¶é—´é•¿
- **ç¼ºç‚¹**ï¼šæ•°æ®é‡å·¨å¤§ï¼ˆTB çº§ï¼‰ï¼Œéœ€è¦å¤„ç†å’Œç­›é€‰

#### Kaggle æ•°æ®é›†

æœç´¢å…³é”®è¯ï¼š
- "Reddit wallstreetbets"
- "Reddit stock discussion"
- "Reddit financial data"

## ğŸ”„ æ›¿ä»£æ–¹æ¡ˆ

å¦‚æœæ— æ³•è·å– Reddit æ•°æ®ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨ä»¥ä¸‹æ›¿ä»£æ–¹æ¡ˆï¼š

### 1. Alpha Vantage æ–°é—»ï¼ˆæ¨èï¼‰

**ä¼˜ç‚¹**ï¼š
- å®˜æ–¹åˆä½œä¼™ä¼´ï¼ŒAPI ç¨³å®š
- æ–°é—»è´¨é‡é«˜ï¼Œè¦†ç›–é¢å¹¿
- å…è´¹é¢åº¦å……è¶³ï¼ˆ60 æ¬¡/åˆ†é’Ÿï¼‰

**é…ç½®**ï¼š
```bash
# .env æ–‡ä»¶
ALPHA_VANTAGE_API_KEY=your_api_key_here
```

### 2. Google News

**ä¼˜ç‚¹**ï¼š
- å…è´¹ï¼Œæ— éœ€ API key
- æ–°é—»æ¥æºå¤šæ ·
- å®æ—¶æ›´æ–°

**ç¼ºç‚¹**ï¼š
- å¯èƒ½å—ç½‘ç»œé™åˆ¶
- éœ€è¦é…ç½®ä»£ç†

### 3. Finnhub æ–°é—»

**ä¼˜ç‚¹**ï¼š
- ä¸“ä¸šè´¢ç»æ–°é—»
- æ”¯æŒæƒ…ç»ªåˆ†æ

**é…ç½®**ï¼š
```bash
# .env æ–‡ä»¶
FINNHUB_API_KEY=your_api_key_here
```

## âœ… éªŒè¯æ•°æ®é…ç½®

### æ£€æŸ¥æ•°æ®ç›®å½•

```bash
# æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
ls -la data/reddit_data/

# æ£€æŸ¥æ–‡ä»¶å†…å®¹
head -n 5 data/reddit_data/company_news/wallstreetbets.jsonl
```

### æµ‹è¯•æ•°æ®è¯»å–

```python
# åœ¨ Python ä¸­æµ‹è¯•
from tradingagents.dataflows.interface import get_reddit_company_news

# æµ‹è¯•è¯»å– NVDA çš„ Reddit è®¨è®º
news = get_reddit_company_news("NVDA", "2024-01-01")
print(news)
```

### æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—

```bash
# å¯åŠ¨åˆ†ææ—¶æŸ¥çœ‹æ—¥å¿—
# å¦‚æœ Reddit æ•°æ®ä¸å¯ç”¨ï¼Œä¼šçœ‹åˆ°å›é€€æç¤º
tail -f logs/tradingagents.log
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: Reddit æ•°æ®ç›®å½•ä¸å­˜åœ¨

**ç°è±¡**ï¼šåˆ†ææŠ¥å‘Šä¸­æ²¡æœ‰ Reddit è®¨è®ºå†…å®¹

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ç¡®è®¤è¿™æ˜¯æ­£å¸¸æƒ…å†µï¼ˆé»˜è®¤ä¸åŒ…å« Reddit æ•°æ®ï¼‰
2. ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨å…¶ä»–æ–°é—»æº
3. å¦‚éœ€ Reddit æ•°æ®ï¼ŒæŒ‰æœ¬æ–‡æ¡£æ–¹æ³•å‡†å¤‡

### Q2: Reddit API é€Ÿç‡é™åˆ¶

**ç°è±¡**ï¼šä¸‹è½½æ•°æ®æ—¶å‡ºç° 429 é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# åœ¨ä¸‹è½½è„šæœ¬ä¸­æ·»åŠ å»¶è¿Ÿ
import time
time.sleep(1)  # æ¯æ¬¡è¯·æ±‚åç­‰å¾… 1 ç§’
```

### Q3: æ•°æ®æ ¼å¼é”™è¯¯

**ç°è±¡**ï¼šç³»ç»Ÿæ— æ³•è¯»å– Reddit æ•°æ®

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥ JSONL æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼‰
2. ç¡®è®¤å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
3. éªŒè¯ Unix æ—¶é—´æˆ³æ ¼å¼

### Q4: ä¸­æ–‡å¸‚åœºèƒ½å¦ä½¿ç”¨ Redditï¼Ÿ

**å›ç­”**ï¼š
- A è‚¡å’Œæ¸¯è‚¡ä¸ä½¿ç”¨ Reddit æ•°æ®
- ä¸­æ–‡å¸‚åœºä½¿ç”¨å…¶ä»–æ–°é—»æºï¼ˆTushareã€AkShareã€ä¸œæ–¹è´¢å¯Œç­‰ï¼‰
- æœªæ¥å¯èƒ½æ”¯æŒä¸­æ–‡ç¤¾äº¤åª’ä½“ï¼ˆé›ªçƒã€è‚¡å§ç­‰ï¼‰

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [Finnhub æ•°æ®é…ç½®](./finnhub-news-data-setup.md)
- [æ•°æ®ç›®å½•é…ç½®](../configuration/data-directory-configuration.md)
- [æµ‹è¯•æŒ‡å—](../guides/TESTING_GUIDE.md)
- [v1.0.0-preview æµ‹è¯•è®¡åˆ’](../tests/v1.0.0-preview/v1.0.0-preview-test-plan.md)

## ğŸ”— å¤–éƒ¨èµ„æº

- [Reddit API æ–‡æ¡£](https://www.reddit.com/dev/api/)
- [PRAW æ–‡æ¡£](https://praw.readthedocs.io/)
- [TauricResearch GitHub](https://github.com/TauricResearch/TradingAgents)
- [Pushshift æ•°æ®é›†](https://files.pushshift.io/reddit/)

## ğŸ“ æ›´æ–°æ—¥å¿—

- **2025-01-23**ï¼šåˆ›å»ºæ–‡æ¡£ï¼Œè¯´æ˜ Reddit æ•°æ®é…ç½®æ–¹æ³•å’Œæ›¿ä»£æ–¹æ¡ˆ

