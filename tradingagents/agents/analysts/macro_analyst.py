#!/usr/bin/env python3
"""
å®è§‚ç»æµåˆ†æå¸ˆ (Macro Analyst)

èŒè´£:
- åˆ†æå®è§‚ç»æµæŒ‡æ ‡ï¼ˆGDPã€CPIã€PMIã€M2ã€LPRç­‰ï¼‰
- åˆ¤æ–­ç»æµå‘¨æœŸé˜¶æ®µï¼ˆå¤è‹/æ‰©å¼ /æ»èƒ€/è¡°é€€ï¼‰
- è¯„ä¼°æµåŠ¨æ€§çŠ¶å†µï¼ˆå®½æ¾/ä¸­æ€§/ç´§ç¼©ï¼‰
- ç»™å‡ºå®è§‚æƒ…ç»ªè¯„åˆ†
"""

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import json

from tradingagents.utils.logging_manager import get_logger

logger = get_logger("agents")


def create_macro_analyst(llm, toolkit):
    """
    åˆ›å»ºå®è§‚ç»æµåˆ†æå¸ˆèŠ‚ç‚¹
    
    Args:
        llm: è¯­è¨€æ¨¡å‹å®ä¾‹
        toolkit: å·¥å…·åŒ…ï¼ŒåŒ…å«fetch_macro_dataç­‰å·¥å…·
        
    Returns:
        å®è§‚åˆ†æå¸ˆèŠ‚ç‚¹å‡½æ•°
    """
    
    def macro_analyst_node(state):
        """å®è§‚ç»æµåˆ†æå¸ˆèŠ‚ç‚¹"""
        logger.info("ğŸŒ [å®è§‚åˆ†æå¸ˆ] èŠ‚ç‚¹å¼€å§‹")
        
        # 1. å·¥å…·è°ƒç”¨è®¡æ•°å™¨ - é˜²æ­¢æ­»å¾ªç¯
        tool_call_count = state.get("macro_tool_call_count", 0)
        max_tool_calls = 5  # å¢åŠ æœ€å¤§è°ƒç”¨æ¬¡æ•°åˆ°5æ¬¡
        logger.info(f"ğŸ”§ [æ­»å¾ªç¯ä¿®å¤] å®è§‚åˆ†æå¸ˆå·¥å…·è°ƒç”¨æ¬¡æ•°: {tool_call_count}/{max_tool_calls}")
        
        # 2. æ£€æŸ¥æ˜¯å¦å·²æœ‰æŠ¥å‘Š
        existing_report = state.get("macro_report", "")
        if existing_report and len(existing_report) > 100:
            logger.info(f"âœ… [å®è§‚åˆ†æå¸ˆ] å·²æœ‰æŠ¥å‘Šï¼Œè·³è¿‡åˆ†æ")
            return {
                "messages": state["messages"],
                "macro_report": existing_report,
                "macro_tool_call_count": tool_call_count
            }
        
        # 3. é™çº§æ–¹æ¡ˆï¼šè¾¾åˆ°æœ€å¤§æ¬¡æ•°æ—¶è¿”å›é™çº§æŠ¥å‘Š
        if tool_call_count >= max_tool_calls:
            logger.warning(f"âš ï¸ [å®è§‚åˆ†æå¸ˆ] è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œè¿”å›é™çº§æŠ¥å‘Š")
            fallback_report = json.dumps({
                "economic_cycle": "ä¸­æ€§",
                "liquidity": "ä¸­æ€§",
                "key_indicators": ["æ•°æ®è·å–å—é™"],
                "analysis_summary": "ç”±äºæ•°æ®è·å–é™åˆ¶ï¼Œæ— æ³•è¿›è¡Œå®Œæ•´çš„å®è§‚åˆ†æã€‚å»ºè®®ç¨åé‡è¯•ã€‚",
                "confidence": 0.3,
                "sentiment_score": 0.0,
                "data_note": "æ³¨æ„ï¼šå®è§‚æ•°æ®é€šå¸¸ä¸ºå†å²æ•°æ®ï¼Œéå®æ—¶æ•°æ®ã€‚GDPã€CPIç­‰æ•°æ®æ›´æ–°é¢‘ç‡è¾ƒä½ã€‚"
            }, ensure_ascii=False)
            
            return {
                "messages": state["messages"],
                "macro_report": fallback_report,
                "macro_tool_call_count": tool_call_count
            }
        
        # 4. è·å–å½“å‰æ—¥æœŸ
        current_date = state.get("trade_date", "")
        index_code = state.get("company_of_interest", "")
        
        logger.info(f"ğŸŒ [å®è§‚åˆ†æå¸ˆ] åˆ†ææŒ‡æ•°: {index_code}, æ—¥æœŸ: {current_date}")
        
        # 5. æ„å»ºPrompt
        prompt = ChatPromptTemplate.from_messages([
            (
                "system",
                "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å®è§‚ç»æµåˆ†æå¸ˆï¼Œä¸“æ³¨äºæŒ‡æ•°åˆ†æã€‚\n"
                "\n"
                "ğŸ“‹ **åˆ†æä»»åŠ¡**\n"
                "- è·å–æœ€æ–°çš„å®è§‚ç»æµæ•°æ®\n"
                "- åˆ†æç»æµå‘¨æœŸé˜¶æ®µ\n"
                "- è¯„ä¼°æµåŠ¨æ€§ç¯å¢ƒ\n"
                "- æç‚¼å…³é”®æŒ‡æ ‡\n"
                "- ç»™å‡ºå®è§‚æƒ…ç»ªè¯„åˆ†\n"
                "\n"
                "ğŸ“Š **åˆ†æç»´åº¦**\n"
                "1. **ç»æµå‘¨æœŸåˆ¤æ–­**ï¼ˆåŸºäºGDPã€PMIï¼‰\n"
                "   - å¤è‹: GDPå¢é€Ÿå›å‡ + PMI > 50\n"
                "   - æ‰©å¼ : GDPé«˜é€Ÿå¢é•¿ + PMI > 52\n"
                "   - æ»èƒ€: GDPå¢é€Ÿä¸‹é™ + CPIé«˜ä¼\n"
                "   - è¡°é€€: GDPè´Ÿå¢é•¿ + PMI < 50\n"
                "\n"
                "2. **æµåŠ¨æ€§è¯„ä¼°**ï¼ˆåŸºäºM2ã€LPRï¼‰\n"
                "   - å®½æ¾: M2å¢é€Ÿ > 10% ä¸” LPRä¸‹é™\n"
                "   - ä¸­æ€§: M2å¢é€Ÿ 8-10%\n"
                "   - ç´§ç¼©: M2å¢é€Ÿ < 8% ä¸” LPRä¸Šå‡\n"
                "\n"
                "3. **æƒ…ç»ªè¯„åˆ†è§„åˆ™**\n"
                "   - ç»æµæ‰©å¼  + æµåŠ¨æ€§å®½æ¾: 0.6 ~ 0.8\n"
                "   - ç»æµå¤è‹ + æµåŠ¨æ€§ä¸­æ€§: 0.3 ~ 0.5\n"
                "   - ç»æµè¡°é€€ + æµåŠ¨æ€§ç´§ç¼©: -0.8 ~ -0.5\n"
                "\n"
                "ğŸ¯ **è¾“å‡ºè¦æ±‚**\n"
                "å¿…é¡»è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:\n"
                "``json\n"
                "{{\n"
                "  \"economic_cycle\": \"å¤è‹|æ‰©å¼ |æ»èƒ€|è¡°é€€\",\n"
                "  \"liquidity\": \"å®½æ¾|ä¸­æ€§|ç´§ç¼©\",\n"
                "  \"key_indicators\": [\"GDPå¢é€ŸX%\", \"CPIåŒæ¯”X%\", \"PMI=XX\"],\n"
                "  \"analysis_summary\": \"100-200å­—çš„åˆ†ææ€»ç»“\",\n"
                "  \"confidence\": 0.0-1.0,\n"
                "  \"sentiment_score\": -1.0åˆ°1.0,\n"
                "  \"data_note\": \"å…³äºæ•°æ®æ—¶æ•ˆæ€§çš„è¯´æ˜\"\n"
                "}}\n"
                "```\n"
                "\n"
                "âš ï¸ **æ³¨æ„äº‹é¡¹**\n"
                "- å…ˆè°ƒç”¨fetch_macro_dataå·¥å…·è·å–æ•°æ®\n"
                "- åŸºäºæ•°æ®è¿›è¡Œå®¢è§‚åˆ†æ\n"
                "- JSONæ ¼å¼å¿…é¡»ä¸¥æ ¼\n"
                "- confidenceå’Œsentiment_scoreå¿…é¡»åœ¨æœ‰æ•ˆèŒƒå›´å†…\n"
                "- è¯·æ³¨æ„ï¼šå®è§‚æ•°æ®ï¼ˆGDPã€CPIã€PMIç­‰ï¼‰é€šå¸¸æ˜¯å†å²æ•°æ®ï¼Œæ›´æ–°é¢‘ç‡è¾ƒä½ï¼Œéœ€è¦åœ¨æŠ¥å‘Šä¸­è¯´æ˜\n"
            ),
            MessagesPlaceholder(variable_name="messages"),
        ])
        
        # 6. ç»‘å®šå·¥å…·
        from tradingagents.tools.index_tools import fetch_macro_data
        tools = [fetch_macro_data]
        
        logger.info(f"ğŸŒ [å®è§‚åˆ†æå¸ˆ] ç»‘å®šå·¥å…·: fetch_macro_data")
        
        chain = prompt | llm.bind_tools(tools)
        
        # 7. è°ƒç”¨LLM
        logger.info(f"ğŸŒ [å®è§‚åˆ†æå¸ˆ] å¼€å§‹è°ƒç”¨LLM...")
        result = chain.invoke({"messages": state["messages"]})
        logger.info(f"ğŸŒ [å®è§‚åˆ†æå¸ˆ] LLMè°ƒç”¨å®Œæˆ")
        
        # 8. å¤„ç†ç»“æœ
        logger.info(f"ğŸŒ [å®è§‚åˆ†æå¸ˆ] å“åº”ç±»å‹: {type(result).__name__}")
        logger.info(f"ğŸŒ [å®è§‚åˆ†æå¸ˆ] å“åº”å†…å®¹å‰500å­—ç¬¦: {str(result.content)[:500]}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        has_tool_calls = hasattr(result, 'tool_calls') and result.tool_calls and len(result.tool_calls) > 0
        
        if has_tool_calls:
            logger.info(f"ğŸŒ [å®è§‚åˆ†æå¸ˆ] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œè¿”å›ç­‰å¾…å·¥å…·æ‰§è¡Œ")
            return {
                "messages": [result],
                "macro_tool_call_count": tool_call_count + 1
            }
        
        # 9. æå–JSONæŠ¥å‘Š
        report = _extract_json_report(result.content)
        
        if report:
            logger.info(f"âœ… [å®è§‚åˆ†æå¸ˆ] JSONæŠ¥å‘Šæå–æˆåŠŸ: {len(report)} å­—ç¬¦")
        else:
            logger.warning(f"âš ï¸ [å®è§‚åˆ†æå¸ˆ] JSONæŠ¥å‘Šæå–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
            report = result.content
        
        # 10. è¿”å›çŠ¶æ€æ›´æ–°
        return {
            "messages": [result],
            "macro_report": report,
            "macro_tool_call_count": tool_call_count + 1
        }
    
    return macro_analyst_node


def _extract_json_report(content: str) -> str:
    """
    ä»LLMå›å¤ä¸­æå–JSONæŠ¥å‘Š
    
    Args:
        content: LLMçš„å›å¤å†…å®¹
        
    Returns:
        str: JSONå­—ç¬¦ä¸²ï¼Œå¦‚æœæå–å¤±è´¥åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    try:
        # æŸ¥æ‰¾JSONå—
        if '{' in content and '}' in content:
            start_idx = content.index('{')
            end_idx = content.rindex('}') + 1
            json_str = content[start_idx:end_idx]
            
            # éªŒè¯JSONæœ‰æ•ˆæ€§
            json.loads(json_str)
            
            logger.info(f"âœ… [å®è§‚åˆ†æå¸ˆ] JSONæå–æˆåŠŸ: {json_str[:200]}...")
            return json_str
        else:
            logger.warning(f"âš ï¸ [å®è§‚åˆ†æå¸ˆ] å†…å®¹ä¸­æœªæ‰¾åˆ°JSONæ ‡è®°")
            return ""
    
    except json.JSONDecodeError as e:
        logger.warning(f"âš ï¸ [å®è§‚åˆ†æå¸ˆ] JSONè§£æå¤±è´¥: {e}")
        return ""
    except Exception as e:
        logger.error(f"âŒ [å®è§‚åˆ†æå¸ˆ] JSONæå–å¼‚å¸¸: {e}")
        return ""
