import logging
from typing import Annotated
try:
    from langchain_core.pydantic_v1 import BaseModel, Field
except ImportError:
    from pydantic import BaseModel, Field

from tradingagents.utils.logging_init import get_logger
from tradingagents.utils.tool_logging import log_tool_call

logger = get_logger("tools.local.sentiment")

def create_unified_sentiment_tool(toolkit):
    """åˆ›å»ºç»Ÿä¸€æƒ…ç»ªåˆ†æå·¥å…·å‡½æ•°"""
    
    class UnifiedSentimentInput(BaseModel):
        ticker: str = Field(description="è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰")
        curr_date: str = Field(description="å½“å‰æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD")
        start_date: Annotated[str, Field(description="å¯é€‰ï¼šå¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œå¦‚æœä¸æä¾›åˆ™é»˜è®¤åˆ†æcurr_dateå½“å¤©")] = None
        end_date: Annotated[str, Field(description="å¯é€‰ï¼šç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œå¦‚æœä¸æä¾›åˆ™é»˜è®¤åˆ†æcurr_dateå½“å¤©")] = None
        source_name: Annotated[str, Field(description="å¯é€‰ï¼šæŒ‡å®šæ•°æ®æºåç§°ï¼ˆå¦‚'é›ªçƒ'ã€'Reddit'ï¼‰ï¼Œå¦‚æœä¸æ”¯æŒå°†è‡ªåŠ¨å¿½ç•¥")] = None

    @log_tool_call(tool_name="get_stock_sentiment_unified", log_args=True)
    def get_stock_sentiment_unified(
        ticker: str,
        curr_date: str,
        start_date: str = None,
        end_date: str = None,
        source_name: str = None
    ) -> str:
        """
        ç»Ÿä¸€çš„è‚¡ç¥¨æƒ…ç»ªåˆ†æå·¥å…·
        è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰å¹¶è°ƒç”¨ç›¸åº”çš„æƒ…ç»ªæ•°æ®æºã€‚
        è¯·æ³¨æ„ï¼šé€šå¸¸åªéœ€è¦æä¾› ticker å’Œ curr_dateã€‚
        """
        logger.info(f"ğŸ˜Š [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] åˆ†æè‚¡ç¥¨: {ticker}")

        try:
            from tradingagents.utils.stock_utils import StockUtils

            # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
            market_info = StockUtils.get_market_info(ticker)
            is_china = market_info['is_china']
            is_hk = market_info['is_hk']
            is_us = market_info['is_us']

            logger.info(f"ğŸ˜Š [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")

            result_data = []

            if is_china or is_hk:
                # ä¸­å›½Aè‚¡å’Œæ¸¯è‚¡ï¼šä½¿ç”¨ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æ
                logger.info(f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] å¤„ç†ä¸­æ–‡å¸‚åœºæƒ…ç»ª...")

                try:
                    from tradingagents.dataflows.interface import get_chinese_social_sentiment
                    sentiment_data = get_chinese_social_sentiment(ticker, curr_date)
                    
                    if sentiment_data and len(sentiment_data) > 50:
                        result_data.append(f"## ä¸­æ–‡ç¤¾äº¤åª’ä½“æƒ…ç»ª\n{sentiment_data}")
                        logger.info(f"âœ… [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] ä¸­æ–‡æƒ…ç»ªæ•°æ®è·å–æˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] ä¸­æ–‡æƒ…ç»ªæ•°æ®ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œå°è¯•å¤‡ç”¨æº")
                        # å¤‡ç”¨ï¼šRedditæ–°é—»ï¼ˆå¯èƒ½åŒ…å«ç›¸å…³è®¨è®ºï¼‰
                        from tradingagents.dataflows.interface import get_reddit_company_news
                        reddit_data = get_reddit_company_news(ticker, curr_date, 7, 5)
                        result_data.append(f"## Redditè®¨è®º(å¤‡ç”¨)\n{reddit_data}")

                except Exception as e:
                    logger.error(f"âŒ [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] ä¸­æ–‡æƒ…ç»ªè·å–å¤±è´¥: {e}")
                    result_data.append(f"## å¸‚åœºæƒ…ç»ªåˆ†æ\nè·å–å¤±è´¥: {e}")

            else:
                # ç¾è‚¡ï¼šä½¿ç”¨Finnhubå†…å¹•äº¤æ˜“å’Œæƒ…ç»ªæ•°æ®
                logger.info(f"ğŸ‡ºğŸ‡¸ [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] å¤„ç†ç¾è‚¡å¸‚åœºæƒ…ç»ª...")

                try:
                    # 1. è·å–å†…å¹•äº¤æ˜“æƒ…ç»ª
                    if hasattr(toolkit, 'get_finnhub_company_insider_sentiment'):
                        insider_sentiment = toolkit.get_finnhub_company_insider_sentiment.invoke({"ticker": ticker, "curr_date": curr_date})
                        result_data.append(f"## å†…éƒ¨äººå£«æƒ…ç»ª\n{insider_sentiment}")
                    
                    # 2. è·å–Redditè®¨è®º
                    if hasattr(toolkit, 'get_reddit_stock_info'):
                        reddit_info = toolkit.get_reddit_stock_info.invoke({"ticker": ticker, "curr_date": curr_date})
                        result_data.append(f"## Redditè®¨è®º\n{reddit_info}")

                except Exception as e:
                    logger.error(f"âŒ [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] ç¾è‚¡æƒ…ç»ªè·å–å¤±è´¥: {e}")
                    result_data.append(f"## å¸‚åœºæƒ…ç»ªåˆ†æ\nè·å–å¤±è´¥: {e}")

            # ç»„åˆæ‰€æœ‰æ•°æ®
            combined_result = f"""# {ticker} å¸‚åœºæƒ…ç»ªåˆ†æ

**è‚¡ç¥¨ç±»å‹**: {market_info['market_name']}
**åˆ†ææ—¥æœŸ**: {curr_date}

{chr(10).join(result_data)}

---
*æ•°æ®æ¥æº: ç¤¾äº¤åª’ä½“ã€æ–°é—»è¯„è®ºåŠå†…éƒ¨äº¤æ˜“æ•°æ®*
"""
            return combined_result

        except Exception as e:
            error_msg = f"ç»Ÿä¸€æƒ…ç»ªåˆ†æå·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ [ç»Ÿä¸€æƒ…ç»ªå·¥å…·] {error_msg}")
            return error_msg

    # è®¾ç½®å·¥å…·å±æ€§
    get_stock_sentiment_unified.name = "get_stock_sentiment_unified"
    get_stock_sentiment_unified.description = """
ç»Ÿä¸€è‚¡ç¥¨æƒ…ç»ªåˆ†æå·¥å…· - è·å–å¸‚åœºå¯¹è‚¡ç¥¨çš„æƒ…ç»ªå€¾å‘ã€‚
è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹å¹¶è°ƒç”¨ç›¸åº”æ•°æ®æºï¼ˆå¦‚ä¸­å›½ç¤¾äº¤åª’ä½“ã€Redditã€å†…éƒ¨äº¤æ˜“ç­‰ï¼‰ã€‚
è¿”å›æ•°æ®åŒ…æ‹¬ï¼šæŠ•èµ„è€…æƒ…ç»ªæŒ‡æ•°ã€ç¤¾äº¤åª’ä½“çƒ­åº¦ã€å†…éƒ¨äººå£«äº¤æ˜“ä¿¡å·ç­‰ã€‚
"""
    get_stock_sentiment_unified.args_schema = UnifiedSentimentInput
    
    return get_stock_sentiment_unified
