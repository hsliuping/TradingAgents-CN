import asyncio
import time
from datetime import datetime, timedelta
from typing import Dict, Any, Optional

from tradingagents.config.database_manager import get_database_manager
from tradingagents.dataflows.hybrid_provider import HybridIndexDataProvider
from tradingagents.utils.logging_init import get_logger

logger = get_logger("default")

class DataSourceProbe:
    """
    æ•°æ®æºå¯ç”¨æ€§æ¢æµ‹å™¨
    
    è´Ÿè´£åœ¨ Workflow æ‰§è¡Œå‰æ¢æµ‹å„ä¸ªæ•°æ®æºï¼ˆAPI å’Œ Cacheï¼‰çš„å¯ç”¨æ€§ã€‚
    æ”¯æŒå¹¶è¡Œå¼‚æ­¥æ¢æµ‹ï¼Œå¹¶å®ç°"ç¼“å­˜ä¼˜å…ˆ"ç­–ç•¥ã€‚
    """
    
    @staticmethod
    async def _check_mongodb_cache(collection_name: str, key_prefix: str, ttl_days: int) -> bool:
        """æ£€æŸ¥ MongoDB ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”åœ¨æœ‰æ•ˆæœŸå†…"""
        try:
            db_manager = get_database_manager()
            mongo_db = db_manager.get_mongodb_db()
            
            if mongo_db is None:
                return False
                
            collection = mongo_db[collection_name]
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ key æ˜¯åŸºäºæ—¥æœŸçš„ï¼Œæˆ‘ä»¬æŸ¥æ‰¾æœ€è¿‘çš„ä¸€æ¡è®°å½•
            # æˆ–è€…æˆ‘ä»¬éœ€è¦å…·ä½“çš„ keyã€‚ä½†åœ¨æ¢æµ‹é˜¶æ®µï¼Œæˆ‘ä»¬å¯èƒ½ä¸çŸ¥é“å…·ä½“çš„ date å‚æ•°ã€‚
            # ç­–ç•¥ï¼šæŸ¥æ‰¾æœ€è¿‘æ›´æ–°çš„ä¸€æ¡è®°å½•ï¼Œå¦‚æœåœ¨ ttl å†…ï¼Œåˆ™è®¤ä¸ºç¼“å­˜ç³»ç»Ÿå¯ç”¨ä¸”æœ‰æ•°æ®
            
            # è·å–æœ€æ–°çš„ä¸€æ¡è®°å½•
            # cursor = collection.find().sort("timestamp", -1).limit(1)
            # async for doc in cursor: # å¦‚æœæ˜¯ motor å¼‚æ­¥é©±åŠ¨
            #     # ä½†ç›®å‰ db_manager è¿”å›çš„æ˜¯ pymongo åŒæ­¥ client
            #     # æ‰€ä»¥æˆ‘ä»¬è¿™é‡Œå¯èƒ½éœ€è¦ç”¨ run_in_executor æˆ–è€…ç›´æ¥è°ƒç”¨ï¼ˆå¦‚æœæ˜¯å¿«é€ŸæŸ¥è¯¢ï¼‰
            #     pass
            
            # ç”±äº pymongo æ˜¯åŒæ­¥çš„ï¼Œæˆ‘ä»¬åœ¨ executor ä¸­è¿è¡Œ
            loop = asyncio.get_running_loop()
            
            def check_sync():
                try:
                    doc = collection.find_one(sort=[("timestamp", -1)])
                    if doc:
                        timestamp = doc.get("timestamp")
                        if timestamp and (datetime.now() - timestamp) < timedelta(days=ttl_days):
                            return True
                    return False
                except Exception as e:
                    logger.warning(f"âš ï¸ [Probe] ç¼“å­˜æŸ¥è¯¢å¼‚å¸¸ ({collection_name}): {e}")
                    return False
                
            return await loop.run_in_executor(None, check_sync)
            
        except Exception as e:
            logger.warning(f"âš ï¸ [Probe] ç¼“å­˜æ£€æŸ¥å¤±è´¥ ({collection_name}): {e}")
            return False

    @staticmethod
    async def probe_macro(index_code: str) -> Dict[str, Any]:
        """æ¢æµ‹å®è§‚æ•°æ®æº"""
        source = "macro"
        
        # 1. Check Cache First (7 days TTL)
        # è¿™é‡Œçš„ key é€»è¾‘éœ€è¦ä¸ macro_analyst ä¿æŒä¸€è‡´
        # ä½†ä¸ºäº†æ¢æµ‹ï¼Œåªè¦ç¡®è®¤ç¼“å­˜ç³»ç»Ÿå·¥ä½œæ­£å¸¸ä¸”æœ‰è¿‘æœŸæ•°æ®å³å¯
        # æˆ–è€…æˆ‘ä»¬å¯ä»¥æ›´ç²¾ç¡®åœ°æ£€æŸ¥å½“å¤©çš„ç¼“å­˜ï¼ˆå¦‚æœ workflow æ€»æ˜¯è¯·æ±‚å½“å¤©ï¼‰
        # è€ƒè™‘åˆ° Macro æ•°æ®æ˜¯ä½é¢‘çš„ï¼Œåªè¦æœ‰æœ€è¿‘ 7 å¤©çš„éƒ½å¯ä»¥
        if await DataSourceProbe._check_mongodb_cache("macro_analysis_cache", "macro", 7):
            return {"available": True, "source": "cache", "latency": 0.001}
            
        # 2. Check API (Async)
        try:
            start = time.time()
            provider = HybridIndexDataProvider()
            # å°è¯•è·å–ä¸€ä¸ªè½»é‡çº§æ•°æ®ï¼Œæˆ–è€…ç›´æ¥è°ƒç”¨ get_macro_data ä½†è®¾ç½®è¾ƒçŸ­è¶…æ—¶
            # ç”±äº get_macro_data å†…éƒ¨å¯èƒ½æœ‰é‡è¯•ï¼Œæˆ‘ä»¬ç»™å®ƒ 5 ç§’
            await asyncio.wait_for(provider.get_macro_data(), timeout=5.0)
            return {"available": True, "source": "api", "latency": time.time() - start}
        except Exception as e:
            return {"available": False, "error": str(e), "latency": time.time() - start}

    @staticmethod
    async def probe_policy() -> Dict[str, Any]:
        """æ¢æµ‹æ”¿ç­–æ•°æ®æº"""
        # 1. Check Cache (30 days TTL)
        if await DataSourceProbe._check_mongodb_cache("policy_analysis_cache", "policy", 30):
            return {"available": True, "source": "cache", "latency": 0.001}
            
        # 2. Check API
        try:
            start = time.time()
            provider = HybridIndexDataProvider()
            # è·å–æœ€è¿‘ 1 å¤©çš„æ”¿ç­–æ–°é—»ä½œä¸ºæ¢æµ‹
            await asyncio.wait_for(provider.get_policy_news_async(lookback_days=1), timeout=5.0)
            return {"available": True, "source": "api", "latency": time.time() - start}
        except Exception as e:
            return {"available": False, "error": str(e), "latency": time.time() - start}

    @staticmethod
    async def probe_news() -> Dict[str, Any]:
        """æ¢æµ‹æ–°é—»æ•°æ®æº (æ— ç¼“å­˜è±å…)"""
        try:
            start = time.time()
            provider = HybridIndexDataProvider()
            # å°è¯•è·å–å¤šæºå¿«è®¯
            await asyncio.wait_for(provider.get_multi_source_news_async(lookback_days=1), timeout=5.0)
            return {"available": True, "source": "api", "latency": time.time() - start}
        except Exception as e:
            return {"available": False, "error": str(e), "latency": time.time() - start}

    @staticmethod
    async def probe_sector() -> Dict[str, Any]:
        """æ¢æµ‹æ¿å—æ•°æ®æº"""
        # 1. Check Cache (1 day TTL)
        if await DataSourceProbe._check_mongodb_cache("sector_analysis_cache", "sector", 1):
            return {"available": True, "source": "cache", "latency": 0.001}
            
        # 2. Check API
        try:
            start = time.time()
            provider = HybridIndexDataProvider()
            # è·å–æ¿å—èµ„é‡‘æµ
            await asyncio.wait_for(provider.get_sector_flows_async(), timeout=5.0)
            return {"available": True, "source": "api", "latency": time.time() - start}
        except Exception as e:
            return {"available": False, "error": str(e), "latency": time.time() - start}

    @staticmethod
    async def probe_technical(index_code: str) -> Dict[str, Any]:
        """æ¢æµ‹æŠ€æœ¯åˆ†ææ•°æ®æº (æ— ç¼“å­˜è±å…ï¼Œéœ€è¦æœ€æ–°è¡Œæƒ…)"""
        try:
            start = time.time()
            provider = HybridIndexDataProvider()
            # è·å–æœ€è¿‘å‡ å¤©çš„æ—¥çº¿æ•°æ®
            end_date = datetime.now().strftime("%Y%m%d")
            start_date = (datetime.now() - timedelta(days=10)).strftime("%Y%m%d")
            # æ³¨æ„ï¼šindex_code å¯èƒ½åŒ…å«åç¼€ï¼Œprovider éœ€è¦å¤„ç†
            data = await asyncio.wait_for(provider.get_index_daily_async(index_code, start_date=start_date, end_date=end_date), timeout=5.0)
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰æ•ˆ (None æˆ– empty DataFrame)
            is_valid = data is not None and not (hasattr(data, 'empty') and data.empty)
            
            if is_valid:
                return {"available": True, "source": "api", "latency": time.time() - start}
            else:
                return {"available": False, "error": "Empty data returned", "latency": time.time() - start}
                
        except Exception as e:
            return {"available": False, "error": str(e), "latency": time.time() - start}

    @staticmethod
    async def run_all_probes(index_code: str, market_type: str = "Aè‚¡") -> Dict[str, Any]:
        """
        å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ¢æµ‹ä»»åŠ¡
        """
        logger.info(f"ğŸ” [Probe] å¼€å§‹æ•°æ®æºå¹¶è¡Œæ¢æµ‹: {index_code} ({market_type})")
        start_time = time.time()
        
        tasks = {
            "macro_db": DataSourceProbe.probe_macro(index_code),
            "policy_db": DataSourceProbe.probe_policy(),
            "news_api": DataSourceProbe.probe_news(),
            "sector_data": DataSourceProbe.probe_sector(),
            "technical": DataSourceProbe.probe_technical(index_code)
        }
        
        # è¿‡æ»¤ä¸å¿…è¦çš„æ¢æµ‹ (ä¾‹å¦‚ç¾è‚¡ä¸éœ€è¦ Aè‚¡æ¿å—æ•°æ®)
        # æš‚æ—¶å…¨é‡æ¢æµ‹ï¼Œå› ä¸º macro/news å¯èƒ½æ˜¯é€šç”¨çš„
        
        # å¹¶è¡Œæ‰§è¡Œ
        results = await asyncio.gather(*tasks.values(), return_exceptions=True)
        
        # ç»„è£…ç»“æœ
        status_map = {}
        details_map = {}
        
        for key, result in zip(tasks.keys(), results):
            if isinstance(result, Exception):
                logger.error(f"âŒ [Probe] {key} æ¢æµ‹å¼‚å¸¸: {result}")
                status_map[key] = False
                details_map[key] = {"error": str(result)}
            else:
                is_available = result.get("available", False)
                status_map[key] = is_available
                details_map[key] = result
                if is_available:
                    source = result.get("source", "unknown")
                    latency = result.get("latency", 0)
                    logger.info(f"âœ… [Probe] {key}: å¯ç”¨ ({source}, {latency:.3f}s)")
                else:
                    logger.warning(f"âš ï¸ [Probe] {key}: ä¸å¯ç”¨ ({result.get('error')})")

        total_time = time.time() - start_time
        logger.info(f"ğŸ [Probe] æ¢æµ‹å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.3f}s")
        
        return {
            "status": status_map,
            "details": details_map
        }
